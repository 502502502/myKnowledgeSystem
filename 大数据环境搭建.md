### 一、Ubuntu安装

1、下载ISO镜像

2、VMware新建虚拟机

3、VMware配置网关

4、修改Ip地址

5、更换软件源

备份原有软件源

在更换软件源之前，建议先备份原有的软件源，以免更换后出现问题。

执行以下命令备份：

> sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak

选择新软件源

打开Ubuntu的软件更新设置（在系统设置中也可以找到），选择 "下载自"，然后从列表中选择一个新的软件源，例如选择中国大陆比较稳定的清华源：

> https://mirrors.tuna.tsinghua.edu.cn/

更新软件源

更换软件源后，需要更新软件源列表，执行以下命令更新软件源列表：

> sudo apt-get update

升级软件包

更新软件源列表后，可以使用以下命令升级系统中已安装的软件包：

> sudo apt-get upgrade

清理已安装但不再需要的软件包

在更新软件包后，可能会出现一些已安装但不再需要的软件包，需要清理它们。可以使用以下命令清理已安装但不再需要的软件包：

> sudo apt-get autoremove



6、安装ssh

安装OpenSSH服务

在大部分Linux系统中，OpenSSH服务已经预安装。如果您的虚拟机中没有安装OpenSSH服务，则可以使用以下命令进行安装（以Ubuntu为例）：

> sudo apt-get update
>
> sudo apt-get install openssh-server

配置OpenSSH服务

打开SSH服务配置文件`/etc/ssh/sshd_config`，通过编辑该文件来更改SSH服务的配置。例如，您可以修改SSH服务监听的端口号、禁用密码登录等。

启动SSH服务

启动或重启SSH服务，让新的配置生效。命令如下：

> sudo service ssh start 

如果您修改了SSH服务配置文件，或者需要重新加载配置文件，可以执行以下命令：

> sudo service ssh reload 

防火墙设置

如果您的虚拟机中启用了防火墙，还需设置允许SSH流量通过防火墙。开放SSH服务默认的22端口，也可以选择其他端口。假设您想要开放SSH服务的22端口，可以执行以下命令：

> sudo ufw allow 22/tcp
>
> sudo ufw disable



7、如果Ubuntu不能全屏，安装vmtools

打开终端，输入

> sudo apt-get install open-vm-tools

安装依赖，这一步很关键，必不可少。

> sudo apt-get install open-vm*

重启

> reboot



8、安装vim

安装 vim

在终端中输入以下命令，安装 vim：

> sudo apt-get install vim

需要输入管理员密码进行确认，然后等待安装完成即可。

验证 vim 是否安装成功

安装完成后，在终端中输入以下命令，查看 vim 的版本信息：

> vim --version



9、修改主机名字

以管理员权限打开 `/etc/hostname` 文件

在终端中输入以下命令以管理员权限打开 `/etc/hostname` 文件：

> sudo vim /etc/hostname

需要输入管理员密码进行确认。

修改主机名

使用 vim 编辑器修改 `/etc/hostname` 文件内容，将原本的主机名改为您想要的新主机名。

保存并退出

完成修改后，按下 `Esc` 键，然后在命令行模式下输入 `:wq` 命令，即可保存并退出 vim 编辑器。

应用修改

在终端中输入以下命令，让新的主机名生效：

> sudo hostname -F /etc/hostname

验证主机名是否已修改

在终端中输入以下命令，查看主机名是否已经修改成功：

> hostname



10、保存虚拟机快照

在 VMware 中打开虚拟机

首先，在 VMware 中打开您要保存快照的虚拟机。

创建快照

在虚拟机打开后，选择 “虚拟机” 菜单栏中的 “快照” 选项，并选择 “拍摄” 选项。

命名快照

在弹出的 “拍摄虚拟机快照” 窗口中，输入快照的名称，并选择是否为快照添加描述信息。

完成创建

点击 “完成” 按钮，即可完成快照的创建过程。

查看快照

您可以通过选择 “虚拟机” 菜单栏中的 “快照” 选项，并选择 “管理” 选项来查看已创建的快照列表。在列表中选择所需的快照，可以对其进行恢复、删除或重命名等操作



11、克隆虚拟机结点



12、修改IP、主机名、Host文件域名解析

主机名未添加到 /etc/hosts 文件：在某些情况下，您可能需要将主机名手动添加到 `/etc/hosts` 文件中。请使用以下命令编辑 `/etc/hosts` 文件并添加主机名和 IP 地址的映射关系：

```
sudo vim /etc/hosts

# 在文件中添加以下行
192.168.17.200   hadoop01
192.168.17.201   hadoop02
192.168.17.202   hadoop03
```



### 二、安装JDK

1、解压 JDK 安装包

使用命令行或图形界面解压下载的 JDK 安装包，例如：

> tar -zxvf jdk-8u51-linux-x64.tar.gz



2、将 JDK 安装程序移动到适当的位置

将解压后的 JDK 安装程序移动到您选择的位置。一般来说，最好将它放在 /usr/local 目录下，如下所示：

> sudo mkdir -p /usr/java
>
> sudo mv jdk1.8.0_51 /usr/java/



3、配置环境变量

为了能够在任何位置使用 JDK 命令，需要将 JDK 安装目录的 bin 子目录添加到 PATH 环境变量中。

> sudo vim /etc/profile

添加如下配置：

```
export JAVA_HOME=/usr/java/jdk1.8.0_51
export JRE_HOME=${JAVA_HOME}/jre  
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib  
export PATH=${JAVA_HOME}/bin:$PATH
```

执行 `source` 命令，使得配置立即生效：

> source /etc/profile



4、验证 JDK 安装

在命令行中输入以下命令：

> java -version



5、ssh免密登录

生成密匙

在每台主机上使用 `ssh-keygen` 命令生成公钥私钥对：

```
ssh-keygen
```

免密登录

将 `hadoop001` 的公钥写到本机和远程机器的 ` ~/ .ssh/authorized_key` 文件中：

```
ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop01
ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop02
ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop03
```

验证免密登录

```
ssh hadoop02
ssh hadoop03
```



### 三、安装python、Mysql



1、准备

在安装之前，请使用以下命令安装Python的先决条件。

```
sudo apt-get install build-essential checkinstall
sudo apt-get install libreadline-gplv2-dev libncursesw5-dev libssl-dev \
    libsqlite3-dev tk-dev libgdbm-dev libc6-dev libbz2-dev
```



2、安装

使用[python](https://www.python.org/)官方站点的以下命令下载Python。您也可以下载最新版本代替下面指定的版本。

```
cd /home/hadoop/bigdata/software
sudo wget https://www.python.org/ftp/python/3.7.0/Python-3.7.0.tgz

sudo tar -zvxf Python-3.7.0.tgz -C /home/hadoop/bigdata
```



3、编译

使用下面的命令集来使用altinstall在您的系统上编译python源代码。

```
cd /home/hadoop/bigdata/Python-3.7.0
sudo ./configure --enable-optimizations
sudo make altinstall
```

make altinstall用于防止替换默认的python二进制文件/ usr / bin / python。



4、检查Python版本

```
python3.7 -V
```



5、



6、



7、



8、



9、





### 四、实验：Hadoop伪分布式安装

1、 解压

下载 Hadoop。这里我下载的是 CDH 版本 Hadoop，下载地址为：http://archive.cloudera.com/cdh5/cdh/5/

```
cd /home/hadoop/bigdata/software
tar -zvxf hadoop-3.2.0.tar.gz -C /home/hadoop/bigdata
```



2、 配置环境变量

编辑 `profile` 文件：

```
sudo vim /etc/profile
```

增加如下配置：

```
export HADOOP_HOME=/home/hadoop/bigdata/hadoop-3.2.0
export  PATH=${HADOOP_HOME}/bin:$PATH
export  PATH=${HADOOP_HOME}/sbin:$PATH
```

执行 `source` 命令，使得配置立即生效：

```
source /etc/profile
```



3、 修改配置

进入 `${HADOOP_HOME}/etc/hadoop` 目录下，修改配置文件。各个配置文件内容如下：

hadoop-env.sh

```
# 指定JDK的安装位置
export JAVA_HOME=/usr/java/jdk1.8.0_51/
```

core-site.xml

```
<configuration>
    <property>
        <!--指定 namenode 的 hdfs 协议文件系统的通信地址-->
        <name>fs.defaultFS</name>
        <value>hdfs://hadoop01:9000</value>
    </property>
    <property>
        <!--指定 hadoop 集群存储临时文件的目录-->
        <name>hadoop.tmp.dir</name>
        <value>/home/hadoop/bigdata/hadoop/tmp</value>
    </property>
</configuration>
```

hdfs-site.xml

```
<property>
      <!--namenode 节点数据（即元数据）的存放位置，可以指定多个目录实现容错，多个目录用逗号分隔-->
    <name>dfs.namenode.name.dir</name>
    <value>/home/hadoop/bigdata/hadoop/namenode/data</value>
</property>
<property>
      <!--datanode 节点数据（即数据块）的存放位置-->
    <name>dfs.datanode.data.dir</name>
    <value>/home/hadoop/bigdata/hadoop/datanode/data</value>
</property>
<property>
	 <!--数据副本数量-->
   <name>dfs.replication</name>
   <value>2</value>
</property>
<property>
   <name>dfs.namenode.secondary.http-addr</name>
   <value>hadoop01:50059</value>
</property>


```

yarn-site.xml

```
<configuration>
    <property>
        <!--配置 NodeManager 上运行的附属服务。需要配置成 mapreduce_shuffle 后才可以在 Yarn 上运行 MapReduce 程序。-->
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <!--resourcemanager 的主机名-->
        <name>yarn.resourcemanager.hostname</name>
        <value>hadoop01</value>
    </property>
    <property>
    	<name>yarn.application.classpath</name>
    	<value>
    	/home/hadoop/bigdata/hadoop-3.2.0/etc/hadoop:/home/hadoop/bigdata/hadoop-3.2.0/share/hadoop/common/lib/*:/home/hadoop/bigdata/hadoop-3.2.0/share/hadoop/common/*:/home/hadoop/bigdata/hadoop-3.2.0/share/hadoop/hdfs:/home/hadoop/bigdata/hadoop-3.2.0/share/hadoop/hdfs/lib/*:/home/hadoop/bigdata/hadoop-3.2.0/share/hadoop/hdfs/*:/home/hadoop/bigdata/hadoop-3.2.0/share/hadoop/mapreduce/lib/*:/home/hadoop/bigdata/hadoop-3.2.0/share/hadoop/mapreduce/*:/home/hadoop/bigdata/hadoop-3.2.0/share/hadoop/yarn:/home/hadoop/bigdata/hadoop-3.2.0/share/hadoop/yarn/lib/*:/home/hadoop/bigdata/hadoop-3.2.0/share/hadoop/yarn/*
    	</value>
	</property>

</configuration>
```

mapred-site.xml

```
<configuration>
    <property>
        <!--指定 mapreduce 作业运行在 yarn 上-->
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>
```

works

配置所有从属节点的主机名或 IP 地址，每行一个。所有从属节点上的 `DataNode` 服务和 `NodeManager` 服务都会被启动。

```
hadoop01
hadoop02
hadoop03
```



4、 分发程序

将 Hadoop 安装包分发到其他两台服务器，分发后建议在这两台服务器上也配置一下 Hadoop 的环境变量。

```
# 将安装包分发到hadoop02
scp -r /home/hadoop/bigdata/hadoop-3.2.0/  hadoop02:/home/hadoop/bigdata/
# 将安装包分发到hadoop03
scp -r /home/hadoop/bigdata/hadoop-3.2.0/  hadoop03:/home/hadoop/bigdata/
```

配置环境变量



5、 初始化

在 `Hadoop01` 上执行 namenode 初始化命令：

```
hdfs namenode -format
```



6、启动集群

进入到 `Hadoop001` 的 `${HADOOP_HOME}/sbin` 目录下，启动 Hadoop。此时 `hadoop02` 和 `hadoop03` 上的相关服务也会被启动：

```
# 启动dfs服务
start-dfs.sh
# 启动yarn服务
start-yarn.sh
```



7、 查看集群

在每台服务器上使用 `jps` 命令查看服务进程，或直接进入 Web-UI 界面进行查看，端口为`9870`

接着可以查看 Yarn 的情况，端口号为 `8088` 



8、提交服务

```
hadoop jar /home/hadoop/bigdata/hadoop-3.2.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.0.jar  pi  3  3
```

![image-20230520195947989](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520195947989.png)

<img src="https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520195908782.png" alt="image-20230520195908782" style="zoom:80%;" />

### 五、实验：读取HDFS

1、配置hadoop-env

> export JAVA_HOME=/usr/java/jdk1.8.0_51/
>
> export HADOOP_LOG_DIR=/home/hadoop/bigdata/hadoop/logs
>
> export HADOOP_CLASS=/home/hadoop/bigdata/hadoop/myclass

2、启动集群

> start-all.sh

3、创建代码目录

>cd /home/hadoop/bigdata/hadoop
>
>mkdir myclass
>
>mkdir input

4、建立文件

>poetry.txt

```
sdgdvbjknvj  udhfus   sduhvfskd 
cnjdvbj cdisvknkd cdsjvbjsd chjdsbcqiwjc
12345678 bhjckcsdjv 9876543bh
dsjvhudshv kdjshc dscjsdb cdsbhc csjabk
csdcjxzc ajkshanc sakckasnc dsjkvk
```

5、在hdfs建立文件夹

> hdfs dfs -mkdir /class
>
> hdfs dfs -ls/

6、上传到hdfs

> hdfs dfs -put /home/hadoop/bigdata/hadoop/input/poetry.txt /class

7、创建myclass文件夹，编写Java代码，读取hdfs文件内容

> cd /home/hadoop/bigdata/hadoop
>
> cd myclass.java
>
> sudo vim myclass.java

```java
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.*;
import org.apache.hadoop.io.IOUtils;

import java.io.InputStream;
import java.net.URI;

public class FileSystemCat {
    public static void main(String[] args) throws Exception {
        String uri = args[0];
        Configuration conf = new Configuration();
        FileSystem fs = FileSystem.get(URI.create(uri), conf);
        InputStream in = null;
        try{
            in = fs.open(new Path(uri));
            IOUtils.copyBytes(in, System.out, 4096, false);
        }finally{
            IOUtils.closeStream(in);
        }
    }
}
```

8、编译成jar包

> cd /home/hadoop/bigdata/hadoop/myclass
>
> javac -classpath /home/hadoop/bigdata/hadoop-3.2.0/share/hadoop/common/hadoop-common-3.2.0.jar FileSystemCat.java
>
> jar -cvf test.jar ./*

9、执行jar程序，读取hdfs文件内容

> hadoop jar test.jar FileSystemCat  /class/poetry.txt

![image-20230520195730037](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520195730037.png)

10、停止运行

> stop-all.sh





### 六、实验：求每年最低温度

![image-20230520200801164](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520200801164.png)

![image-20230520200511075](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520200511075.png)

![image-20230520200527099](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520200527099.png)

![image-20230520200539325](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520200539325.png)

![image-20230520200552255](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520200552255.png)

![image-20230520200607241](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520200607241.png)

![image-20230520200621115](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520200621115.png)

![image-20230520200632950](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520200632950.png)

![image-20230520200643137](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520200643137.png)

![image-20230520200656123](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520200656123.png)

![image-20230520200710893](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520200710893.png)

![image-20230520200733364](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520200733364.png)

![image-20230520200745157](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520200745157.png)

1、

> 

2、

> 

3、

> 

4、

> 

5、

> 

6、

> 

7、

> 

8、

> 

9、

> 

10、

> 

11、

> 

12、

> 

13、

> 



### 七、实验：安装Hive

![image-20230520205226928](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520205226928.png)

![image-20230520205237885](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520205237885.png)

![image-20230520205256685](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520205256685.png)

![image-20230520205311338](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520205311338.png)

![image-20230520205341150](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520205341150.png)

![image-20230520205358437](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520205358437.png)

![image-20230520205420264](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520205420264.png)

![image-20230520205443495](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520205443495.png)

![image-20230520205500992](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520205500992.png)



1、

> 

2、

> 

3、

> 

4、

> 

5、

> 

6、

> 

7、

> 

8、

> 

9、

> 

10、

> 

11、

> 

12、

> 

13、

> 





### 八、实验：Hive应用-CLI命令行

![image-20230520205739497](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520205739497.png)

![image-20230520205755871](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520205755871.png)

![image-20230520205810494](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520205810494.png)

![image-20230520205828234](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520205828234.png)

![image-20230520205839431](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520205839431.png)

![image-20230520205851770](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520205851770.png)

1、

> 

2、

> 

3、

> 

4、

> 

5、

> 

6、

> 

7、

> 

8、

> 

9、

> 

10、

> 

11、

> 

12、

> 

13、

> 



### 九、实验：Hive应用-Web和远程调用



1、

> 

2、

> 

3、

> 

4、

> 

5、

> 

6、

> 

7、

> 

8、

> 

9、

> 

10、

> 

11、

> 

12、

> 

13、

> 



### 十、实验：Hive应用-数据类型



1、

> 

2、

> 

3、

> 

4、

> 

5、

> 

6、

> 

7、

> 

8、

> 

9、

> 

10、

> 

11、

> 

12、

> 

13、

> 



### 十一、实验：Hive应用-HQL应用



1、

> 

2、

> 

3、

> 

4、

> 

5、

> 

6、

> 

7、

> 

8、

> 

9、

> 

10、

> 

11、

> 

12、

> 

13、

> 



### 十二、实验：Hive应用-JDBC连接



1、

> 

2、

> 

3、

> 

4、

> 

5、

> 

6、

> 

7、

> 

8、

> 

9、

> 

10、

> 

11、

> 

12、

> 

13、

> 



### 十三、实验：安装Hbase



1、

> 

2、

> 

3、

> 

4、

> 

5、

> 

6、

> 

7、

> 

8、

> 

9、

> 

10、

> 

11、

> 

12、

> 

13、

> 





### 十四、实验：Hbase应用-执行



1、

> 

2、

> 

3、

> 

4、

> 

5、

> 

6、

> 

7、

> 

8、

> 

9、

> 

10、

> 

11、

> 

12、

> 

13、

> 



### 十五、实验：Hbase应用-编程



1、

> 

2、

> 

3、

> 

4、

> 

5、

> 

6、

> 

7、

> 

8、

> 

9、

> 

10、

> 

11、

> 

12、

> 

13、

> 



### 十六、实验：Hbase应用-管理工具



1、

> 

2、

> 

3、

> 

4、

> 

5、

> 

6、

> 

7、

> 

8、

> 

9、

> 

10、

> 

11、

> 

12、

> 

13、

> 



### 十七、实验：Hbase应用-数据导入



1、

> 

2、

> 

3、

> 

4、

> 

5、

> 

6、

> 

7、

> 

8、

> 

9、

> 

10、

> 

11、

> 

12、

> 

13、

> 









### 十八、综合应用：超市零售数据分析

![image-20230520210945102](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520210945102.png)

![image-20230520210958430](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520210958430.png)

![image-20230520211011180](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520211011180.png)

![image-20230520211031006](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520211031006.png)

![image-20230520211041792](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520211041792.png)

![image-20230520211052403](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520211052403.png)

![image-20230520211107494](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520211107494.png)

![image-20230520211120799](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520211120799.png)

![image-20230520211132920](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520211132920.png)

![image-20230520211142893](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520211142893.png)

![image-20230520211157798](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520211157798.png)

![image-20230520211302654](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520211302654.png)

![image-20230520211315323](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520211315323.png)

![image-20230520211328217](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230520211328217.png)

1、

> 

2、

> 

3、

> 

4、

> 

5、

> 

6、

> 

7、

> 

8、

> 

9、

> 

10、

> 

11、

> 

12、

> 

13、

> 





### 十九、课程设计：



### 二十、机器学习

