### 1、用threadlocal做了什么，为什么要用，底层实现

> 做了什么

我有这样一个需求，就是在整个请求的处理过程中，会多次需要到当前用户对象，所以我想在请求处理之前，从数据库把这个对象加载到内存中，交给spring容器，需要的地方直接用注解注入就行，不用每次都创建。



> 为什么要用

一开始我想用session存储，使用session的好处是，同一个用户发的请求，不用每一次都去创建用户对象，直接从session获取就行，不同用户发的请求都从自己的session获取，实现并发隔离。而且使用redis替代session后，在分布式环境下，无论哪个结点来处理请求，都能直接获取创建好的用户对象。



但是有一个问题就是，用户对象是可变的，如果进行了用户资料的修改，需要同步到session或者redis，这就比较麻烦了，同步过程还得解决丢失，并发覆盖等问题。而且用户连续发送的多个请求，可能会出现多个线程同时操作同一个session的情况。这就导致一个请求在处理的过程中，它的用户对象是可能会变的，这个会留下一些隐患。



所以我用threadlocal来解决这个问题，去保证每一个线程执行过程中，它的用户对象信息都不会发生修改。在请求处理之前，使用拦截器从数据库加载对象，放到threadlocal中，整个处理过程使用的都是同一个对象，请求处理结束后手动从threadlocal删除用户对象。



> 实现原理

threadlocal有一个静态内部类ThreadLocalMap，这个Map是实现线程隔离的核心，它是自定义的，没有实现Map接口，用了一个Entry数组来存储threadlocal, value键值对，这个key是threadlocal实例，value是绑定的对象。

每个线程都有自己Map对象，用来存储自己线程的所有thtreadlocal对象和它绑定的对象，所以不会存在并发安全问题。

Map是local类的静态内部类，意味着，同样的线程，即使你有多个threadlocal实例，线程都只有一个Map实例，在这个实例里以threadlocal实例为键，存储对象。



> threadlocalMap解决哈希冲突的方式

处理冲突检测的机制是向后移位, 清除过期条目 最终找到合适的位置



> 为什么结束后要删除用户对象

会，当前线程结束后，当前线程对应的map应该被回收，map里的threadlocal，value都应该被回收，但是如果其它线程保持着对local实例的引用，当前对象的Map会被认定为存活对象，不能被回收，map里的threadlocal，value对也会一直存在。

解决办法就是在当前线程使用完local对象后，手动调用remove方法将其从Map中删除。



### 2、用elasticsearch做了什么，为什么要用，底层实现

> 做了什么

我希望能够对我的帖子进行一个搜素，就是我输入一些关键字，帖子包含这些关键字，或者部分关键字，就应该被搜索到。



> 为什么要用

一开始是使用mysql的like模糊查询做的搜索。

但是这样限制很多，首先是索引会失效，走全表扫描效率很低，再有就是不能做复杂的查询，比如我只需要包含关键词的一部分，模糊查询就做不到。

于是想到使用全文索引来做这个功能，mysql本身也支持全文索引，但是建立多个字段的全文索引会占用大量的磁盘空间，而且做复杂查询的时候会比较吃力。

es是专门做全文检索的，使用倒排索引来检索关键词，直接得到包含关键词的文档列表。它支持分布式的存储和搜索，将数据做了分片，存储到不同的结点；支持更高级的分词算法和匹配算法，在做复杂查询合海量数据查询的时候性能较好。



> es底层原理

主要是通过分区存储数据，以及通过分词算法切分关键词，然后通过倒排索引高校检索数据。



> 怎么做的搜索

首先配置好es服务器，将mysql的帖子数据存储到es中，并且在数据发生增删改的时候，同步到es服务器。

之后就是构建一个查询请求，向es发送查询请求，获取搜索的结果。



> 数据同步是怎么做的

mysql到es的数据同步方式有几种。

第一种是双写，有同步和异步的方式，同步就是在修改时同时写入es，异步就是发送到mq进行消费。双写策略需要耦合业务代码，而且需要自己处理同步失败的情况。

第二种是基于binlog订阅，binlog就是用来做主从同步的，通过第三方组件模拟为从节点，对mysql发起同步请求，然后将binlog回放，写到es。比如Canal，这种方式比较简单省事，而且海量数据同步效率也高。

第三种是基于sql查询做的数据抽取，通过第三方组件定时查询mysql，找到增量修改的数据，同步到es。比如logstash，这种方式需要增加修改时间的字段，ogstash会保存每一次查询的最后修改时间，通过实践判断哪个记录是新增的。



我使用的是canal做的数据同步。首先是开启mysql的binlog功能，然后安装canal服务器，配置数据库的连接，以及es客户端的连接参数，以及es和mysql表的映射关系。之后保持canal的运行就能实现数据同步。





> 查询请求是怎么样构建的

首先得执行GTE请求，然后是需要查询的索引，然后构建一个query请求体，在请求体中配置查询的模式，比如match，或者term，然后配置查询的字段以及响应的关键词，最后就是一些条件的配置，比如分组，排序，过滤，分页等等。





> es是怎么检索一个关键词的

解析查询请求：Elasticsearch会解析接收到的搜索请求，提取其中的索引名称、查询条件、排序规则等信息。

查询路由和分片选择：根据索引名称和查询条件，Elasticsearch确定要在哪些分片上执行查询操作。如果查询请求没有指定特定的分片，则会在索引中的所有分片上执行查询。

倒排索引搜索：Elasticsearch使用倒排索引来加速搜索过程。倒排索引是根据每个唯一词项（terms）建立的数据结构，记录了该词项在哪些文档中出现。根据查询条件中的关键词，在倒排索引中找到匹配的词项，进而找到对应的文档。

结果打分和排序：Elasticsearch对于每个匹配的文档进行打分，根据打分结果对文档进行排序。默认情况下，Elasticsearch使用TF-IDF（词频-逆向文档频率）算法来计算文档的相关性得分，也可以根据需要使用其他自定义的打分算法。

结果返回：根据用户的设定，Elasticsearch将搜索结果返回给用户。搜索结果通常包括匹配的文档、相关性得分以及任何附加的聚合结果。



> 倒排索引的原理是什么

倒排索引可以实现从词语到文档的映射。它由两部分组成：词典和倒排列表。

倒排索引将文档集合中的每个词语与包含该词语的文档列表关联起来。

词典是由所有不重复的词语构成的数据结构，用于存储词语及其对应的倒排列表的位置信息。

倒排列表则记录了包含该词语的文档的详细信息，如文档的编号、出现的位置等。



> 分词的原理是什么

分词器就是把一个短语通过一些分词算法拆分成语义独立的词语的一个组件。这些词语将作为倒排索引的字典。

分词器除了进行分词的操作，还会有一些别的处理，比如对分词后的词语做一个过滤，或者一些大写小写转化，以及更进一步的分词处理。

常见的分词算法有几种类型，一种是基于字典的，对短语做匹配，匹配成功后作为一个词语，并接着进行匹配。

也可以基于语法规则对短语做切分，根据语法，语义，词性等规则做切分。也可以基于深度学习算法，根据大量的数据训练来学习如何做拆分。



> es是怎么存储一条记录的

首先根据路由策略确定该数据应该路由到索引的哪个分片中。路由策略可以自定义，或者根据某个字段的值做区分。

把数据写入分片的缓冲区中，生成文档ID等信息以及倒排索引等数据，然后定期从缓冲区把数据刷到磁盘。



> term和match的区别

Term 查询是一种精确匹配的查询，它在搜索时不会对关键词进行分词处理。

Match 查询： Match 查询是一种通过分词来进行全文搜索的查询方式。它会对搜索条件进行分词，并将分词后的词项与索引中的词项进行匹配。

 

### 3、用Kafka做了什么，为什么要用，底层实现

> 做了什么

当发生点赞，关注和评论事件的时候，需要给关联的用户发送一条系统通知。我使用了异步执行的机制，就是先将这个事件发送给Kafka，再进行消费，把通知写入到数据库。

在注册账号的时候，有一个邮箱激活的需求，需要给指定邮箱发送一个激活邮件，这个发送的操作非常的耗时，会导致前端界面一直在转圈圈，所以我把这个发的动作发送到了Kafka，异步的执行发邮件的动作。



> 为什么用Kafka

Kafka可以处理大规模的实时数据流，拥有非常高的吞吐量和低延迟。

Kafka将所有消息持久化到磁盘上，因此不会因为消费者的速度慢或者宕机导致数据丢失，提高数据可靠性。

Kafka采用分布式架构，可以在多个服务器上进行水平扩展。将topic的数据存储到不同结点的分区上。而且还建立了副本存储数据，不会因为结点的宕机产生数据丢失的问题。

Kafka支持发布订阅模式，消费者可以订阅感兴趣的主题并实时接收消息，多个消费者组可以并行的消费同一个topic的不同分区。



> Kafka分区数量和消费者组怎么考虑

Kafka分区数量默认是1，可以在创建topic的时候指定分区数量，分区数量应该大于消费者组的数量，否则消费者会出现分不到分区消费，浪费资源的情况。多个消费者组之间是可以并行消费一个topic的。



> kafka底层原理、为什么吞吐量高

存储：Kafka使用持久化日志的方式来存储消息，基于顺序写和随机读的特性，以及磁盘顺序读写的高效性

副本：Kafka采用分布式的多副本机制，将主题的分区数据复制到多个Broker上。这样的设计不仅提高了数据的可靠性，还允许通过增加Broker节点来水平扩展整个系统的吞吐量和容量。

批量：Kafka支持批量处理消息，即生产者可以将多条消息批量发送到Broker。这种批量处理减少了网络开销和磁盘IO，提高了生产者和消费者的效率。同时，Kafka还支持消息的压缩，可以减小网络传输的数据量，节省带宽和存储空间。

消费：Kafka引入了消费者组的概念，组内的消费者可以同时处理多个分区的消息，实现了消息的并行处理和负载均衡。

Kafka提供了灵活的分区分配策略，确保分区在消费者组内均匀分布，以及在消费者加入或退出时自动进行重新分配。



> kafka消息丢失怎么解决

Kafka的消息丢失问题可能会发生在Broker、Producer和Consumer三种中的任意一种。

Broker消息丢失是因为采用异步批量的刷盘策略，宕机会丢失一部分数据，解决的办法就是同步刷盘。

producer消息丢失是因为采用异步发送的方式，没等Kafka确认就认为发送成功，解决办法就是改成同步发送，或者设置一定的重传次数。

consumer丢失数据是因为分区offset的提交是在消费之前，提交后没来得及消费就宕机了，解决办法就是改成消费消息之后再提交offset。



> kafka重复消费怎么解决

重复消费是由于offset提交的时候宕机了，Kafka把分区交给其它消费者进行消费。



> kafka顺序消费怎么实现

kafka每个partition中的消息在写入时都是有序的，消费时，每个partition只能被每一个group中的一个消费者消费，保证了消费时也是有序的。

整个topic不保证有序。如果为了保证topic整个有序，那么将partition调整为1.







### 4、用caffeine做了什么，为什么要用，底层实现

> 做了什么

我在首页会展示一页的帖子，在操作的过程中，会频繁的访问首页，需要不断的查询数据库，帖子的信息是很少会改变的，所以我想使用一个本地缓存来保存首页展示的帖子。直接从缓存中获取，不需要每次都查库。



> 为什么用caffeine

直接使用map也能实现简单的缓存效果，但是得单独做过期时间，过期之后再次访问还要重新加载，而且在并发环境下加载，有可能会出现线程安全的问题。

caffeine可以配置过期时间和过期策略，可以使用手动或者异步的方式加载数据，并且使用了分段锁保证并发环境下的线程安全问题，而且caffeine还提供了一些监控和统计的功能。

如果数据已经过期，会从redis重新加载数据，redis作为一个集中缓存，可以解决分布式共享的问题。



> caffeine底层是怎么实现的

Caffeine 使用了一种类似于哈希表的数据结构。它是一个线程安全的哈希表，采用分段锁的方式来提高并发性能。每个 不同的段可以被不同的线程同时访问，增加了并发度。

使用堆外内存来存储缓存数据，自己实现内存池，内存管理器来做内存分配和释放，减轻 Java 堆内存的压力，提高 GC 性能，并且通过跳表等数据结构来实现缓存数据的排序等操作。



> 堆外内存有什么不同

堆外内存绕过JVM直接使用操作系统提供的内存空间，不受JVM堆内存管理。

可以提供更大的内存空间，访问速度快，不受JVM的影响

但是需要自己管理内存的分配和释放等问题。





### 5、用redis做了什么，为什么要用，底层实现

作为数据库存储了点赞，关注信息，以及DAU和UV的统计信息，以及登录的时候保存登录状态信息还有验证码信息等，作为一个临时的缓存。



> 做了什么

为了缓解mysql数据库的压力，我把一些操作频繁，数据量小的数据放到了redis中，redis是一个性能高的，读取非常快的一个缓存，比较适合存储一些热点数据。



第一个是点赞信息，关注信息，这些信息的辩护频率非常的快。

第二个是UV和DAU统计信息，redis对于做统计有非常优秀的数据结构，可以很方便的进行数据统计。

第三个是一些会话状态的信息，比如一些用于验证身份的验证key，临时生成的验证码。这些信息保存到redis是为了解决分布式的一个问题，可以在分布式环境下共享状态信息，不会出现在这个结点登录之后，再次访问另一个结点获取不到的情况。

第四个是文章热度信息的保存，文章的热度是通过一个公式算出来的一个数字。它是需要频繁去更新的，所以把它放到了redis去保存。

第五个就是热点文章的数据缓存，给热点文章做缓存可以降低数据库的压力，提高响应速度。redis作为一个分布式环境的共享缓存，使用caffeine在本地做了高速的缓存，caffeine数据过期之后会从redis重新加载。因为我已经把文章变化频繁的数据做了抽离，而且文章被修改修改的频率是很低的，文章一致性问题带来的影响也不会很大。文章缓存在过期之前是不会和数据库数据做同步的，哪怕文章发生了修改，热榜发生了变化。在过期之后，才会去查热榜，得到热榜前一页文章的id，去访问数据库，然后把查询到的数据更新到redis。





> 用了哪些数据结构去保存

会话状态信息和热度信息，热点数据都使用简单的string类型，通过一个键值对的简单形式保存数据；

关注信息使用了sorted set，因为关注我除了要记录关注者，被关注者，还要记一个关注的时间，而且对这个时间有一个排序的需求，就是展示粉丝列表的时候，会根据这个关注时间排序展示。恰巧这个sorted set本身有一个分数，可以用来存时间，也很方便的做排序。

点赞信息使用了set，因为我对这个点赞没有做这个时间记录，所以只需要set记录就行，使用set可以方便的进行排除重复点赞。

UV和DAU的记录使用了HyperLogLog统计，HyperLogLog使用了基数统计的算法，使用固定数量的内存来估计集合的基数，计算速度快，空间占用小。



> 这些数据结构的底层有了解过吗

string底层是一个动态数组sds，使用字节数组来存储数据，通过空间预分配，以及扩容可以实现动态扩展。string的字节数组是以二进制的格式存储的，所以能存储任何形式的数据，包括字符，图片，视频等。string实现了一系列方便操作字符串的api，比如替换，截取，追加等等，功能非常的强大。



set底层是用哈希表实现的，哈希表是一种键值对的数据结构，其中每个元素由一个唯一的键和对应的值组成。set中的每一个元素是哈希表的键，哈希表的值是忽略的。



Sorted Set底层的实现主要基于跳表（Skip List）和哈希表两个数据结构，跳表由多个层级组成的，每个层级都是一个有序链表，可以实现向后和向下查找，就类似与二叉树的结构，可以实现ln(n)效率的查找。哈希表是用来存储元素和分数对应关系的。



Hyperloglog底层是基于一定数量的桶作为计数器，通过一个哈希函数将元素转变为固定长度的哈希值，通过哈希值前缀定位到属于它的桶，然后，桶会记录哈希值最长连续尾部0的最大个数。这个最大个数后边经过求平均数之后作为一个基数，去估计元素的数量。基数估计的核心原理是通过桶内的最大连续尾部零个数来推断数据集的基数大小。





> 分布式锁有了解吗

在分布式环境中，会有多个结点竞争共享资源资源，不可避免地会出现并发安全问题，本地锁只能作用在同一台机器上，它是基于操作系统实现的，不能协调控制到其它的结点。所以需要一个作用范围更大的，能在多台机器共享的锁，来保证分布式并发操作的安全性。



分布式锁的实现很简单，就是多个结点去获取同一把锁，保证只有一个结点获取成功，并且处理好死锁问题，以及锁的可靠性问题即可。



可以使用数据库的行锁或者利用数据库做一个乐观锁的机制去保证只有一个结点能够获取到锁。也可以使用redis单线程的安全性去保证只有一个结点能够获取成功。在redis使用set nx命令可以设置一个锁，nx命令保证了如果key为空才会设置成功，再加上redis是单线程的，就能保证只有一个结点能够得到锁。



死锁问题是因为结点宕机，不释放锁造成的，解决办法就是给key加一个过期时间。如果过期了，redis或者其它线程就能够释放并获取锁。但是结点有可能没有宕机，只是执行时间久，所以还得解决锁的误删问题。使用心跳机制可以解决这个问题，锁快过期了就发送请求给锁的结点，如果它还在使用，就为这个锁延长过期时间。



最后一个问题就是锁的可靠性问题，redis结点可能会宕机，导致锁服务不可用，所以需要一个集群环境。主从环境的模式可能会出现脑裂的情况，就是从节点上位后给其它结点上锁，然后主节点恢复，导致锁被多个结点获取到。

可以使用Redlock算法解决这个问题，就是设置多个相互独立的主节点，当结点尝试获取锁的时候，向所有的主节点发送加锁请求，只有超过一半的结点加锁成功，才认为分布式锁加锁成功，否则会回退，在已经加锁成功的redis结点释放锁。





> redis为什么这么快

第一个原因是redis把数据存储到了内存，内存的读写速度是远远超过磁盘的。

第二个是redis使用单线程模型，避免了上下文切换以及并发控制带来的开销。

还有就是redis向操作系统提交请求是异步的，在等待提交结果的时候不会阻塞其它请求提交。

还有一个比较重要的原因是redis使用简单高效的数据结构，很多都是基于哈希表的存储，查找复杂度是o(1)

在网络通信方面没有使用http协议，而是使用自己开发的resp协议，resp是基于二进制的协议，数据格式非常简单，可以快速进行解析和序列化，降低网络传输开销。





> 有用过redis事务吗

在做点赞的时候，除了要记录文章的帖子数量变化，同时对于文章作者总共获得的点赞数，也要同时变化。还有关注的时候，除了被关注者的粉丝列表发送变化，关注者的关注列表也要同时变化。这就需要使用redis事务来保证一致性。



redis事务使用multi开启，使用exec执行，使用watch监控。redis事务保证在开启时候后，执行事务之前，如果发生了key的变化，或者命令出现语法错误，会发生回滚，不执行任何命令。

但是一旦事务开始执行了，发生运行时错误，redis事务不会回滚，其它命令正常执行。

redis还保证在事务的命令之间不会插入其它客户端的命令，保证了事务的一致性。





### 6、用线程池做了什么，线程池有哪些参数

查找所有帖子的时候，使用线程池并发的查找每一个帖子关联的评论，使用concurrentMap聚合起来。



> 做了什么

在查询一个帖子的详情信息的时候，会查询它的评论信息，而且每一个评论还需要去查询评论的人的信息，这条评论的点赞信息，以及回复信息每一条评论都要进行相同的查询，彼此独立没有交互，所以使用线程池去分别查询每一个评论的回复信息吗，提高查询的效率。使用threadpoolExecutor创建一个线程池，配置了它的一些参数，比如核心线程数，最大线程数，阻塞队列长度，拒绝策略。使用countdownlatch阻塞主线程，等待所有查询结束。因为每一个评论都是放到一个map里边的，它的用户信息，点赞信息，回复信息也都是放到这个map里边，不同的评论有不同的map，不会发生并发修改的问题。



> 说一下线程池的几个参数

线程池的核心参数是核心线程数和最大线程数，核心线程数是指一直保持存活状态的线程数量，最大线程数是指线程池中允许存在的最大线程数。还有线程存活时间，当线程池中的线程数量超过核心线程数，并且处于空闲状态时，空闲线程在这个时间之后就会被回收。还有阻塞队列，当线程池中的线程数量达到核心线程数，并且所有核心线程都在执行任务时，新的任务将被放入阻塞队列中等待被执行。阻塞队列的类型有三种，有界队列，无界队列以及不存储元素的队列

有界队列可以使用ArrayBlockingQueue，LinkedBolckingQueue实现，无界队列可以使用LinkedBlockingqueue实现，同步队列可以使用SynchronousQueue实现。



> 任务提交之后是怎么处理的

判断线程池的线程数量是否达到核心线程数，如果没有，创建新线程执行。

否则看看有没有空闲的核心线程，如果有，直接执行，如果没有，把任务加入阻塞队列。

如果队列满了，判断线程池的数量是否超过最大线程数，如果没有，创建新的线程执行，否则根据拒绝策略处理。



如果使用的是同步队列，任务提交之后如果没有空闲线程，直接被阻塞，直到有空闲线程或创建了新线程来消费之后才会唤醒提交任务的线程。Java线程池中的**newCachedThreadPool**（带缓存的线程池）底层就是使用SynchronousQueue实现的，它的核心线程数是0，最大线程数是Integer的最大值，特点就是来一个线程就处理一个，速度非常快。



> 怎么考虑阻塞队列的类型

如果任务数量很多，应该使用无界队列或者容量大的有界队列，避免任务丢失。

如果内存有限，应该使用有界队列，并设置合适大小。

如果需要做线程同步，应该使用不存储元素的队列，它会阻塞任务提交线程直到被消费。



> 怎么考虑核心线程数和最大线程数的取值

首先核心线程数不应该超过cpu的核心数量，避免上下文切换的开销。

然后最大线程数应该考虑任务的特点，如果是计算型的，最大线程数应该和核心线程数保持相同或者稍微多一点，避免CPU上下文切换。如果是IO型的，可以稍微多一点，因为在IO的时候，会释放CPU资源，可以处理其它的任务。



> ArrayBlockingQueue，LinkedBolckingQueue底层有了解吗

ArrayBlockingQueue就是一个指定大小的数组，不能扩容，使用ReentrantLock还有两个condition保证并发修改。

ReentrantLock保证修改的时候只有一个线程进行，两个condition分别在队列为空或者满的时候阻塞消费者和生产者。



LinkedBlockingQueue可以实现无界阻塞队列和有界阻塞队列，内部分别使用了自定义的takeLock 和 putLock和两个condition 进行并发控制。当消费者进程需要来取数据的时候，需要先获取到takeLock，如果队列为空或，会在notempty条件进行阻塞。当生产者将元素放到队列，需要获取putlock，如果队列已满，会在notfull条件上阻塞。也就是说，添加和删除操作并不是互斥操作，可以同时进行，这样也就可以大大提高吞吐量。takelock和putlock底层是使用AQS实现的锁机制实现的



> SynchronousQueue底层有了解吗

SynchronousQueue是一个没有存储容量的阻塞队列，在元素的交换过程中需要等待其他线程同时到达。

SynchronousQueue线程的消费次序可以实现公平和非公平的，公平消费使用队列存储阻塞的线程，非公平使用栈实现。

对于这个栈或者队列的存取操作，使用CAS保证并发安全性。入栈或者队列之后，使用自选和挂起的策略阻塞线程，等待消费。





### 7、用Quartz做了什么，为什么要用，底层实现

> 做了什么

我做了一个热榜排行，每篇文章会有一个热度值。这个值变化的频率非常高，点赞，关注，评论，回复，置顶，加精，都会参与热度的加权计算，这些事件每发生一次就进行一次热度值计算是非常浪费资源的，而且热度值本身也是一个近似的模型，所以我使用了定时任务去更新热度值，但是也不是对所有文章都进行更新，我使用一个set保存发生了热度变化事件的文章的id，set可以实现去重，在一段时间内发生多次热度变化事件，只需要进行一次更新即可。为了满足分布式消费地需求，这个set使用了redis实现。

定时任务使用了quartz实现。

配置了多个线程去执行定时任务，任务的逻辑是从redis的set中pop出来一个id，然后使用公式去计算热度值，更新热度值。

由于redis单线程执行，pop操作不会出现并发安全问题，不会出现重复消费的问题，但是会有丢失的问题。这个更新操作应该是原子性的，就是如果没有更新成功，就不应该在set里把id删除，如果先删除，再消费，消费失败之后会发生消息丢失。

可以对刷新分数的代码进行异常捕获，有异常的时候将id重新放回set进行第二次消费。不过要是因为宕机丢失，那就是真的丢了。



> 怎么解决客户端宕机导致消息丢失的问题

可以先消费，再删除，如果消费过程出现异常，就不删除；这个方案可以解决消息丢失的问题，但是会出现重复消费的问题，多个客户端同时获取到同一个id，进行刷新。这个重复消费的问题其实不是很严重，因为多次刷新分数并不会造成数据错乱，它具有幂等性。

但是如果真的要解决这个也不是没有办法。



就是执行这样一个操作。设置一个set，当获取到元素，消费之前，检查这个id是不是已经在set里边了，如果是，说明已经有客户端在消费了，将取消本次操作，否则将id放到这个set里边，并且设置合适的过期时间，保证不会因为客户端宕机，这个id无法被再次消费的问题。

这一个操作应该是线程互斥的，同一时间只能有一个客户端的一个线程在执行。可以使用分布式锁协调控制所有的redis客户端，保证只有一个客户端可以进行这一个操作。

这样重复消费的问题就解决了。



> 分布式锁怎么做

分布式锁的实现很简单，就是多个结点去获取同一把锁，保证只有一个结点获取成功，并且处理好死锁问题，以及锁的可靠性问题即可。



可以使用数据库的行锁或者利用数据库做一个乐观锁的机制去保证只有一个结点能够获取到锁。

也可以使用redis单线程的安全性去保证只有一个结点能够获取成功。在redis使用set nx命令可以设置一个锁，nx命令保证了如果key为空才会设置成功，再加上redis是单线程的，就能保证只有一个结点能够得到锁。



死锁问题是因为结点宕机，不释放锁造成的，解决办法就是给key加一个过期时间。如果过期了，redis或者其它线程就能够释放并获取锁。但是结点有可能没有宕机，只是执行时间久，所以还得解决锁的误删问题。使用心跳机制可以解决这个问题，锁快过期了就发送请求给锁的结点，如果它还在使用，就为这个锁延长过期时间。Redission就是基于这个原理，使用守护线程去保持过期时间的有效性，封装了对redis的操作实现了分布式锁。



我使用的是redsson封装的分布式锁。



当然这个锁在单机环境或者主从环境是存在风险的，单机环境有宕机风险，主从环境有脑裂风险。可以使用redlock算法实现一个可靠的分布式锁。设置多个相互独立的主节点，当结点尝试获取锁的时候，向所有的主节点发送加锁请求，只有超过一半的结点加锁成功，才认为分布式锁加锁成功，否则会回退，在已经加锁成功的redis结点释放锁。





> 配置了哪些参数

配置了定时任务的间隔时间，执行任务的线程数量





> Quartz底层实现有了解吗？









### 8、使用springsecurity做了什么，为什么要用，底层实现







### 9、使用docker做了什么，为什么要用，底层实现







### 10、有没有用到事务，为什么要用，底层实现

对一些有写操作的service方法。



redis关注时使用事务



> spring怎么实现事务





> mysql怎么实现事务





### 11、进行了哪些JVM参数的调整







