### 1、用threadlocal做了什么，为什么要用，底层实现

> 做了什么

我有这样一个需求，就是在整个请求的处理过程中，会多次需要到当前用户对象，所以我想在请求处理之前，从数据库把这个对象加载到内存中，交给spring容器，需要的地方直接用注解注入就行，不用每次都创建。



> 为什么要用

一开始我想用session存储，使用session的好处是，同一个用户发的请求，不用每一次都去创建用户对象，直接从session获取就行，不同用户发的请求都从自己的session获取，实现并发隔离。而且使用redis替代session后，在分布式环境下，无论哪个结点来处理请求，都能直接获取创建好的用户对象。



但是有一个问题就是，用户对象是可变的，如果进行了用户资料的修改，需要同步到session或者redis，这就比较麻烦了，同步过程还得解决丢失，并发覆盖等问题。而且用户连续发送的多个请求，可能会出现多个线程同时操作同一个session的情况。这就导致一个请求在处理的过程中，它的用户对象是可能会变的，这个会留下一些隐患。



所以我用threadlocal来解决这个问题，去保证每一个线程执行过程中，它的用户对象信息都不会发生修改。在请求处理之前，使用拦截器从数据库加载对象，放到threadlocal中，整个处理过程使用的都是同一个对象，请求处理结束后手动从threadlocal删除用户对象。



> 实现原理

threadlocal有一个静态内部类ThreadLocalMap，这个Map是实现线程隔离的核心，它是自定义的，没有实现Map接口，用了一个Entry数组来存储threadlocal, value键值对，这个key是threadlocal实例，value是绑定的对象。

每个线程都有自己Map对象，用来存储自己线程的所有thtreadlocal对象和它绑定的对象，所以不会存在并发安全问题。

Map是local类的静态内部类，意味着，同样的线程，即使你有多个threadlocal实例，线程都只有一个Map实例，在这个实例里以threadlocal实例为键，存储对象。



> threadlocalMap解决哈希冲突的方式

处理冲突检测的机制是向后移位, 清除过期条目 最终找到合适的位置



> 为什么结束后要删除用户对象

会，当前线程结束后，当前线程对应的map应该被回收，map里的threadlocal，value都应该被回收，但是如果其它线程保持着对local实例的引用，当前对象的Map会被认定为存活对象，不能被回收，map里的threadlocal，value对也会一直存在。

解决办法就是在当前线程使用完local对象后，手动调用remove方法将其从Map中删除。



### 2、用elasticsearch做了什么，为什么要用，底层实现

> 做了什么

我希望能够对我的帖子进行一个搜素，就是我输入一些关键字，帖子包含这些关键字，或者部分关键字，就应该被搜索到。



> 为什么要用

一开始是使用mysql的like模糊查询做的搜索。

但是这样限制很多，首先是索引会失效，走全表扫描效率很低，再有就是不能做复杂的查询，比如我只需要包含关键词的一部分，模糊查询就做不到。

于是想到使用全文索引来做这个功能，mysql本身也支持全文索引，但是建立多个字段的全文索引会占用大量的磁盘空间，而且做复杂查询的时候会比较吃力。

es是专门做全文检索的，使用倒排索引来检索关键词，直接得到包含关键词的文档列表。它支持分布式的存储和搜索，将数据做了分片，存储到不同的结点；支持更高级的分词算法和匹配算法，在做复杂查询合海量数据查询的时候性能较好。



> es底层原理

主要是通过分区存储数据，以及通过分词算法切分关键词，然后通过倒排索引高校检索数据。



> 怎么做的搜索

首先配置好es服务器，将mysql的帖子数据存储到es中，并且在数据发生增删改的时候，同步到es服务器。

之后就是构建一个查询请求，向es发送查询请求，获取搜索的结果。



> 数据同步是怎么做的

mysql到es的数据同步方式有几种。

第一种是双写，有同步和异步的方式，同步就是在修改时同时写入es，异步就是发送到mq进行消费。双写策略需要耦合业务代码，而且需要自己处理同步失败的情况。

第二种是基于binlog订阅，binlog就是用来做主从同步的，通过第三方组件模拟为从节点，对mysql发起同步请求，然后将binlog回放，写到es。比如Canal，这种方式比较简单省事，而且海量数据同步效率也高。

第三种是基于sql查询做的数据抽取，通过第三方组件定时查询mysql，找到增量修改的数据，同步到es。比如logstash，这种方式需要增加修改时间的字段，ogstash会保存每一次查询的最后修改时间，通过实践判断哪个记录是新增的。



我使用的是canal做的数据同步。首先是开启mysql的binlog功能，然后安装canal服务器，配置数据库的连接，以及es客户端的连接参数，以及es和mysql表的映射关系。之后保持canal的运行就能实现数据同步。





> 查询请求是怎么样构建的

首先得执行GTE请求，然后是需要查询的索引，然后构建一个query请求体，在请求体中配置查询的模式，比如match，或者term，然后配置查询的字段以及响应的关键词，最后就是一些条件的配置，比如分组，排序，过滤，分页等等。





> es是怎么检索一个关键词的

解析查询请求：Elasticsearch会解析接收到的搜索请求，提取其中的索引名称、查询条件、排序规则等信息。

查询路由和分片选择：根据索引名称和查询条件，Elasticsearch确定要在哪些分片上执行查询操作。如果查询请求没有指定特定的分片，则会在索引中的所有分片上执行查询。

倒排索引搜索：Elasticsearch使用倒排索引来加速搜索过程。倒排索引是根据每个唯一词项（terms）建立的数据结构，记录了该词项在哪些文档中出现。根据查询条件中的关键词，在倒排索引中找到匹配的词项，进而找到对应的文档。

结果打分和排序：Elasticsearch对于每个匹配的文档进行打分，根据打分结果对文档进行排序。默认情况下，Elasticsearch使用TF-IDF（词频-逆向文档频率）算法来计算文档的相关性得分，也可以根据需要使用其他自定义的打分算法。

结果返回：根据用户的设定，Elasticsearch将搜索结果返回给用户。搜索结果通常包括匹配的文档、相关性得分以及任何附加的聚合结果。



> 倒排索引的原理是什么

倒排索引可以实现从词语到文档的映射。它由两部分组成：词典和倒排列表。

倒排索引将文档集合中的每个词语与包含该词语的文档列表关联起来。

词典是由所有不重复的词语构成的数据结构，用于存储词语及其对应的倒排列表的位置信息。

倒排列表则记录了包含该词语的文档的详细信息，如文档的编号、出现的位置等。



> 分词的原理是什么

分词器就是把一个短语通过一些分词算法拆分成语义独立的词语的一个组件。这些词语将作为倒排索引的字典。

分词器除了进行分词的操作，还会有一些别的处理，比如对分词后的词语做一个过滤，或者一些大写小写转化，以及更进一步的分词处理。

常见的分词算法有几种类型，一种是基于字典的，对短语做匹配，匹配成功后作为一个词语，并接着进行匹配。

也可以基于语法规则对短语做切分，根据语法，语义，词性等规则做切分。也可以基于深度学习算法，根据大量的数据训练来学习如何做拆分。



> es是怎么存储一条记录的

首先根据路由策略确定该数据应该路由到索引的哪个分片中。路由策略可以自定义，或者根据某个字段的值做区分。

把数据写入分片的缓冲区中，生成文档ID等信息以及倒排索引等数据，然后定期从缓冲区把数据刷到磁盘。



> term和match的区别

Term 查询是一种精确匹配的查询，它在搜索时不会对关键词进行分词处理。

Match 查询： Match 查询是一种通过分词来进行全文搜索的查询方式。它会对搜索条件进行分词，并将分词后的词项与索引中的词项进行匹配。

 

### 3、用Kafka做了什么，为什么要用，底层实现

> 做了什么

当发生点赞，关注和评论事件的时候，需要给关联的用户发送一条系统通知。我使用了异步执行的机制，就是先将这个事件发送给Kafka，再进行消费，把通知写入到数据库。

在注册账号的时候，有一个邮箱激活的需求，需要给指定邮箱发送一个激活邮件，这个发送的操作非常的耗时，会导致前端界面一直在转圈圈，所以我把这个发的动作发送到了Kafka，异步的执行发邮件的动作。



> 为什么用Kafka

Kafka可以处理大规模的实时数据流，拥有非常高的吞吐量和低延迟。

Kafka将所有消息持久化到磁盘上，因此不会因为消费者的速度慢或者宕机导致数据丢失，提高数据可靠性。

Kafka采用分布式架构，可以在多个服务器上进行水平扩展。将topic的数据存储到不同结点的分区上。而且还建立了副本存储数据，不会因为结点的宕机产生数据丢失的问题。

Kafka支持发布订阅模式，消费者可以订阅感兴趣的主题并实时接收消息，多个消费者组可以并行的消费同一个topic的不同分区。





> kafka底层原理、为什么吞吐量高

存储：Kafka使用持久化日志的方式来存储消息，基于顺序写和随机读的特性，以及磁盘顺序读写的高效性

副本：Kafka采用分布式的多副本机制，将主题的分区数据复制到多个Broker上。这样的设计不仅提高了数据的可靠性，还允许通过增加Broker节点来水平扩展整个系统的吞吐量和容量。

批量：Kafka支持批量处理消息，即生产者可以将多条消息批量发送到Broker。这种批量处理减少了网络开销和磁盘IO，提高了生产者和消费者的效率。同时，Kafka还支持消息的压缩，可以减小网络传输的数据量，节省带宽和存储空间。

消费：Kafka引入了消费者组的概念，组内的消费者可以同时处理多个分区的消息，实现了消息的并行处理和负载均衡。

Kafka提供了灵活的分区分配策略，确保分区在消费者组内均匀分布，以及在消费者加入或退出时自动进行重新分配。



> kafka消息丢失怎么解决

Kafka的消息丢失问题可能会发生在Broker、Producer和Consumer三种中的任意一种。

Broker消息丢失是因为采用异步批量的刷盘策略，宕机会丢失一部分数据，解决的办法就是同步刷盘。

producer消息丢失是因为采用异步发送的方式，没等Kafka确认就认为发送成功，解决办法就是改成同步发送，或者设置一定的重传次数。

consumer丢失数据是因为分区offset的提交是在消费之前，提交后没来得及消费就宕机了，解决办法就是改成消费消息之后再提交offset。



> kafka重复消费怎么解决

重复消费是由于offset提交的时候宕机了，Kafka把分区交给其它消费者进行消费。



> kafka顺序消费怎么实现

kafka每个partition中的消息在写入时都是有序的，消费时，每个partition只能被每一个group中的一个消费者消费，保证了消费时也是有序的。

整个topic不保证有序。如果为了保证topic整个有序，那么将partition调整为1.







### 4、用caffeine做了什么，为什么要用，底层实现

> 做了什么

我在首页会展示一页的帖子，在操作的过程中，会频繁的访问首页，需要不断的查询数据库，帖子的信息是很少会改变的，所以我想使用一个本地缓存来保存首页展示的帖子。直接从缓存中获取，不需要每次都查库。



> 为什么用caffeine

直接使用map也能实现简单的缓存效果，但是得单独做过期时间，过期之后再次访问还要重新加载，而且在并发环境下加载，有可能会出现线程安全的问题。

caffeine可以配置过期时间和过期策略，可以使用手动或者异步的方式加载数据，并且使用了分段锁保证并发环境下的线程安全问题，而且caffeine还提供了一些监控和统计的功能。

如果数据已经过期，会从redis重新加载数据，redis作为一个集中缓存，可以解决分布式共享的问题。



> caffeine底层是怎么实现的

Caffeine 使用了一种类似于哈希表的数据结构。它是一个线程安全的哈希表，采用分段锁的方式来提高并发性能。每个 不同的段可以被不同的线程同时访问，增加了并发度。

使用堆外内存来存储缓存数据，自己实现内存池，内存管理器来做内存分配和释放，减轻 Java 堆内存的压力，提高 GC 性能，并且通过跳表等数据结构来实现缓存数据的排序等操作。



> 堆外内存有什么不同

堆外内存绕过JVM直接使用操作系统提供的内存空间，不受JVM堆内存管理。

可以提供更大的内存空间，访问速度快，不受JVM的影响

但是需要自己管理内存的分配和释放等问题。





### 5、用redis做了什么，为什么要用，底层实现

作为数据库存储了点赞，关注信息，以及DAU和UV的统计信息，以及登录的时候保存登录状态信息还有验证码信息等，作为一个临时的缓存。





### 6、用线程池做了什么，线程池有哪些参数

查找所有帖子的时候，使用线程池并发的查找每一个帖子关联的评论，使用concurrentMap聚合起来。







### 7、用Quartz做了什么，为什么要用，底层实现

帖子热度计算，不能点赞一个算一次，而是定时去计算，更新。

也不是每次都更新所有的帖子，有事件发生的帖子才需要更新



配置化开发，可以配置作业的参数、并发性、持久化等属性，支持支持在集群环境下进行作业调度







### 8、使用springsecurity做了什么，为什么要用，底层实现







### 9、使用docker做了什么，为什么要用，底层实现







### 10、有没有用到事务，为什么要用，底层实现

对一些有写操作的service方法。



> spring怎么实现事务





> mysql怎么实现事务





### 11、进行了哪些JVM参数的调整







