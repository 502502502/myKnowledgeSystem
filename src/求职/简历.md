



## 1、说一下HashMap

> 底层数据结构

在JDK1.7 中，由“数组+链表”组成，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的。

在JDK1.8 中，由“数组+链表+红黑树”组成。当链表过长，则会严重影响 HashMap 的性能，红黑树搜索时间复杂度是 O(logn)，而链表是糟糕的 O(n)。因此，JDK1.8 对数据结构做了进一步的优化，引入了红黑树，链表和红黑树在达到一定条件会进行转换：

- 当链表超过 8 且数据总量超过 64 才会转红黑树。
- 将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树，以减少搜索时间。

> 为什么在解决 hash 冲突的时候，不直接用红黑树？而选择先用链表，再转红黑树?

因为红黑树需要进行左旋，右旋，变色这些操作来保持平衡，而单链表不需要。当元素小于 8 个的时候，此时做查询操作，链表结构已经能保证查询性能。当元素大于 8 个的时候， 红黑树搜索时间复杂度是 O(logn)，而链表是 O(n)，此时需要红黑树来加快查询速度，但是新增节点的效率变慢了。

因此，如果一开始就用红黑树结构，元素太少，新增效率又比较慢，无疑这是浪费性能的

> 用二叉查找树可以么?

可以。但是二叉查找树在特殊情况下会变成一条线性结构（这就跟原来使用链表结构一样了，造成很深的问题），遍历查找会非常慢。

> 为什么链表改为红黑树的阈值是 8?

链表中元素个数为 8 时的概率已经非常小，再多的就更少了，是根据概率统计而选择的。

> 说说负载因子

HashMap的负载因子是指哈希表中元素的数量与哈希表容量的比值。在Java中，HashMap的默认负载因子是0.75，也就是说，当哈希表中元素的数量达到了容量的3/4时，就会进行自动扩容。

在数组定义好长度之后，负载因子越大，所能容纳的键值对个数越多

默认负载因子（0.75）在时间和空间成本上提供了很好的折衷。较高的值会降低空间开销，但提高查找成本（体现在大多数的HashMap类的操作，包括get和put）

> HashMap 中 key 的存储索引是怎么计算的？

首先根据key的值计算出hashcode的值，然后根据hashcode计算出hash值，最后通过hash&（length-1）计算得到存储的位置。

> JDK1.8 为什么要 hashcode 异或其右移十六位的值？

因为后边需要和数组长度-1进行于运算，可以在数组的 length 比较小的时候，也能保证考虑到高位Bit都参与到Hash的计算中，同时不会有太大的开销。

> 为什么 hash 值要与length-1相与？

- 把 hash 值对数组长度取模运算，模运算的消耗很大，没有位运算快。
- 当 length 总是 2 的n次方时，h& (length-1) 运算等价于对length取模，也就是 h%length，但是 & 比 % 具有更高的效率。

> HashMap数组的长度为什么是 2 的幂次方？

这样做效果上等同于取模，在速度、效率上比直接取模要快得多。除此之外，2 的 N 次幂有助于减少碰撞的几率。如果 length 为2的幂次方，则 length-1 转化为二进制必定是11111……的形式，在与h的二进制与操作效率会非常的快，而且空间不浪费，如果不是2的幂次方，减掉1后最后一位为0的可能性会很大，导致做完与运算后，最后一位都是0，加大了位置碰撞的概率。

> 数组容量计算

HashMap 构造函数允许用户传入的容量不是 2 的 n 次方，因为它可以自动地将传入的容量转换为 2 的 n 次方

```java
static final int tableSizeFor(int cap) {
        int n = cap - 1;
    	//将最高有效位以及后边都变成1
        n |= n >>> 1;
        n |= n >>> 2;
        n |= n >>> 4;
        n |= n >>> 8;
        n |= n >>> 16;
    	//加1即可
        return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
    }
/*
解释：位或( | )
int n = cap - 1;　让cap-1再赋值给n的目的是另找到的目标值大于或等于原值。例如二进制1000，十进制数值为8。如果不对它减1而直接操作，将得到答案10000，即16。显然不是结果。减1后二进制为111，再进行操作则会得到原来的数值1000，即8。
*/
```

> HashMap 的put方法流程？

1. 首先根据 key 的值计算 hash 值，找到该元素在数组中存储的下标；
2. 如果数组是空的，则调用 resize 进行初始化；
3. 如果没有哈希冲突直接放在对应的数组下标里；
4. 如果冲突了，且 key 已经存在，就覆盖掉 value；
5. 如果冲突后，发现该节点是红黑树，就将这个节点挂在树上；
6. 如果冲突后是链表，判断该链表是否大于 8 ，如果大于 8 并且数组容量小于 64，就进行扩容；如果链表节点大于 8 并且数组的容量大于 64，则将这个结构转换为红黑树；否则，链表插入键值对，若 key 存在，就覆盖掉 value。

> HashMap 的扩容方式？

Hashmap 在容量超过负载因子所定义的容量之后，就会扩容。Java 里的数组是无法自动扩容的，方法是将 Hashmap 的大小扩大为原来数组的两倍，并将原来的对象放入新的数组中。

JDK1.7 重新计算每个元素在数组中的位置，使用了单链表的头插入方式解决冲突

JDK1.8resize 之后，元素的位置在原来的位置，或者原来的位置 +oldCap (原来哈希表的长度），只需要看看原来的 hash 值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引 + oldCap ”，使用尾插解决冲突。

> 还知道哪些hash算法？

Hash函数是指把一个大范围映射到一个小范围，目的往往是为了节省空间，使得数据容易保存。 比较出名的有MurmurHash、MD4、MD5等等。

> key 可以为 Null 吗?

可以，key 为 Null 的时候，hash算法最后的值以0来计算，也就是放在数组的第一个位置。

> 一般用什么作为HashMap的key?

一般用Integer、String 这种不可变类当 HashMap 当 key，而且 String 最为常用。

- 因为字符串是不可变的，所以在它创建的时候 hashcode 就被缓存了，不需要重新计算。这就是 HashMap 中的键往往都使用字符串的原因。
- 因为获取对象的时候要用到 equals() 和 hashCode() 方法，那么键对象正确的重写这两个方法是非常重要的,这些类已经很规范的重写了 hashCode() 以及 equals() 方法。

> 用可变类当 HashMap 的 key 有什么问题?

hashcode 可能发生改变，导致 put 进去的值，无法 get 出

> HashMap的线程安全问题

**多线程下扩容死循环**

JDK1.7中的 HashMap 使用头插法插入元素，在多线程的环境下，扩容的时候有可能导致环形链表的出现，形成死循环

**多线程的put可能导致元素的丢失**

多线程同时执行 put 操作，如果计算出来的索引位置是相同的，那会造成前一个 key 被后一个 key 覆盖，从而导致元素的丢失。

**put和get并发时，可能导致get为null	**

线程1执行put时，因为元素个数超出threshold而导致rehash，线程2此时执行get，有可能导致这个问题。	



## 2、说一下ConcurrentHashMap

> ConcurrentHashMap 的实现原理是什么？

JDK1.7 中的 ConcurrentHashMap 是由 `Segment` 数组结构和 `HashEntry` 数组结构组成，即 ConcurrentHashMap 把哈希桶数组切分成小数组（Segment ），每个小数组有 n 个 HashEntry 组成。将数据分为一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一段数据时，其他段的数据也能被其他线程访问，实现了真正的并发访问。

用 volatile 修饰了 HashEntry 的数据 value 和 下一个节点 next，保证了多线程环境下数据获取时的**可见性**！



DK1.8 中的ConcurrentHashMap 选择了与 HashMap 相同的**Node数组+链表+红黑树**结构；在锁的实现上，抛弃了原有的 Segment 分段锁，采用` CAS + synchronized`实现更加细粒度的锁。

将锁的级别控制在了更细粒度的哈希桶数组元素级别，也就是说只需要锁住这个链表头节点（红黑树的根节点），就不会影响其他的哈希桶数组元素的读写，大大提高了并发度。

> JDK1.8 中为什么使用内置锁 synchronized替换 可重入锁 ReentrantLock？

- 在 JDK1.6 中，对 synchronized 锁的实现引入了大量的优化，并且 synchronized 有多种锁状态，会从无锁 -> 偏向锁 -> 轻量级锁 -> 重量级锁一步步转换。
- 减少内存开销 。假设使用可重入锁来获得同步支持，那么每个节点都需要通过继承 AQS 来获得同步支持。但并不是每个节点都需要获得同步支持的，只有链表的头节点（红黑树的根节点）需要同步，这无疑带来了巨大内存浪费。

> ConcurrentHashMap 的 put 方法执行逻辑是什么

JDK1.7首先会尝试获取锁，如果获取失败肯定就有其他线程存在竞争，则利用 `scanAndLockForPut()` 自旋获取锁。

1. 尝试自旋获取锁。
2. 如果重试的次数达到了 `MAX_SCAN_RETRIES` 则改为阻塞锁获取，保证能获取成功。



JDK1.8

1. 根据 key 计算出 hash 值；
2. 判断是否需要进行初始化；
3. 定位到 Node，拿到首节点 f，判断首节点 f：
   - 如果为 null ，则通过 CAS 的方式尝试添加；
   - 如果为 `f.hash = MOVED = -1` ，说明其他线程在扩容，参与一起扩容；
   - 如果都不满足 ，synchronized 锁住 f 节点，判断是链表还是红黑树，遍历插入；
4. 当在链表长度达到 8 的时候，数组扩容或者将链表转换为红黑树。

> ConcurrentHashMap 的 get 方法执行逻辑是什么？

**JDK1.7**

1、根据 key 计算出 hash 值定位到具体的 Segment 

2、再根据 hash 值获取定位 HashEntry 对象，并对 HashEntry 对象进行链表遍历，找到对应元素。

3、 HashEntry 涉及到的共享变量都使用 volatile 修饰，volatile 可以保证内存可见性，所以每次获取时都是最新值。

**JDK1.8**

1. 根据 key 计算出 hash 值，判断数组是否为空；
2. 如果是首节点，就直接返回；
3. 如果是红黑树结构，就从红黑树里面查询；
4. 如果是链表结构，循环遍历判断。

> ConcurrentHashMap 的 get 方法是否要加锁，为什么？

get 方法不需要加锁。因为 Node 的元素 value 和指针 next 是用 volatile 修饰的，在多线程环境下线程A修改节点的 value 或者新增节点的时候是对线程B可见的。

> get 方法不需要加锁与 volatile 修饰的哈希桶数组有关吗？

没有关系。哈希桶数组`table`用 volatile 修饰主要是保证在数组扩容的时候保证可见性。

> ConcurrentHashMap 不支持 key 或者 value 为 null 的原因？★★★

 ConcurrentHashMap 是用于多线程的 ，如果`ConcurrentHashMap.get(key)`得到了 null ，这就无法判断，是映射的value是 null ，还是没有找到对应的key而为 null ，就有了二义性。因为单线程的时候，可以通过containsKey()判断是不是key，多线程由于是两步操作，在判断和取值时有其它的线程突然增加了null的key，会改变原来线程期望的结果。

> ConcurrentHashMap 的并发度是什么？

JDK1.7中，实际上就是ConcurrentHashMap中的分段锁个数，即Segment[]的数组长度，默认是16，这个值可以在构造函数中设置。

JDK1.8中，已经摒弃了Segment的概念，选择了Node数组+链表+红黑树结构，并发度大小依赖于数组的大小。

> ConcurrentHashMap 迭代器是强一致性还是弱一致性？

与 HashMap 迭代器是强一致性不同，ConcurrentHashMap 迭代器是弱一致性。

ConcurrentHashMap 的迭代器创建后，就会按照哈希表结构遍历每个元素，但在遍历过程中，内部元素可能会发生变化，如果变化发生在已遍历过的部分，迭代器就不会反映出来，而如果变化发生在未遍历过的部分，迭代器就会发现并反映出来，这就是弱一致性。

> JDK1.7 与 JDK1.8 中ConcurrentHashMap 的区别？

- 数据结构：取消了 Segment 分段锁的数据结构，取而代之的是数组+链表+红黑树的结构。
- 保证线程安全机制：JDK1.7 采用 Segment 的分段锁机制实现线程安全，其中 Segment 继承自 ReentrantLock 。JDK1.8 采用`CAS+synchronized `保证线程安全。
- 锁的粒度：JDK1.7 是对需要进行数据操作的 Segment 加锁，JDK1.8 调整为对每个数组元素加锁（Node）。
- 链表转化为红黑树：定位节点的 hash 算法简化会带来弊端，hash 冲突加剧，因此在链表节点数量大于 8（且数据总量大于等于 64）时，会将链表转化为红黑树进行存储。
- 查询时间复杂度：从 JDK1.7的遍历链表O(n)， JDK1.8 变成遍历红黑树O(logN)。

> ConcurrentHashMap 和 Hashtable 的效率哪个更高？为什么？

ConcurrentHashMap 的效率要高于 Hashtable，因为 Hashtable 给整个哈希表加了一把大锁从而实现线程安全。而ConcurrentHashMap 的锁粒度更低，在 JDK1.7 中采用分段锁实现线程安全，在 JDK1.8 中采用`CAS+synchronized`实现线程安全

> 具体说一下Hashtable的锁机制

Hashtable 是使用 synchronized来实现线程安全的，给整个哈希表加了一把大锁，多线程访问时候，只要有一个线程访问或操作该对象，那其他线程只能阻塞等待需要的锁被释放

> 多线程下安全的操作 map还有其他方法吗？

可以使用`Collections.synchronizedMap`方法，对方法进行加同步锁,本质也是对 HashMap 进行全表锁,在竞争激烈的多线程环境下性能依然也非常差.。



## 3、说一下ArrayList

ArrayList是Java中的一个类，是一个动态数组，实现了List接口，主要用来存储数据。如果存储基本类型的数据，如int，long，boolean，short，byte，那只存储它们对应的包装类。ArrayList提供了相关的添加、删除、修改、遍历等功能。

> 底层

使用Object[]数组存储元素

> 线程安全

不具备线程安全

> 特点

支持随机存取，可以通过下标获取元素，查找快；

插入和删除复杂度为O(n)、

> 扩容机制

ArrayList初始化时并不分配容量。而是第一次存入元素才扩充容量；

当剩余容量不足以容纳存储元素时，会进行扩容；

首先尝试将容量扩充到原来的1.5倍；

如果1.5倍不够存，直接使用最小满足的容量作为新容量；

如果1.51倍够了，再检查是否大于最大存储容量；

如果没有大于，就用1.51倍作为新的容量，否则比较最大容量和最小满足的容量；

如果最小需要容量大于最大容量，选取Integer的最大值作为新容量，否则选择最大容量作为新容量；



## 4、说一下反射

反射在运行时获取类的方法、属性和构造函数等信息，并且可以通过反射机制在运行时调用对象的方法或者操作对象的属性。

> 关键类

Class类：代表一个类或者接口，在运行时获取类的构造方法、方法、字段等信息。

Constructor类：代表一个类的构造方法，在运行时获取构造方法的信息，并能够使用构造方法创建新的对象。

Method类：代表类的方法，在运行时获取方法信息，并能够使用方法调用类的实例方法。

> 应用场景

动态代理：Java反射机制可以用于创建动态代理对象，使得代理对象在运行时可以动态地调用被代理对象的方法。

插件化开发：Java反射机制可以用于插件化开发，使得应用程序在运行时可以动态地加载并使用插件。

注解处理器：Java反射机制可以用于注解处理器，使得程序在运行时可以动态地获取注解信息，并且根据注解信息完成相应的操作。

> 获取Class对象

使用类的class属性，如String.class； 

调用对象的getClass()方法，如new String().getClass()；

使用Class类的forName()静态方法，如Class.forName("java.lang.String")。

>  如何创建一个对象并调用它的方法

获取类的Class对象； 

获取类的构造函数；

使用构造函数创建对象； 

获取类的方法； 

使用对象调用方法。

> 反射机制对程序的性能有什么影响？

反射机制的性能比直接调用方法要差，因为它需要在运行时获取类信息，并且需要进行类型转换等操作



## 5、说一下垃圾回收机制

> 判断对象是否存活

JVM使用可达性分析算法来判断对象是否存活。该算法基于以下的假设：

- 一个对象可以被作为GC Root对象，如果它被直接引用或被间接引用（比如作为某个引用对象的字段）。
- 从一个GC Root对象开始，沿着对象引用链进行遍历，能够到达的所有对象都是存活的，反之则是垃圾对象。

当JVM执行垃圾回收时，它会从一组GC Root对象开始，通过可达性分析算法来确定哪些对象是存活的。它会遍历所有可达对象，并标记它们。然后，它会清除所有未被标记的对象。

JVM会从以下三个GC Root对象开始进行可达性分析：

1. 虚拟机栈（栈帧中的本地变量表）中引用的对象。
2. 方法区中类静态属性引用的对象。
3. 方法区中常量引用的对象。

> 引用分类

1. 强引用（Strong Reference）：最普通的引用类型，如果一个对象具有强引用，那么它就不会被垃圾回收器回收。只有当对象的所有强引用都被释放时，对象才会被回收。
2. 软引用（Soft Reference）：如果一个对象只具有软引用，那么在内存不足时，这个对象就会被垃圾回收器回收。可以通过java.lang.ref.SoftReference类来创建软引用。
3. 弱引用（Weak Reference）：如果一个对象只具有弱引用，那么它会被垃圾回收器回收，不管内存是否充足。可以通过java.lang.ref.WeakReference类来创建弱引用。

除了这三种引用类型之外，还有一种虚引用（Phantom Reference），它用于在对象被回收之前执行一些清理工作。虚引用不能单独使用，必须与引用队列（ReferenceQueue）一起使用。

> 垃圾回收算法

1. 标记-清除算法（Mark-and-Sweep Algorithm）：该算法会在堆内存中遍历所有对象，并标记所有可达对象。然后，清除未被标记的对象，释放空间。
2. 复制算法（Copying Algorithm）：该算法将内存分为两个区域，每次只使用其中一个区域。当一个区域的空间用尽时，将所有可达对象复制到另一个区域中，并清除之前的区域。
3. 标记-整理算法（Mark-and-Compact Algorithm）：该算法会在堆内存中遍历所有对象，并标记所有可达对象。然后，将所有可达对象移动到内存的一端，未被标记的对象移动到内存的另一端，以便为新对象腾出更大的空间。
4. 分代收集算法（Generational Garbage Collection）：该算法将内存分为多个代，每个代包含不同年龄的对象。新创建的对象通常会放入第一代，随着时间的推移，对象会被转移到更老的代。垃圾收集器会优先清理年轻代中的垃圾，因为它们的生命周期更短。
5. 引用计数算法（Reference Counting Algorithm）：该算法会跟踪每个对象的引用计数，当一个对象的引用计数降为零时，该对象将被回收。但是，该算法无法处理循环引用的情况，因为循环引用会导致对象的引用计数永远不为零。

> 垃圾回收器

JVM中的垃圾回收器有多种类型，包括：

1. Serial垃圾回收器：这是一种最古老、最简单的垃圾回收器。它使用单个线程进行垃圾回收操作，只有在停止所有应用线程的情况下才能进行垃圾回收。
2. Parallel垃圾回收器：这种垃圾回收器使用多个线程进行垃圾回收，以提高垃圾回收的效率。它也需要在停止应用程序的情况下进行垃圾回收。
3. CMS垃圾回收器：CMS（Concurrent Mark Sweep）是一种并发的垃圾回收器，它可以在应用程序运行的同时进行垃圾回收。它使用多个线程来标记和清除垃圾对象，从而避免了应用程序停顿的情况。
4. G1垃圾回收器：G1（Garbage First）是一种面向服务端应用的垃圾回收器，它能够在不停顿应用程序的情况下回收大量的堆内存。它使用分代收集算法，并将堆内存划分为多个区域来进行垃圾回收。

> 空间担保原则

在执行每次 YoungGC 之前，JVM会先检查**老年代最大可用连续空间是否大于新生代所有对象的总大小**。

因为在极端情况下，可能新生代 YoungGC 后，所有对象都存活下来了，而 survivor 区又放不下，那可能所有对象都要进入老年代了。这个时候如果老年代的可用连续空间是大于新生代所有对象的总大小的，那就可以放心进行 YoungGC。

但如果老年代的内存大小是小于新生代对象总大小的，那就有可能老年代空间不够放入新生代所有存活对象，

这个时候JVM就会先检查 -XX:HandlePromotionFailure 参数是否允许担保失败，如果允许，就会判断老年代最大可用连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试进行一次YoungGC，尽快这次YoungGC是有风险的。

如果小于，或者 -XX:HandlePromotionFailure 参数不允许担保失败，这时就会进行一次 Full GC。

在允许担保失败并尝试进行YoungGC后，可能会出现三种情况：

- ① YoungGC后，存活对象小于survivor大小，此时存活对象进入survivor区中
- ② YoungGC后，存活对象大于survivor大小，但是小于老年大可用空间大小，此时直接进入老年代。
- ③ YoungGC后，存活对象大于survivor大小，也大于老年大可用空间大小，老年代也放不下这些对象了，此时就会发生“Handle Promotion Failure”，就触发了 Full GC。如果 Full GC后，老年代还是没有足够的空间，此时就会发生OOM内存溢出了

> CMS过程

CMS的回收过程是指CMS垃圾回收器对老年代的垃圾回收过程。CMS是一种以牺牲吞吐量为代价来获得最短回收停顿时间的垃圾回收器，适合对响应速度要求高的应用。CMS的回收过程大致分为以下几个步骤：

- 初始标记：这个阶段会暂停虚拟机，从根对象开始，只扫描和根对象直接关联的对象，并作标记。
- 并发标记：这个阶段和应用程序线程并发执行，从初始标记的结果继续向下追溯标记可达对象。
- 并发预清理：这个阶段也是和应用程序线程并发执行，查找在并发标记阶段新进入老年代的对象，并重新扫描，减少下一个阶段的工作量。
- 重新标记：第 2 步并没有阻塞其它工作线程，其它线程在标识过程中，很有可能会产生新的垃圾，需要重新标记一次
- 并发清理：这个阶段和应用程序线程并发执行，清理垃圾对象。
- 并发重置：这个阶段也是和应用程序线程并发执行，重置CMS收集器的数据结构，等待下一次垃圾回收。



CMS的回收过程有以下几个缺点

- CMS不会整理、压缩堆空间，会产生空间碎片，降低堆空间的利用率。
- CMS需要更多的CPU资源，因为它和应用程序线程并发执行，并且在重新标记阶段需要占用所有的CPU资源。
- CMS需要更大的堆空间，因为它不会在老年代满的时候才开始回收，而是提前开始回收，以避免在回收完成之前，堆没有足够空间分配。

> G1过程

G1的回收过程是指G1垃圾回收器对堆内存的垃圾回收过程。G1是一种以获取可预测的停顿时间为目标的垃圾回收器，适合对响应速度要求高的应用¹。G1的回收过程大致分为以下几个步骤¹²：

- 初始标记：这个阶段会暂停虚拟机，从根对象开始，只扫描和根对象直接关联的对象，并作标记。这个阶段也会标记一些老年代中的区域（Region）作为混合回收的候选。
- 并发标记：这个阶段和应用程序线程并发执行，从初始标记的结果继续向下追溯标记可达对象。这个阶段会记录在标记过程中被修改过的对象。
- 最终标记：这个阶段会暂停虚拟机，处理并发标记期间遗漏的对象，并更新老年代区域的回收优先级。
- 筛选回收：这个阶段会暂停虚拟机，根据用户设定的停顿时间和回收价值，选择一部分区域进行回收。这个阶段会回收新生代区域和一些老年代区域，称为混合回收

> G1和CMS区别

CMS和G1是两种不同的垃圾回收器，它们都是以获取最短回收停顿时间为目标的，但是有以下几点区别¹²：

- CMS是基于标记-清除算法的，会产生内存碎片，而G1是基于标记-整理算法的，不会产生内存碎片。
- CMS只作用于老年代，而G1可以同时作用于新生代和老年代。
- CMS将堆分为连续的新生代和老年代，而G1将堆分为多个大小相等的区域（Region），每个区域可以属于新生代或老年代。
- CMS在并发标记和并发清理阶段需要占用一部分CPU资源，而G1在并发标记阶段不占用CPU资源，在筛选回收阶段可以控制回收的区域数量。
- CMS无法处理浮动垃圾，可能会导致Concurrent Mode Failure，而G1可以处理浮动垃圾，并且有预留内存空间来避免内存不足的情况。
- CMS在重新标记阶段使用单线程进行扫描，而G1在重新标记阶段使用多线程进行扫描，可以缩短停顿时间。
- G1可以预测停顿时间，并根据用户设定的停顿时间模型来制定回收计划，而CMS无法做到这一点。

> 对象在堆的转化过程

- 对象优先在Eden分配。当 eden 区没有足够空间进行分配时，虚拟机将发起一次 Minor GC。

  - 在 Eden 区执行了第一次 GC 之后，存活的对象会被移动到其中一个 Survivor 分区；
  - Eden 区再次 GC，这时会采用复制算法，将 Eden 和 from 区一起清理，存活的对象会被复制到 to 区；
  - 移动一次，对象年龄加 1。
  - 如果对象的年龄达到了MaxTenuringThreshold参数指定的值（默认为15），则对象直接晋升到老年代。
  - 如果对象的年龄小于MaxTenuringThreshold参数指定的值，但是Survivor空间中相同年龄所有对象的大小总和大于Survivor空间的一半（可以通过TargetSurvivorRatio参数设置，默认为50%），则年龄大于或等于该年龄的对象直接晋升到老年代。
  - Survivor 区内存不足会发生担保分配，超过指定大小的对象可以直接进入老年代。

- 大对象直接进入老年代，大对象就是需要大量连续内存空间的对象（比如：字符串、数组），为了避免为大对象分配内存时由于分配担保机制带来的复制而降低效率。

- 老年代满了而**无法容纳更多的对象**，Minor GC 之后通常就会进行Full GC，Full GC 清理整个内存堆 – **包括年轻代和老年代**。

> Minor Gc 和Full Gc 有什么区别

- Minor GC是指对年轻代（Young Generation）的垃圾回收，也叫做新生代GC。年轻代是所有新创建的对象的存放区域，当年轻代空间被占满时，就会触发Minor GC，将存活的对象转移到Survivor区或者老年代（Old Generation），并清理掉死亡的对象。Minor GC通常发生得比较频繁，但是回收速度比较快。
- Full GC是指对整个堆（Heap）的垃圾回收，也叫做老年代GC或者Major GC。整个堆包括年轻代、老年代和元空间（Metaspace）。老年代是存放长期存活的对象的区域，当老年代空间被占满时，就会触发Full GC，将存活的对象进行压缩或者移动，并清理掉死亡的对象。Full GC通常发生得比较少，但是回收速度比较慢，并且会导致应用停顿（Stop The World）。

不同的垃圾回收器（Garbage Collector）可能有不同的实现细节和策略，但是基本上都遵循这两种类型的垃圾回收。



## 6、说一下Iterator

> Iterator 和 ListIterator 有什么区别？

- 遍历。使用Iterator，可以遍历所有集合，如Map，List，Set；但只能在向前方向上遍历集合中的元素。

使用ListIterator，只能遍历List实现的对象，但可以向前和向后遍历集合中的元素。

- 添加元素。Iterator无法向集合中添加元素；而，ListIteror可以向集合添加元素。
- 修改元素。Iterator无法修改集合中的元素；而，ListIterator可以使用set()修改集合中的元素。
- 索引。Iterator无法获取集合中元素的索引；而，使用ListIterator，可以获取集合中元素的索引。

> 讲一讲快速失败(fail-fast)和安全失败(fail-safe)

**快速失败（fail—fast）**

- 在用迭代器遍历一个集合对象时，如果遍历过程中对集合对象的内容进行了修改（增加、删除、修改），则会抛出Concurrent Modification Exception。
- 原理：迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 modCount 变量。集合在被遍历期间如果内容发生变化，就会改变modCount的值。每当迭代器使用hashNext()/next()遍历下一个元素之前，都会检测modCount变量是否为expectedmodCount值，是的话就返回遍历；否则抛出异常，终止遍历。
- 注意：这里异常的抛出条件是检测到 modCount！=expectedmodCount 这个条件。如果集合发生变化时修改modCount值刚好又设置为了expectedmodCount值，则异常不会抛出。因此，不能依赖于这个异常是否抛出而进行并发操作的编程，这个异常只建议用于检测并发修改的bug。
- 场景：java.util包下的集合类都是快速失败的，不能在多线程下发生并发修改（迭代过程中被修改），比如HashMap、ArrayList 这些集合类。

**安全失败（fail—safe）**

- 采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。
- 原理：由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会触发Concurrent Modification Exception。
- 缺点：基于拷贝内容的优点是避免了Concurrent Modification Exception，但同样地，迭代器并不能访问到修改后的内容，即：迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的。
- 场景：java.util.concurrent包下的容器都是安全失败，可以在多线程下并发使用，并发修改，比如：ConcurrentHashMap。





## 7、说一下JVM内存分区

> JVM构成

<img src="../../../../../AppData/Roaming/Typora/typora-user-images/image-20230331211439070.png" alt="image-20230331211439070" style="zoom:67%;" />

程序计数器：记住下一行JVM指令的执行地址

- 程序计数器是线程私有的，每个线程单独持有一个程序计数器
- 程序计数器不会内存溢出

本地方法栈：本地方法栈为虚拟机使用到的 Native 方法服务

+ Native 方法是 Java 通过 JNI 直接调用本地 C/C++ 库，可以认为是 Native 方法相当于 C/C++ 暴露给 Java 的一个接口
+ 如notify，hashcode，wait等都是native方法

> 栈

线程运行需要的内存空间

栈帧：每一个方法运行需要的内存（包括参数，局部变量，返回地址等信息）

栈内存分配：内存一定时，栈内存越大，线程数就越少，所以不应该过大

方法内的局部变量是否是线程安全的：

+ 普通局部变量是安全的
+ 静态的局部变量是不安全的
+ 对象类型的局部变量被返回了是不安全的
+ 基本数据类型局部变量被返回时安全的
+ 参数传入对象类型变量是不安全的
+ 参数传入基本数据类型变量时安全的

栈内存溢出

- 栈帧过多 ：如递归调用没有正确设置结束条件
- 栈帧过大：json数据转换 对象嵌套对象 （用户类有部门类属性，部门类由用户类属性）
- 线程运行诊断

> 堆

通过new关键字创建的对象都会使用堆内存

堆是线程共享的

存在垃圾回收机制

堆内存溢出

+ 死循环创建对象

+ 堆内存诊断

  + 命令行方式

    jps获取运行进程号
    jmap -heap 进程号’查看当前时刻的堆内存信息

  + jconsole

    命令行输入jconsole打开可视化的界面连接上进程
    可视化的检测连续的堆内存信息

  + jvisualvm

    命令行输入jvisualvm打开可视化界面选择进程
    可视化的查看堆内存信息

> 方法区

存放类信息、常量、静态变量等数据的内存区域

线程共享，也被称为“永久代”（Permanent Generation）或“元空间”（Metaspace）

常量池

> OOM

除了程序计数器，其他内存区域都有 OOM 的风险。

- 栈一般经常会发生 StackOverflowError，比如 32 位的 windows 系统单进程限制 2G 内存，无限创建线程就会发生栈的 OOM
- 堆内存溢出，报错同上，这种比较好理解，GC 之后无法在堆中申请内存创建对象就会报错；
- 方法区 OOM，经常会遇到的是动态生成大量的类、jsp 等；
- 直接内存 OOM，涉及到 -XX:MaxDirectMemorySize 参数和 Unsafe 对象对内存的申请。

排查 OOM 的方法：

- 增加两个参数 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/heapdump.hprof，当 OOM 发生时自动 dump 堆内存信息到指定目录；
- 同时 jstat 查看监控 JVM 的内存和 GC 情况，先观察问题大概出在什么区域；
- 使用 MAT 工具载入到 dump 文件，分析大对象的占用情况，比如 HashMap 做缓存未清理，时间长了就会内存溢出，可以把改为弱引用 。

> 常量池

- **Class文件常量池**。class文件是一组以字节为单位的二进制数据流，在java代码的编译期间，我们编写的java文件就被编译为.class文件格式的二进制数据存放在磁盘中，其中就包括class文件常量池。
- **运行时常量池**：运行时常量池相对于class常量池一大特征就是具有动态性，java规范并不要求常量只能在运行时才产生，也就是说运行时常量池的内容并不全部来自class常量池，在运行时可以通过代码生成常量并将其放入运行时常量池中，这种特性被用的最多的就是String.intern()。
- **全局字符串常量池**：字符串常量池是JVM所维护的一个字符串实例的引用表，在HotSpot VM中，它是一个叫做StringTable的全局表。在字符串常量池中维护的是字符串实例的引用，底层C++实现就是一个Hashtable。这些被维护的引用所指的字符串实例，被称作”被驻留的字符串”或”interned string”或通常所说的”进入了字符串常量池的字符串”。 
- **基本类型包装类对象常量池**：java中基本类型的包装类的大部分都实现了常量池技术，这些类是Byte,Short,Integer,Long,Character,Boolean,另外两种浮点数类型的包装类则没有实现。另外上面这5种整型的包装类也只是在对应值小于等于127时才可使用对象池，也即对象不负责创建和管理大于127的这些类的对象。



> 堆和栈的区别





## 8、说一下双亲委派机制

> 类加载

虚拟机把描述类的数据加载到内存里面，并对数据进行校验、解析和初始化，最终变成可以被虚拟机直接使用的class对象；

类加载过程如下：

- 加载，加载分为三步： 1、通过类的全限定性类名获取该类的二进制流； 2、将该二进制流的静态存储结构转为方法区的运行时数据结构； 3、在堆中为该类生成一个class对象；
- 验证：验证该class文件中的字节流信息复合虚拟机的要求，不会威胁到jvm的安全；
- 准备：为class对象的静态变量分配内存，初始化其初始值；
- 解析：该阶段主要完成符号引用转化成直接引用；
- 初始化：到了初始化阶段，才开始执行类中定义的java代码；初始化阶段是调用类构造器的过程；

> 类加载器

通过一个类的全限定性类名获取该类的二进制字节流叫做类加载器

- 启动类加载器：用来加载java核心类库，无法被java程序直接引用；
- 扩展类加载器：用来加载java的扩展库，java的虚拟机实现会提供一个扩展库目录，该类加载器在扩展库目录里面查找并加载java类；
- 系统类加载器：它根据java的类路径来加载类，一般来说，java应用的类都是通过它来加载的；
- 自定义类加载器：由java语言实现，继承自ClassLoader；

> 双亲委派机制

当一个类加载器收到一个类加载的请求，他首先不会尝试自己去加载，而是将这个请求委派给父类加载器去加载，只有父类加载器在自己的搜索范围类查找不到给类时，子加载器才会尝试自己去加载该类；

> 作用

为了防止内存中出现多个相同的字节码；

如果没有双亲委派的话，用户就可以自己定义一个java.lang.String类，那么就无法保证类的唯一性。

> 怎么打破双亲委派机制

1. 使用线程上下文类加载器（Thread Context Classloader）：在Java应用程序中，每个线程都有自己的类加载器。可以通过设置线程上下文类加载器来实现打破双亲委派机制。例如，在Tomcat等容器中，通常会使用线程上下文类加载器来加载Web应用程序的类。
2. 自定义类加载器：可以自己实现一个类加载器，从而打破双亲委派机制，实现自定义的类加载逻辑
3. 使用Java反射机制：可以使用Java反射机制来加载自定义的类



## 9、写几个排序算法

```Java
// 冒泡排序
public static void bubbleSort(int[] arr) {
    // 参数检查
    if (arr == null || arr.length <= 1) {
        return;
    }
    // 外层循环控制趟数，每趟将一个最大元素移动到最右边
    for (int i = 0; i < arr.length - 1; i++) {
        // 内层循环控制比较次数，每次比较相邻两个元素并交换位置
        for (int j = 0; j < arr.length - 1 - i; j++) {
            // 如果左边元素大于右边元素，交换位置
            if (arr[j] > arr[j + 1]) {
                int temp = arr[j];
                arr[j] = arr[j + 1];
                arr[j + 1] = temp;
            }
        }
    }
}

// 插入排序
public static void insertionSort(int[] arr) {
    // 参数检查
    if (arr == null || arr.length <= 1) {
        return;
    }
    // 外层循环控制取出元素的位置，从第二个元素开始
    for (int i = 1; i < arr.length; i++) {
        // 内层循环控制插入位置的寻找，从右向左比较
        int temp = arr[i]; // 保存当前要插入的元素
        int j = i - 1; // 指向已经有序的最后一个元素
        while (j >= 0 && arr[j] > temp) { // 如果当前元素大于要插入的元素，就将其后移一位
            arr[j + 1] = arr[j];
            j--;
        }
        // 找到了合适的插入位置，将要插入的元素放在那里
        arr[j + 1] = temp;
    }
}


//选择排序
public static void selectionSort(int[] arr) {
        for (int i = 0; i < arr.length - 1; i++) { // 外层循环控制需要进行多少趟比较
            int minIndex = i; // 假设每趟开始时，最小值的索引为i
            for (int j = i + 1; j < arr.length; j++) { // 内层循环从i+1开始，找出最小值的索引
                if (arr[j] < arr[minIndex]) { // 如果发现比假设的最小值还小的元素
                    minIndex = j; // 更新最小值的索引为j
                }
            }
            if (minIndex != i) { // 如果最小值不是原来假设的那个元素
                int temp = arr[i]; // 交换两个元素的位置
                arr[i] = arr[minIndex];
                arr[minIndex] = temp;
            }
        }
    }


//归并排序
public static void mergeSort(int[] arr, int left, int right, int[] temp) {
        if (left < right) { // 如果左边界小于右边界，说明还可以继续分割
            int mid = (left + right) / 2; // 计算中间位置
            mergeSort(arr, left, mid, temp); // 对左半部分进行递归排序
            mergeSort(arr, mid + 1 , right , temp); // 对右半部分进行递归排序
            merge(arr , left , mid , right , temp); // 将两个有序的子数组合并为一个有序的数组
        }
    }

    public static void merge(int[] arr , int left , int mid , int right , int[] temp) {
        int i = left; // 左边子数组的起始位置
        int j = mid + 1; // 右边子数组的起始位置
        int t = 0; // 临时数组的起始位置

        while (i <= mid && j <= right) { // 当左右两个子数组都还有元素时，比较它们的大小，并按顺序放入临时数组中
            if (arr[i] <= arr[j]) { // 如果左边元素小于等于右边元素，将左边元素放入临时数组，并移动指针到下一位
                temp[t++] = arr[i++];
            } else { // 否则，将右边元素放入临时数组，并移动指针到下一位
                temp[t++] = arr[j++];
            }
        }

        while (i <= mid) { // 当左边子数组还有剩余元素时，将它们全部放入临时数组中，并移动指针到下一位
            temp[t++] = arr[i++];
        }

        while (j <= right) { // 当右边子数组还有剩余元素时，将它们全部放入临时数组中，并移动指针到下一位
            temp[t++] = arr[j++];
        }

        t = 0; // 将临时变量重置为0

        while(left <= right){ // 将临时变量中存储的有序数据拷贝回原来的arr中[left,right]
            arr[left++] = temp[t++];
         }
    }



//快排
public static void quickSort(int[] arr , int left , int right) {
        if (left < right) { // 如果左边界小于右边界，说明还可以继续分割
            int pivot = partition(arr , left , right); // 调用划分方法，返回中心元素的位置
            quickSort(arr , left , pivot - 1); // 对左半部分进行递归排序
            quickSort(arr , pivot + 1 , right); // 对右半部分进行递归排序
        }
    }

    public static int partition(int[] arr , int left , int right) {
        int pivot = arr[right]; // 取最后一个元素作为中心元素
        int i = left; // 定义一个变量i指向左边界

        for (int j = left; j < right; j++) { // 遍历从左边界到右边界之前的所有元素
            if (arr[j] < pivot) { // 如果当前元素小于中心元素，则将其与i位置上的元素交换，并将i向右移动一位
                swap(arr , i++ , j);
            }
        }

        swap(arr , i , right); // 最后将i位置上的元素与中心元素交换，并返回i作为中心元素的位置

        return i;
    }

    public static void swap(int[] arr , int i , int j) {
        int temp = arr[i]; // 定义一个临时变量，用于存放交换时的值
        arr[i] = arr[j];
        arr[j] = temp;
    }


//堆排序
  // 堆排序方法
    public static void heapSort(int[] array) {
        int n = array.length; // 数组长度
        // 建堆，从最后一个非叶子节点开始，自下而上，自右而左进行下沉操作
        for (int i = n / 2 - 1; i >= 0; i--) {
            sink(array, i, n);
        }
        // 调整堆，每次将堆顶元素与最后一个元素交换，并对剩余的元素进行下沉操作
        for (int i = n - 1; i > 0; i--) {
            swap(array, 0, i); // 交换堆顶和最后一个元素
            sink(array, 0, i); // 对剩余的元素进行下沉操作
        }
    }

    // 下沉操作，将指定位置的元素与其子节点中较大（或较小）的元素交换，直到满足堆的性质
    private static void sink(int[] array, int i, int n) {
        int largest = i; // 假设当前节点为最大值
        int left = 2 * i + 1; // 左子节点的索引
        int right = 2 * i + 2; // 右子节点的索引
        // 如果左子节点存在且大于当前节点，更新最大值的索引
        if (left < n && array[left] > array[largest]) {
            largest = left;
        }
        // 如果右子节点存在且大于当前节点，更新最大值的索引
        if (right < n && array[right] > array[largest]) {
            largest = right;
        }
        // 如果最大值不是当前节点，交换它们，并对被交换的节点继续进行下沉操作
        if (largest != i) {
            swap(array, i, largest);
            sink(array, largest, n);
        }
    }

    // 交换数组中两个元素的位置
    private static void swap(int[] array, int i, int j) {
        int temp = array[i];
        array[i] = array[j];
        array[j] = temp;
    }

//希尔排序
public static void shellSort(int[] arr) {
        int len = arr.length; // 获取数组长度
        int gap = len / 2; // 定义初始增量为数组长度的一半

        while (gap > 0) { // 当增量大于0时，继续循环
            for (int i = gap; i < len; i++) { // 遍历从增量位置开始到数组末尾的所有元素
                int j = i; // 定义一个变量j指向当前元素位置
                int temp = arr[j]; // 定义一个临时变量存放当前元素值

                while (j - gap >= 0 && temp < arr[j - gap]) { // 如果j减去增量位置还在有效范围内，并且当前元素值小于前面对应位置上的元素值，则进行交换，并将j向前移动一个增量位置
                    arr[j] = arr[j - gap];
                    j -= gap;
                }

                arr[j] = temp; // 最后将临时变量赋值给j位置上的元素，完成一次插入操作
            }

            gap /= 2; // 缩小增量为原来的一半，继续下一轮循环
        }
    }
```



## 10、说一下贪心算法

贪心算法是一种用于求解最优化问题的算法，它的基本思想是在每一步中，根据当前的状态，选择最好或最优的选择，从而希望得到全局最优的解。

贪心算法的优点是简单直观，易于实现，效率高；缺点是不能保证一定能找到最优解，而且对问题的要求较高，需要具有贪心选择性质和最优子结构性质。

贪心算法的一般步骤是：

1. 将问题分解为若干个子问题；
2. 对每个子问题，按照某种贪心准则，作出最优的选择；
3. 将所有子问题的局部最优解合并为一个全局最优解。

> 哈夫曼编码

哈夫曼编码是一种用于无损数据压缩的熵编码算法，它的基本思想是根据每个字符出现的频率，为每个字符分配一个变长的二进制编码，使得出现频率高的字符使用较短的编码，而出现频率低的字符使用较长的编码，从而减少编码后的数据总长度。

哈夫曼编码的过程是通过构建一棵哈夫曼树来实现的，哈夫曼树是一种带权路径长度最短的二叉树，其中每个叶子节点代表一个字符，其权值为该字符出现的频率，每个非叶子节点代表一个字符集合，其权值为其子节点权值之和。¹²

哈夫曼编码的步骤如下：

1. 根据每个字符出现的频率，创建一个由所有字符组成的最小优先队列，优先级由频率决定，频率越低优先级越高。
2. 从队列中取出两个最小优先级的节点，创建一个新的内部节点，其权值为两个节点权值之和，并将两个节点作为其左右子节点。将新节点加入到队列中。
3. 重复第二步，直到队列中只剩下一个节点，这个节点就是哈夫曼树的根节点。
4. 从根节点开始，沿着左子树走标记0，沿着右子树走标记1，直到到达叶子节点，此时得到该叶子节点对应字符的哈夫曼编码。
5. 对所有字符重复第四步，得到所有字符的哈夫曼编码。¹²

> kruskals算法

克鲁斯克尔算法是一种用于寻找最小生成树的算法，它的基本思想是按照边的权值从小到大的顺序选择边加入到最小生成树中，如果加入的边不会构成环，就保留该边，否则就舍弃该边，直到找到所有顶点的最小生成树。¹²

克鲁斯克尔算法的过程是通过使用并查集来实现的，并查集是一种维护集合之间关系的数据结构，可以快速判断两个顶点是否属于同一个连通分量，从而避免形成环。

克鲁斯克尔算法的步骤如下：

1. 将图中的所有边按照权值从小到大排序，创建一个空的最小生成树。
2. 从排序后的边中依次取出一条边，判断该边的两个顶点是否属于同一个连通分量，如果不是，则将该边加入到最小生成树中，并将两个顶点所在的连通分量合并为一个。
3. 重复第二步，直到最小生成树中包含了图中的所有顶点或者所有的边都被考虑过。

> dijkstra算法

迪杰斯特拉算法是一种用于求解带权图中单源最短路径问题的算法，它的基本思想是利用贪心、广度优先搜索和动态规划的原理，从源点开始，每次选择距离源点最近的未访问过的顶点，更新其邻接顶点的距离，直到找到源点到所有其他顶点的最短路径。

迪杰斯特拉算法的过程是通过使用一个优先队列来实现的，优先队列中存储了图中的所有顶点，按照顶点到源点的距离从小到大排序。

迪杰斯特拉算法的步骤如下：

1. 将源点的距离设为0，将其他所有顶点的距离设为无穷大，将所有顶点加入优先队列中。
2. 从优先队列中取出距离最小的顶点u，标记为已访问。
3. 遍历u的所有邻接顶点v，如果u到v的距离加上v到源点的距离小于当前记录的v到源点的距离，则更新v到源点的距离，并更新优先队列中v的位置。
4. 重复第二步和第三步，直到优先队列为空或者找到目标顶点为止。¹²

迪杰斯特拉算法具有以下性质：

- 迪杰斯特拉算法是一种贪心算法，即每次都选择当前最近的顶点来扩展最短路径。
- 迪杰斯特拉算法适用于稠密图，即边数接近顶点数平方的图，因为它的时间复杂度主要取决于对优先队列进行操作的次数。
- 迪杰斯特拉算法不能有效处理存在负权边的图，因为它可能会忽略一些更优的路径。¹²



## 11、说一下动态规划算法

将原问题分解为若干个子问题，先求解子问题，并将子问题的解存储起来，避免重复计算，然后通过子问题的解来构造原问题的解。

动态规划算法的过程是通过使用一个表格或者数组来记录子问题的解的过程，通常有两种方法：自顶向下和自底向上。

自顶向下的方法是从原问题出发，递归地求解子问题，并将子问题的解保存在表格或数组中，直到求出原问题的解为止。这种方法也称为记忆化搜索或者备忘录法

自底向上的方法是从最简单的子问题开始，逐步求解更复杂的子问题，并将子问题的解保存在表格或数组中，直到求出原问题的解为止。这种方法也称为填表法或者迭代法

> 性质：

- 动态规划算法是一种多阶段决策过程，即原问题可以分为若干个阶段，每个阶段需要做出一个决策，从而影响后续阶段的状态和结果。
- 动态规划算法具有最优子结构性质，即原问题的最优解包含了其子问题的最优解，也就是说，可以通过子问题的最优解来构造原问题的最优解。
- 动态规划算法具有重叠子问题性质，即原问题可以分解为若干个相互重叠的子问题，而不是互斥的子问题，这样可以避免重复计算相同的子问题，提高效率。

> 设计动态规划算法的状态和转移方程的步骤

+ 确定状态：确定问题的状态，以及状态之间的转移关系。状态就是对题目模型的数学描述，把能决定当前答案的信息都装在下标里，缺少一个都不能决定当前答案。
+ 确定转移方程：根据状态之间的转移关系，确定状态转移方程。转移方程就是描述一个状态如何由其他状态推导出来的公式。
+ 确定初始条件和边界情况：确定初始状态的值，以及不能用方程直接计算得出的情况。 初始条件和边界情况是为了保证算法的正确性和完备性。
+ 确定计算顺序：确定从哪个状态开始计算，以及按照什么顺序计算其他状态。2计算顺序一般有两种，一种是自底向上，从最小的子问题开始计算，另一种是自顶向下，从最大的问题开始递归求解。



## 12、说一下KMP算法的实现思路

回溯表

+ 当前俩字符不匹配，模式串需要回溯到的位置
+ 由递推求出回溯表，当前位置之前的字符串前后缀最大长度为k，说明当前位置如果要回溯，应该回溯到第K+1个位置进行比较，因为前K个已经是相等的了。第K+1个的下标为k。故每一个位置的回溯值应当由前面的字符串确定，因此，递推时根据当前的字符串求出。
+ 如果第K+1个位置和当前位置是一样的，那回溯到K+1个位置自然也会匹配不成功，需要再往前。因此，往后哦递推回溯值的时候，如果以当前字符结尾的字符串最大前后缀是K，即后一个位置应该回溯到下标K，如果k下标和后一个位置的字符相等，那应该回溯到k下标位置的回溯值。
+ k代表回溯某个位置的下标，若为0，说明应该和第一个字符比较，如果不相等，k应该赋予一个特殊值，-1。

+ 匹配
  + 不相等就回溯
  + 长度够了就找到第一个

```java
public int strStr(String haystack, String needle) {
        char[] hay = haystack.toCharArray();
        char[] nee = needle.toCharArray();
        int hLen = haystack.length();
        int nLen = needle.length();
        int[] nextval = new int[nLen];
        nextval[0] = -1;
        //计算nextval
        int j = 0;
        int k = -1;
        while(j < nLen -1){
            if(k == -1 || nee[k] == nee[j]){
                j++;
                k++;
                if(nee[j] == nee[k]){
                    nextval[j] = nextval[k];
                }
                else{
                    nextval[j] = k;
                }
            }
            else{
                k = nextval[k];
            }
        }
        //匹配
        int i = 0;
        j = 0;
        while(i < hLen){
            if(j == -1 || hay[i] == nee[j]){
                i++;
                j++;
                if(j == nLen){
                    return i -j;
                }
            }
            else{
                j = nextval[j];
            }
        }
        return -1; 
}
```



## 13、说一下HTTP协议

> 常见的状态码

- 200：服务器已成功处理了请求。 通常，这表示服务器提供了请求的网页。
- 301 ： (永久移动) 请求的网页已永久移动到新位置。 服务器返回此响应(对 GET 或 HEAD 请求的响应)时，会自动将请求者转到新位置。
- 302：(临时移动) 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。
- 400 ：客户端请求有语法错误，不能被服务器所理解。
- 403 ：服务器收到请求，但是拒绝提供服务。
- 404 ：(未找到) 服务器找不到请求的网页。
- 500： (服务器内部错误) 服务器遇到错误，无法完成请求。

> 请求方式

| 方法    | 作用                                                    |
| ------- | ------------------------------------------------------- |
| GET     | 获取资源                                                |
| POST    | 传输实体主体                                            |
| PUT     | 上传文件                                                |
| DELETE  | 删除文件                                                |
| HEAD    | 和GET方法类似，但只返回报文首部，不返回报文实体主体部分 |
| PATCH   | 对资源进行部分修改                                      |
| OPTIONS | 查询指定的URL支持的方法                                 |
| CONNECT | 要求用隧道协议连接代理                                  |
| TRACE   | 服务器会将通信路径返回给客户端                          |

> GET请求和POST请求的区别

**使用上的区别**：

- GET使用URL或Cookie传参，而POST将数据放在BODY中
- GET方式提交的数据有长度限制，则POST的数据则可以非常大
- POST比GET安全，因为数据在地址栏上不可见

**本质区别**

GET请求是幂等性的，多次请求的结果相同；POST请求不是，多次发送相同的post请求得到的结果不一定相同

GET请求是安全的，不会修改服务器资源；POST请求不是安全的，会修改服务器的资源

> 长连接和短连接

**在HTTP/1.0中，默认使用的是短连接**。也就是说，浏览器和服务器每进行一次HTTP操作，就建立一次TCP连接，但任务结束就中断连接。如果客户端浏览器访问的某个HTML或其他类型的 Web页中包含有其他的Web资源，如JavaScript文件、图像文件、CSS文件等；当浏览器每遇到这样一个Web资源，就会建立一个HTTP会话。

但从 **HTTP/1.1起，默认使用长连接**，用以保持连接特性。使用长连接的HTTP协议，会在响应头有加入这行代码：`Connection:keep-alive`

在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的 TCP连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接要客户端和服务端都支持长连接。

> 请求报文和响应报文的格式

**请求报文格式**：

1. 请求行（请求方法+URI协议+版本）
2. 请求头部
3. 空行
4. 请求主体

```
GET/sample.jspHTTP/1.1 请求行
Accept:image/gif.image/jpeg, 请求头部
Accept-Language:zh-cn
Connection:Keep-Alive
Host:localhost
User-Agent:Mozila/4.0(compatible;MSIE5.01;Window NT5.0)
Accept-Encoding:gzip,deflate

username=jinqiao&password=1234 请求主体
```

**响应报文**：

1. 状态行（版本+状态码+原因短语）
2. 响应首部
3. 空行
4. 响应主体

```
HTTP/1.1 200 OK
Server:Apache Tomcat/5.0.12
Date:Mon,6Oct2003 13:23:42 GMT
Content-Length:112

<html>
    <head>
        <title>HTTP响应示例<title>
    </head>
    <body>
        Hello HTTP!
    </body>
</html>
```

> HTTP/1.0和HTTP/1.1的区别

- **长连接**：HTTP 1.1支持长连接（Persistent Connection）和请求的流水线（Pipelining）处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启`Connection： keep-alive`，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。
- **缓存处理**：在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略，可供选择的缓存头来控制缓存策略。
- **带宽优化及网络连接的使用**：HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。
- **错误通知的管理**：在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。
- **Host头处理**：在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）

> HTTP/1.1和 HTTP/2的区别

- **新的二进制格式**：HTTP1.1的解析是基于文本。基于文本协议的格式解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多，二进制则不同，只认0和1的组合。基于这种考虑HTTP2.0的协议解析决定采用二进制格式，实现方便且健壮。
- **多路复用**，即连接共享，即每一个request都是用作连接共享机制的。一个request对应一个id，这样一个连接上可以有多个request，每个连接的request可以随机的混杂在一起，接收方可以根据request的 id将request再归属到各自不同的服务端请求里面。
- **头部压缩**，HTTP1.1的头部（header）带有大量信息，而且每次都要重复发送；HTTP/2使用encoder来减少需要传输的header大小，通讯双方各自cache一份header fields表，既避免了重复header的传输，又减小了需要传输的大小。
- **服务端推送**：服务器除了对最初请求的响应外，服务器还可以额外的向客户端推送资源，而无需客户端明确的请求

> HTTP/3和HTTP/2的区别

+ **基于UDP**：HTTP/2使用TCP作为传输层，而HTTP/3使用UDP作为传输层，并在其上实现了QUIC协议。解决HTTP/2中存在的队头阻塞问题，即当一个TCP连接中的一个请求因为丢包或延迟而被阻塞时，会影响该连接中的其他请求。HTTP/3通过使用QUIC协议，可以实现快速握手、多路复用、连接迁移、数据可靠传输等功能，提高了连接的安全性和效率
+ **连接快**： QUIC 协议握手，只需要 1 RTT，握手的目的是为确认双方的连接 ID。QUIC内部包含TLS1.3，在建立连接时同时建立安全连接，只需要1个RTT就能完成密钥协商，不需要复杂的TLS握手链接后再进行TCP三次握手。
+ **连接迁移：**QUIC使用连接ID通信，当IP发生变化时，不会断开之前的连接



> 缓存实现方式

HTTP 缓存有多种实现方式，主要分为三类：强缓存、协商缓存和启发式缓存

- 强缓存是利用 HTTP 头中的 Expires 和 Cache-Control 两个字段来控制的。它们指定了响应的过期时间，如果没有过期，客户端就可以直接从本地缓存中读取响应，而不需要再向服务器发送请求
- 协商缓存是利用 HTTP 头中的 Last-Modified/If-Modified-Since 和 Etag/If-None-Match 两对字段来控制的。它们用于比较本地缓存和服务器上的资源是否一致，如果一致，服务器就返回一个 304 Not Modified 状态码，告诉客户端可以继续使用本地缓存
- 启发式缓存是在没有明确指定 Cache-Control 的情况下，根据响应的 Date 和 Last-Modified 字段来估算一个过期时间。这种方式不太准确

> 设置HTTP缓存

设置 HTTP 缓存的方法主要是通过在响应头中添加 Cache-Control 字段来实现的。Cache-Control 字段可以指定多种缓存控制指令，例如：

- no-store：表示禁止缓存，每次请求都要向服务器获取最新的资源。
- no-cache：表示跳过强缓存，直接进入协商缓存阶段，需要向服务器验证资源是否修改过。
- max-age=：表示设置缓存的最大有效期，单位是秒，超过这个时间缓存就会过期。
- public：表示响应可以被任何对象（包括客户端和代理服务器）缓存。
- private：表示响应只能被客户端缓存，不能被代理服务器缓存。

除了 Cache-Control 字段外，还有一些其他的字段可以用来设置 HTTP 缓存，例如 Expires、Last-Modified、Etag 等。但是它们的优先级比 Cache-Control 低，而且有一些局限性和缺陷。因此，在实际开发中，建议使用 Cache-Control 来设置 HTTP 缓存



## 14、说一下HTTPS协议

> 对称加密和非对称加密

- 对称加密是指加密和解密使用相同的密钥或者同一套逻辑的加密方式，例如DES、AES等
- 非对称加密是指加密和解密使用不同的密钥或者一对密钥的加密方式，其中一个密钥是公开的（公钥），另一个密钥是私有的（私钥），例如RSA、DSA等
- 对称加密的优点是速度快，缺点是密钥管理和分发困难，容易泄露
- 非对称加密的优点是安全性高，不需要传输密钥，缺点是速度慢，计算量大
- 一般情况下，对称加密用于加密数据，非对称加密用于加密对称密钥或者数字签名

> 常见非对称加密算法

- RSA算法：基于大整数分解问题的非对称加密算法，其密钥长度通常为1024位或2048位，广泛应用于数字签名、加密通信等领域。
- DSA算法：一种基于离散对数难题的数字签名算法，其密钥长度通常为1024位，主要用于验证数字文档的真实性和完整性。
- ECC算法：一种基于椭圆曲线密码学的非对称加密算法，其密钥长度只需要256位，相对于RSA算法的2048位或更高，具有更高的安全性和更短的密钥长度，适合在资源受限的环境下使用，比如物联网设备、移动设备等

> HTTPS 的优缺点

**优点**：

- 使用HTTPS协议可认证用户和服务器，确保数据发送到正确的客户机和服务器；
- HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全，可防止数据在传输过程中不被窃取、改变，确保数据的完整性。
- HTTPS是现行架构下最安全的解决方案，虽然不是绝对安全，但它大幅增加了中间人攻击的成本。

**缺点**：

- 在相同网络环境中，HTTPS 相比 HTTP 无论是响应时间还是耗电量都有大幅度上升。
- HTTPS 的安全是有范围的，在黑客攻击、服务器劫持等情况下几乎起不到作用。
- 在现有的证书机制下，中间人攻击依然有可能发生。
- HTTPS 需要更多的服务器资源，也会导致成本的升高。

> HTTPS 的原理

1. 客户端请求 HTTPS 网址，然后连接到 server 的 443 端口 (HTTPS 默认端口，类似于 HTTP 的80端口)。

2. 采用 HTTPS 协议的服务器必须要有一套数字 CA (Certification Authority)证书。颁发证书的同时会产生一个私钥和公钥。私钥由服务端自己保存，不可泄漏。公钥则是附带在证书的信息中，可以公开的。证书本身也附带一个证书电子签名，这个签名用来验证证书的完整性和真实性，可以防止证书被篡改。

3. 服务器响应客户端请求，将证书传递给客户端，证书包含公钥和大量其他信息，比如证书颁发机构信息，公司信息和证书有效期等。

4. 客户端解析证书并对其进行验证。如果证书不是可信机构颁布，或者证书中的域名与实际域名不一致，或者证书已经过期，就会向访问者显示一个警告，由其选择是否还要继续通信。

   如果证书没有问题，客户端就会从服务器证书中取出服务器的公钥A。然后客户端还会生成一个随机码 KEY，并使用公钥A将其加密。

5. 客户端把加密后的随机码 KEY 发送给服务器，作为后面对称加密的密钥。

6. 服务器在收到随机码 KEY 之后会使用私钥B将其解密。经过以上这些步骤，客户端和服务器终于建立了安全连接，完美解决了对称加密的密钥泄露问题，接下来就可以用对称加密进行通信了






## 15、说一下TCP协议

> 三次握手机制

- 第一次握手：客户端请求建立连接，向服务端发送一个**同步报文**（SYN=1），同时选择一个随机数 seq = x 作为**初始序列号**，并进入SYN_SENT状态，等待服务器确认。
- 第二次握手：：服务端收到连接请求报文后，如果同意建立连接，则向客户端发送**同步确认报文**（SYN=1，ACK=1），确认号为 ack = x + 1，同时选择一个随机数 seq = y 作为**初始序列号**，此时服务器进入SYN_RECV状态。
- 第三次握手：客户端收到服务端的确认后，向服务端发送一个**确认报文**（ACK=1），确认号为 ack = y + 1，序列号为 seq = x + 1，客户端和服务器进入ESTABLISHED状态，完成三次握手。

> 为什么需要三次握手，而不是两次

1. **防止已过期的连接请求报文突然又传送到服务器**，因而产生错误和资源浪费。

   在双方两次握手即可建立连接的情况下，假设客户端发送 A 报文段请求建立连接，由于网络原因造成 A 暂时无法到达服务器，服务器接收不到请求报文段就不会返回确认报文段。

   客户端在长时间得不到应答的情况下重新发送请求报文段 B，这次 B 顺利到达服务器，服务器随即返回确认报文并进入 ESTABLISHED 状态，客户端在收到 确认报文后也进入 ESTABLISHED 状态，双方建立连接并传输数据，之后正常断开连接。

   此时姗姗来迟的 A 报文段才到达服务器，服务器随即返回确认报文并进入 ESTABLISHED 状态，但是已经进入 CLOSED 状态的客户端无法再接受确认报文段，更无法进入 ESTABLISHED 状态，这将导致服务器长时间单方面等待，造成资源浪费。

2. 三次握手才能让**双方均确认自己和对方的发送和接收能力都正常**。

   第一次握手：客户端只是发送处请求报文段，什么都无法确认，而服务器可以确认自己的接收能力和对方的发送能力正常；

   第二次握手：客户端可以确认自己发送能力和接收能力正常，对方发送能力和接收能力正常；

   第三次握手：服务器可以确认自己发送能力和接收能力正常，对方发送能力和接收能力正常；

   可见三次握手才能让双方都确认自己和对方的发送和接收能力全部正常，这样就可以愉快地进行通信了。

3. 告知对方**自己的初始序号值**，并确认收到**对方的初始序号值**。

   TCP 实现了可靠的数据传输，原因之一就是 TCP 报文段中维护了序号字段和确认序号字段，通过这两个字段双方都可以知道在自己发出的数据中，哪些是已经被对方确认接收的。这两个字段的值会在初始序号值得基础递增，如果是两次握手，只有发起方的初始序号可以得到确认，而另一方的初始序号则得不到确认。

> SYN洪泛攻击

SYN洪泛攻击属于 DOS 攻击的一种，它利用 TCP 协议缺陷，通过发送大量的半连接请求，耗费 CPU 和内存资源。

原理：

- 在三次握手过程中，服务器发送 `[SYN/ACK]` 包（第二个包）之后、收到客户端的 `[ACK]` 包（第三个包）之前的 TCP 连接称为半连接（half-open connect），此时服务器处于 `SYN_RECV`（等待客户端响应）状态。如果接收到客户端的 `[ACK]`，则 TCP 连接成功，如果未接受到，则会**不断重发请求**直至成功。
- SYN 攻击的攻击者在短时间内**伪造大量不存在的 IP 地址**，向服务器不断地发送 `[SYN]` 包，服务器回复 `[SYN/ACK]` 包，并等待客户的确认。由于源地址是不存在的，服务器需要不断的重发直至超时。
- 这些伪造的 `[SYN]` 包将长时间占用未连接队列，影响了正常的 SYN，导致目标系统运行缓慢、网络堵塞甚至系统瘫痪。



防范：

- 通过防火墙、路由器等过滤网关防护。
- 通过加固 TCP/IP 协议栈防范，如增加最大半连接数，缩短超时时间。
- SYN cookies技术。SYN Cookies 是对 TCP 服务器端的三次握手做一些修改，专门用来防范 SYN 洪泛攻击的一种手段。

> 最后一次ACK包丢失，会发生什么

**服务端：**

- 第三次的ACK在网络中丢失，那么服务端该TCP连接的状态为SYN_RECV,并且会根据 TCP的超时重传机制，会等待3秒、6秒、12秒后重新发送SYN+ACK包，以便客户端重新发送ACK包。
- 如果重发指定次数之后，仍然未收到 客户端的ACK应答，那么一段时间后，服务端自动关闭这个连接。

**客户端：**

客户端认为这个连接已经建立，如果客户端向服务端发送数据，服务端将以RST包（Reset，标示复位，用于异常的关闭连接）响应。此时，客户端知道第三次握手失败。

> 四次挥手过程

- 第一次挥手：客户端向服务端发送**连接释放报文（FIN**=1，ACK=1），主动关闭连接，同时等待服务端的确认。

  - 序列号 seq = u，即客户端上次发送的报文的最后一个字节的序号 + 1
  - 确认号 ack = k, 即服务端上次发送的报文的最后一个字节的序号 + 1

- 第二次挥手：服务端收到连接释放报文后，立即发出**确认报文**（ACK=1），序列号 seq = k，确认号 ack = u + 1。

  这时 TCP 连接处于半关闭状态，即客户端到服务端的连接已经释放了，但是服务端到客户端的连接还未释放。这表示客户端已经没有数据发送了，但是服务端可能还要给客户端发送数据。

- 第三次挥手：服务端向客户端发送**连接释放报文（FIN=1**，ACK=1），主动关闭连接，同时等待 A 的确认。

  - 序列号 seq = w，即服务端上次发送的报文的最后一个字节的序号 + 1。
  - 确认号 ack = u + 1，与第二次挥手相同，因为这段时间客户端没有发送数据

- 第四次挥手：客户端收到服务端的连接释放报文后，立即发出**确认报文**（ACK=1），序列号 seq = u + 1，确认号为 ack = w + 1。

  此时，客户端就进入了 `TIME-WAIT` 状态。注意此时客户端到 TCP 连接还没有释放，必须经过 2*MSL（最长报文段寿命）的时间后，才进入 `CLOSED` 状态。而服务端只要收到客户端发出的确认，就立即进入 `CLOSED` 状态。可以看到，服务端结束 TCP 连接的时间要比客户端早一些。

> 为什么连接的时候是三次握手，关闭的时候却是四次握手？

服务器在收到客户端的 FIN 报文段后，可能还有一些数据要传输，所以不能马上关闭连接，但是会做出应答，返回 ACK 报文段.

接下来可能会继续发送数据，在数据发送完后，服务器会向客户单发送 FIN 报文，表示数据已经发送完毕，请求关闭连接。服务器的**ACK和FIN一般都会分开发送**，从而导致多了一次，因此一共需要四次挥手。

> 为什么客户端的 TIME-WAIT 状态必须等待 2MSL ？

1. **确保 ACK 报文能够到达服务端**，从而使服务端正常关闭连接。

   第四次挥手时，客户端第四次挥手的 ACK 报文不一定会到达服务端。服务端会超时重传 FIN/ACK 报文，此时如果客户端已经断开了连接，那么就无法响应服务端的二次请求，这样服务端迟迟收不到 FIN/ACK 报文的确认，就无法正常断开连接。

   MSL 是报文段在网络上存活的最长时间。客户端等待 2MSL 时间，即「客户端 ACK 报文 1MSL 超时 + 服务端 FIN 报文 1MSL 传输」，就能够收到服务端重传的 FIN/ACK 报文，然后客户端重传一次 ACK 报文，并重新启动 2MSL 计时器。如此保证服务端能够正常关闭。

   如果服务端重发的 FIN 没有成功地在 2MSL 时间里传给客户端，服务端则会继续超时重试直到断开连接。

2. **防止已失效的连接请求报文段出现在之后的连接中**。

   TCP 要求在 2MSL 内不使用相同的序列号。客户端在发送完最后一个 ACK 报文段后，再经过时间 2MSL，就可以保证本连接持续的时间内产生的所有报文段都从网络中消失。这样就可以使下一个连接中不会出现这种旧的连接请求报文段。或者即使收到这些过时的报文，也可以不处理它。

> 如果已经建立了连接，但是客户端出现故障了怎么办？

或者说，如果三次握手阶段、四次挥手阶段的包丢失了怎么办？如“服务端重发 FIN丢失”的问题。

简而言之，通过**定时器 + 超时重试机制**，尝试获取确认，直到最后会自动断开连接。

具体而言，TCP 设有一个保活计时器。服务器每收到一次客户端的数据，都会重新复位这个计时器，时间通常是设置为 2 小时。若 2 小时还没有收到客户端的任何数据，服务器就开始重试：每隔 75 分钟发送一个探测报文段，若一连发送 10 个探测报文后客户端依然没有回应，那么服务器就认为连接已经断开了。

> TIME-WAIT 状态过多会产生什么后果？怎样处理？

从服务器来讲，短时间内关闭了大量的Client连接，就会造成服务器上出现大量的TIME_WAIT连接，严重消耗着服务器的资源，此时部分客户端就会显示连接不上。

从客户端来讲，客户端TIME_WAIT过多，就会导致端口资源被占用，因为端口就65536个，被占满就会导致无法创建新的连接。

**解决办法：**

- 服务器可以设置 SO_REUSEADDR 套接字选项来避免 TIME_WAIT状态，此套接字选项告诉内核，即使此端口正忙（处于 TIME_WAIT状态），也请继续并重用它。

- 调整系统内核参数，修改/etc/sysctl.conf文件，即修改`net.ipv4.tcp_tw_reuse 和 tcp_timestamps`

  ```
  net.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；
  net.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。
  ```

- 强制关闭，发送 RST 包越过TIME_WAIT状态，直接进入CLOSED状态。

> TCP协议如何保证可靠性？

TCP主要提供了检验和、序列号/确认应答、超时重传、滑动窗口、拥塞控制和 流量控制等方法实现了可靠性传输。

- 检验和：通过检验和的方式，接收端可以检测出来数据是否有差错和异常，假如有差错就会直接丢弃TCP段，重新发送。

- 序列号/确认应答：

  序列号的作用不仅仅是应答的作用，有了序列号能够将接收到的数据根据序列号排序，并且去掉重复序列号的数据。

  TCP传输的过程中，每次接收方收到数据后，都会对传输方进行确认应答。也就是发送ACK报文，这个ACK报文当中带有对应的确认序列号，告诉发送方，接收到了哪些数据，下一次的数据从哪里发。

- 滑动窗口：滑动窗口既提高了报文传输的效率，也避免了发送方发送过多的数据而导致接收方无法正常处理的异常。

- 超时重传：超时重传是指发送出去的数据包到接收到确认包之间的时间，如果超过了这个时间会被认为是丢包了，需要重传。最大超时时间是动态计算的。

- 拥塞控制：在数据传输过程中，可能由于网络状态的问题，造成网络拥堵，此时引入拥塞控制机制，在保证TCP可靠性的同时，提高性能。

- 流量控制：如果主机A 一直向主机B发送数据，不考虑主机B的接受能力，则可能导致主机B的接受缓冲区满了而无法再接受数据，从而会导致大量的数据丢包，引发重传机制。而在重传的过程中，若主机B的接收缓冲区情况仍未好转，则会将大量的时间浪费在重传数据上，降低传送数据的效率。所以引入流量控制机制，主机B通过告诉主机A自己接收缓冲区的大小，来使主机A控制发送的数据量。流量控制与TCP协议报头中的窗口大小有关。

> 滑动窗口

TCP滑动窗口原理是指TCP协议如何**根据发送方和接收方的缓冲区大小和网络状况动态调整发送数据的数量**，以避免发送方发送过多的数据导致接收方缓冲区溢出或网络拥塞。

TCP滑动窗口原理主要包括两个方面：**流量控制和拥塞控制**



**流量控制：**

流量控制是指发送方**根据接收方通告的窗口大小（RCV.WND）来控制发送数据的速率**，以保证接收方能够及时处理数据，不会出现缓冲区溢出的情况。流量控制涉及到四个变量：SND.UNA（已发送并确认的字节序号），SND.NXT（下一个要发送的字节序号），SND.WND（发送窗口大小），RCV.WND（接收窗口大小）。¹²

**发送窗口**是指发送方可以发送但还未确认的数据段所占用的字节数，它等于SND.NXT - SND.UNA。

**接收窗口**是指接收方可以接收但还未接收的数据段所占用的字节数，它等于RCV.WND。

**可用窗口**是指发送方可以立即发送的数据段所占用的字节数，它等于SND.UNA + SND.WND - SND.NXT。¹²

当发送方窗口全都是已经发送但是未收到确认的数据时，停止发送，直到收到确认后，更新窗口的大小以及边界，向右边滑动。

接收方同理。





**拥塞控制：**

TCP拥塞控制原理是指TCP协议如何**根据网络状况调整发送数据的速率**，以避免过多的数据包导致路由器缓存溢出或丢包。TCP拥塞控制原理主要包括四个算法：慢启动、拥塞避免、快速重传和快速恢复。

+ 慢启动算法是指TCP连接建立后，发送方先以较小的拥塞窗口（cwnd）发送数据，每收到一个确认报文，就将cwnd乘以2，这样cwnd会呈指数增长，直到达到一个慢启动阈值（ssthresh）或发生丢包。

+ 拥塞避免算法是指当cwnd达到ssthresh后，发送方进入拥塞避免阶段，每收到一个确认报文，就将cwnd加上一个小于1的常数，这样cwnd会呈线性增长，直到发生丢包。

+ 快速重传算法是指当发送方收到对同一个数据段的三个冗余确认（也就是四个相同的确认号），就认为该数据段的下一个数据段已经丢失，于是不等待超时重传计时器，立即重传该数据段。

+ 快速恢复算法是指当发送方进入快速重传阶段后，将ssthresh设为当前cwnd的一半，并将cwnd设为ssthresh加上三个MSS（最大报文段长度），然后每收到一个冗余确认，就将cwnd加一，直到收到新的确认号或超时



## 16、说一下UDP协议

UDP是用户数据报协议，是一种无连接的传输层协议，它提供了一种**简单的、不可靠的、面向报文的数据传输服务**。

UDP的特点有：

- UDP不需要建立连接，减少了开销和时延。
- UDP没有拥塞控制和流量控制，适合实时性要求高的应用，如音视频通信。
- UDP支持一对一、一对多、多对一和多对多的通信模式，适合广播和组播应用。
- UDP只在报文首部添加8个字节的头部信息，没有额外的开销，效率高。
- UDP不保证数据的有序性和完整性，可能出现丢包、重复、乱序等问题，需要上层协议或应用层来处理。

> UDP如何实现可靠传输

在应用层实现一些TCP已经提供的功能，如确认机制、重传机制、窗口机制、拥塞控制等。这样可以保证数据的完整性、有序性和流量控制。但是这样做的代价是增加了开销和时延，降低了效率和实时性



## 17、说一下DNS协议

DNS的过程是指域名系统（Domain Name System）将域名（如www.baidu.com）解析为对应的IP地址（如14.215.177.38）的过程。DNS的过程大致如下：
- 首先，用户在浏览器中输入一个域名，浏览器会检查自己的**缓存**中是否有该域名对应的IP地址，如果有，就直接访问该IP地址，如果没有，就进行下一步。
- 其次，浏览器会向操作系统查询该域名是否在本地的**hosts文件**中绑定了IP地址，如果有，就直接访问该IP地址，如果没有，就进行下一步。
- 然后，操作系统会向**本地的DNS服务器**（通常是网络运营商提供的）发送一个DNS查询请求，本地DNS服务器会检查自己的缓存中是否有该域名对应的IP地址，如果有，就返回给操作系统，如果没有，就进行下一步。
- 接着，本地DNS服务器会向**根DNS服务器**（全球共有13台）发送一个DNS查询请求，根DNS服务器会根据域名的顶级域（如.com）返回一个负责该顶级域的DNS服务器的地址给本地DNS服务器。
- 然后，本地DNS服务器会向该**顶级DNS服务器**发送一个DNS查询请求，顶级DNS服务器会根据域名的二级域（如.baidu.com）返回一个负责该二级域的权威DNS服务器的地址给本地DNS服务器。
- 接着，本地DNS服务器会向该**权威DNS服务器**发送一个DNS查询请求，权威DNS服务器会根据域名的完整名称（如www.baidu.com）返回一个对应的IP地址给本地DNS服务器。
- 最后，本地DNS服务器会将得到的IP地址返回给**操作系统，并存起来**以备后用。操作系统也会将IP地址返回给浏览器，并缓存起来以备后用。**浏览器也会将IP地址缓存**起来以备后用。然后浏览器就可以通过IP地址访问目标网站了。



## 18、说一下ICMP协议

ICMP是Internet控制消息协议的缩写，它是TCP/IP协议族中的一个重要子协议，主要用于在IP主机和路由器之间传递控制消息，用于报告主机是否可达、路由是否可用等网络问题¹²。

ICMP报文被封装在IP数据包内部，作为IP数据包的数据部分通过互联网传递。

ICMP报文有不同的类型和代码，对应了数据包处理过程中可能出现的不同错误情况。

ICMP协议在网络诊断和排错中有很多应用，例如ping和traceroute等工具就是基于ICMP报文实现的。

ICMP协议也存在一些安全问题，例如可能被用于发起拒绝服务攻击

> ping和traceroute

ping是用来测试网络设备是否可达和数据包的传输延迟的，它通过发送ICMP Echo请求报文和接收ICMP Echo响应报文来实现。

traceroute是用来查看数据包从源地址到目的地址的传输路径和每一跳的延迟的，它通过发送不同TTL值的ICMP Echo请求报文和接收ICMP超时或目的不可达报文来实现。

要使用ping和traceroute工具，需要在命令行或终端窗口中输入相应的命令和参数

ping -c 5 www.baidu.com

traceroute www.baidu.com

> 报文类型

可以将ICMP报文分为两大类：差错报文和查询报文。

差错报文是用于报告IP数据包在传输过程中出现的各种错误，例如目的不可达、时间超时、参数问题等。

查询报文是用于测试网络连接或获取网络信息，例如回显请求和回应、时间戳请求和回应、地址掩码请求和回应等。

| 类型 | 代码 | 描述         | 查询/差错 |
| ---- | ---- | ------------ | --------- |
| 0    | 0    | 回显回应     | 查询      |
| 3    | 0-15 | 目的不可达   | 差错      |
| 4    | 0    | 源站抑制     | 控制      |
| 5    | 0-3  | 路由重定向   | 控制      |
| 8    | 0    | 回显请求     | 查询      |
| 9    | 0    | 路由器通告   | 查询      |
| 10   | 0    | 路由器请求   | 查询      |
| 11   | 0-1  | 时间超时     | 差错      |
| 12   | 0-2  | 参数问题     | 差错      |
| 13   | 0    | 时间戳请求   | 查询      |
| 14   | 0    | 时间戳回应   | 查询      |
| 17   | 0    | 地址掩码请求 | 查询      |
| 18   | 0    | 地址掩码回应 | 查询      |



## 19、说一下Cookie合Session

Cookie是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。

通常，它用于告知服务端两个请求是否来自同一浏览器，如保持用户的登录状态。

Cookie 使基于无状态的 HTTP 协议记录稳定的状态信息成为了可能。

Cookie 主要用于以下三个方面：

- 会话状态管理
- 个性化设置
- 浏览器行为跟踪



Session 对象存储特定用户会话所需的属性及配置信息。

当用户在应用程序的 Web 页之间跳转时，存储在 Session 对象中的变量将不会丢失

当客户端关闭会话，或者 Session 超时失效时会话结束。



用户第一次请求服务器的时候，服务器根据用户提交的相关信息，创建对应的 Session ，请求返回时将此 Session 的唯一标识信息 SessionID 返回给浏览器，浏览器接收到服务器返回的 SessionID 信息后，会将此信息存入到 Cookie 中，同时 Cookie 记录此 SessionID 属于哪个域名。

当用户第二次访问服务器的时候，请求会自动判断此域名下是否存在 Cookie 信息，如果存在自动将 Cookie 信息也发送给服务端，服务端会从 Cookie 中获取 SessionID，再根据 SessionID 查找对应的 Session 信息，如果没有找到说明用户没有登录或者登录失效，如果找到 Session 证明用户已经登录可执行后面操作

> Cookie和Session的区别

- 作用范围不同，Cookie 保存在客户端（浏览器），Session 保存在服务器端。
- 存取方式的不同，Cookie 只能保存 ASCII，Session 可以存任意数据类型，一般情况下我们可以在 Session 中保持一些常用变量信息，比如说 UserId 等。
- 有效期不同，Cookie 可设置为长时间保持，比如我们经常使用的默认登录功能，Session 一般失效时间较短，客户端关闭或者 Session 超时都会失效
- 存储大小不同， 单个 Cookie 保存的数据不能超过 4K，Session 可存储数据远高于 Cookie

> 分布式 Session 问题

后端往往需要多台服务器共同来支撑前端用户请求，那如果用户在 A 服务器登录了，第二次请求跑到服务 B 就会出现登录失效问题。

分布式 Session 一般会有以下几种解决方案：

- **客户端存储**：直接将信息存储在cookie中，cookie是存储在客户端上的一小段数据，客户端通过http协议和服务器进行cookie交互，通常用来存储一些不敏感信息

- **Nginx ip_hash 策略**：服务端使用 Nginx 代理，每个请求按访问 IP 的 hash 分配，这样来自同一 IP 固定访问一个后台服务器，避免了在服务器 A 创建 Session，第二次分发到服务器 B 的现象。
- **Session 复制**：任何一个服务器上的 Session 发生改变（增删改），该节点会把这个 Session 的所有内容序列化，然后广播给所有其它节点。
- **共享 Session**：服务端无状态话，将用户的 Session 等信息使用缓存中间件（如Redis）来统一管理，保障分发到每一个服务器的响应结果都一致。



## 20、说一下DHCP

DHCP的主要作用是让网络设备可以自动获取IP地址、子网掩码、默认网关、DNS服务器等参数，而不需要手动配置。

DHCP的工作原理是基于客户端/服务器模式，即DHCP客户端向DHCP服务器发送请求消息，DHCP服务器根据预先定义的地址池为客户端分配一个IP地址，并返回应答消息，包含租约期限和其他选项。

DHCP客户端和服务器之间的通信过程一般分为四个步骤：发现、提供、选择和确认。

- 发现：DHCP客户端以广播方式发送DHCP DISCOVER消息，寻找可用的DHCP服务器。
- 提供：收到DHCP DISCOVER消息的DHCP服务器会从自己的地址池中选择一个可用的IP地址，并以广播方式发送DHCP OFFER消息，向客户端提供该IP地址。
- 选择：如果有多个DHCP服务器向客户端发送DHCP OFFER消息，客户端一般会选择第一个收到的消息，并以广播方式发送DHCP REQUEST消息，通知所有的DHCP服务器它将选择哪个服务器提供的IP地址。
- 确认：被选中的DHCP服务器收到DHCP REQUEST消息后，会以广播方式发送DHCP ACK消息，确认分配给客户端的IP地址，并附上租约期限和其他选项。未被选中的DHCP服务器则会收回自己提供的IP地址，以便分配给其他客户端。



## 21、说一下ARP

在局域网中根据IP地址获取MAC地址的网络协议。

ARP的工作原理是基于客户端/服务器模式，即ARP客户端向ARP服务器发送请求消息，ARP服务器根据自己的ARP表为客户端提供一个IP地址对应的MAC地址，并返回应答消息。

ARP客户端和服务器之间的通信过程一般分为四个步骤：发现、提供、选择和确认¹²³。

- 发现：ARP客户端以广播方式发送ARP请求消息，寻找目标IP地址对应的MAC地址。
- 提供：收到ARP请求消息的ARP服务器会从自己的ARP表中查找目标IP地址对应的MAC地址，并以单播方式发送ARP应答消息，向客户端提供该MAC地址。
- 选择：如果有多个ARP服务器向客户端发送ARP应答消息，客户端一般会选择第一个收到的消息，并将该IP地址和MAC地址存入本机ARP缓存中。
- 确认：客户端收到ARP应答消息后，会使用该MAC地址进行数据传输



## 22、说一下IP协议

是TCP/IP协议族中最核心的协议之一，位于网络层。

IP协议的主要功能是为网络设备提供唯一的IP地址，并通过IP地址实现数据包的无连接、不可靠的、尽力而为的传输服务

IP协议的主要内容包括IP编址方案、分组封装格式和分组转发规则。

+ IP编址方案是指如何给网络设备分配和管理IP地址，包括IP地址的结构、分类、特殊用途等。
+ 分组封装格式是指IP数据包的头部和数据部分的组成和含义，包括版本号、首部长度、服务类型、总长度、标识符、标志位、片偏移、生存时间、协议类型、首部校验和、源地址、目的地址等字段 
+ 分组转发规则是指如何根据IP地址和路由表在网络中传送和接收数据包，包括直接交付和间接交付两种方式，以及分片和重组的机制。

> IP地址的分类

IP地址的分类是指根据IP地址的第一个字节的最高位来划分不同的地址类型，主要有A、B、C、D、E五类¹²³。不同的地址类型有不同的网络号和主机号，用于区分不同规模和用途的网络。

A类地址的第一个字节以0开头，范围是1-126，后面三个字节表示主机号，用于大型网络

B类地址的第一个字节以10开头，范围是128-191，后面两个字节表示主机号，用于中型网络

C类地址的第一个字节以110开头，范围是192-223，最后一个字节表示主机号，用于小型网络

D类地址的第一个字节以1110开头，范围是224-239，用于多播

E类地址的第一个字节以1111开头，范围是240-255，保留给将来使用

> 网络号和主机号

网络号和主机号是IP地址的两个组成部分，用于区分不同的网络和不同的主机。

网络号表示主机所属的网络，主机号表示网络中的具体主机。

网络号和主机号的划分取决于IP地址的类型和子网掩码。

子网掩码是一个32位的二进制数，其中连续的1表示网络号，连续的0表示主机号

通过将IP地址和子网掩码进行按位与运算，可以得到网络地址。



子网划分是指将一个较大的网络划分为若干个较小的子网络的过程。

子网划分的方法是借用IP地址的主机位作为子网位，从而增加网络层次，缩小主机范围。

子网划分后，IP地址由三部分组成：网络号、子网号和主机号。网络号表示主机所属的网络，子网号表示主机所属的子网络，主机号表示子网络中的具体主机

> 报文封装格式

IP分组头包含了一些控制信息，如**版本号、长度、服务类型、生存时间、协议、首部校验和、源地址、目的地址**等。

IP分组头的基本单位是4字节，最小长度是20字节，最大长度是60字节

IP分组数据是指IP分组封装的上层协议的数据包，如TCP段、UDP数据报、ICMP报文等。IP分组数据的长度取决于IP分组头中的总长度字段和首部长度字段。IP分组数据的最大长度是65515字节

> IP分组

由于不同的网络链路层有不同的最大传输单元（MTU），即数据帧可封装数据的上限，因此当一个较大的IP分组在转发时遇到一个较小的MTU时，就需要进行分片，即将一个大的IP分组划分为多个小的IP分组。

每个小的IP分组都复制原来的IP分组头，并根据原来的IP分组数据进行封装。

为了标识和重组分片，IP分组头中有三个字段与之相关，即标识、标志和片偏移。

+ 标识字段用于标识同属于一个原始IP分组的所有小的IP分组；
+ 标志字段用于指示是否还有后续的分片，以及是否允许进行分片；
+ 片偏移字段用于表示每个小的IP分组在原始IP分组中的相对位置

> 分组转发规则

IP分组转发规则是指路由器如何根据IP分组的目的地址和路由表来决定将分组转发到哪个下一跳路由器或目的主机的过程。

1. 从收到的分组的首部提取目的主机的IP地址D。
2. 若查找到有特定主机路由（目的地址为D)，就按照这条路由的下一跳转发分组；否则从转发表中下一行（也就是前缀最长的一行）开始检查，执行 (3)。
3. 把这一行的子网掩码与目的地址D按位进行AND运算。若运算结果与本行的前缀匹配，则查找结束；否则，对下一行进行检查，重新执行 (3)。没有下一行了，执行 (4)。
4. 若转发表中有一个默认路由，则按照指明的接口，把分组传送到指明的默认路由器；否则，报告转发分组出错

> 静态路由和动态路由

**静态路由**

需要管理员手动配置的路由，使得数据包能够按照预定的路径传送到指定的目标网络。

静态路由适合用于小型且稳定的网络，因为它可以节省网络带宽，减少额外开支，控制路由选择，提高转发效率。

**动态路由**

路由器能够根据路由器之间的交换的特定路由信息，自动地建立自己的路由表，并且能够根据链路和节点的变化适时地进行自动调整。

动态路由是通过配置动态路由协议实现的，例如RIP、OSPF、EIGRP等

> 路由器和交换机

- 路由器和交换机工作在不同的**网络层次**。路由器工作在网络层，负责连接不同类型的网络，并根据IP地址选择数据传送路径。交换机工作在数据链路层，负责连接局域网内的设备，并根据MAC地址转发数据帧。
- 路由器和交换机的**转发对象**不同。路由器转发的是数据包，也就是IP层的协议数据单元。交换机转发的是数据帧，也就是数据链路层的协议数据单元。
- 路由器和交换机的**功能**不同。路由器可以实现局域网与局域网、局域网与广域网、广域网与广域网之间的**互联**，可以提供**防火墙、虚拟专用网、动态主机配置协议**等服务。交换机主要用于构建局域网，可以提供**端口聚合、虚拟局域网、生成树协议**等功能。
- 路由器和交换机的**外形**不同。路由器通常端口较少，体积较小，有时还带有无线功能。交换机通常端口较多，体积较大，一般没有无线功能。
- 路由器和交换机对**冲突域和广播域的划分**不同。路由器可以分割冲突域和广播域，即每个接口都是一个独立的冲突域和广播域。交换机可以分割冲突域，即每个端口都是一个独立的冲突域，但默认情况下不能分割广播域，即所有端口都在同一个广播域内。



## 23、说一下socket

Socket是操作系统提供的一种操作TCP/IP的工具，是TCP/IP协议的封装，它可以让不同的主机或进程之间通过IP地址、协议和端口来建立连接和交换数据。Socket的编程就是利用socket接口来实现网络通信的过程，它需要使用一些socket函数来创建、绑定、监听、连接、发送和接收socket。

Socket有不同的类型和协议，常见的有面向连接的TCP和无连接的UDP。

> 编程技巧

- 在选择Socket的**类型和协议**时，要根据具体的应用场景和需求来决定，比如是否需要可靠的数据传输、是否需要实时的数据传输、是否需要双向的数据传输等。
- 在设计Socket的**数据格式**时，要尽量简单、清晰、规范，避免使用复杂的结构或不常用的编码，同时要考虑数据的压缩、加密、校验等问题，提高数据的安全性和效率。
- 在编写Socket的代码时，要尽量使用**模块化、面向对象、异常处理**等技术，提高代码的可读性、可维护性、可扩展性，同时要遵循一些编码规范和风格，方便自己和他人理解和修改。
- 在测试Socket的程序时，要使用一些**工具**和方法，如抓包工具、日志工具、单元测试等，方便发现和解决问题，同时要考虑不同的网络环境和场景，如局域网、互联网、断网、重连等，检验程序的稳定性和健壮性。



## 24、说一下进程通信

> 通信方式

- 管道（pipe）：这是一种最基本的IPC机制，由pipe函数创建，它在内核中开辟一块缓冲区用于通信，它有一个读端和一个写端，数据从写端流入从读端流出。管道只能用于具有亲缘关系的进程间通信，而且只能实现单向通信。
- 命名管道（FIFO）：这是一种改进的管道，它提供一个路径名与之关联，以FIFO的文件形式存储在文件系统中。命名管道可以用于任何两个进程之间的通信，不管它们是否有亲缘关系，也可以实现双向通信。
- 消息队列：这是一种通过消息的形式进行通信的机制，消息队列是存放在内核中的消息链表，每个消息队列由一个标识符（即队列ID）来标识。进程可以向消息队列中写入或读取不同类型和长度的消息，从而实现进程间的数据交换。
- 共享内存：这是一种最快的IPC机制，它允许多个进程共享一个给定的内存区域。由一个进程创建的内存区域可以被其他进程访问，这样就不需要通过内核来传递数据。为了同步对共享内存的访问，需要使用信号量等机制。
- 信号量：这是一种用于实现进程间或线程间同步与互斥的机制。信号量是一个计数器，它表示可用资源的数量。进程可以通过增加或减少信号量的值来占用或释放资源。当信号量为0时，表示没有可用资源，此时进程需要等待直到有资源被释放。
- 信号：这是一种用于通知事件发生的机制。信号是一种异步事件，它可以由内核、其他进程或进程自身产生，并发送给某个进程。当进程收到信号后，可以选择忽略、捕捉或执行默认动作。
- Socket：这是一种支持网络通信的IPC机制。Socket是一种特殊的文件描述符，它提供了一组接口函数，使得不同主机上的进程可以通过网络进行数据交换。

> 线程同步的方式

1、临界区：通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。

2、互斥量：为协调共同对一个共享资源的单独访问而设计的。互斥量跟临界区很相似，比临界区复杂，互斥对象只有一个，只有拥有互斥对象的线程才具有访问资源的权限。

3、信号量：为控制一个具有有限数量用户资源而设计。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。互斥量是信号量的一种特殊情况，当信号量的最大资源数=1就是互斥量了。

4、事件： 用来通知线程有一些事件已发生，从而启动后继任务的开始。

## 25、说一下进程调度

进程调度是指操作系统按某种策略或规则选择进程占用CPU进行运行的过程

> 进程调度策略

- **先来先服务**：非抢占式的调度算法，按照请求的顺序进行调度。有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。另外，对`I/O`密集型进程也不利，因为这种进程每次进行`I/O`操作之后又得重新排队。

- **短作业优先**：非抢占式的调度算法，按估计运行时间最短的顺序进行调度。长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

- **最短剩余时间优先**：最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

- **时间片轮转**：将所有就绪进程按 `FCFS` 的原则排成一个队列，每次调度时，把 `CPU` 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 `CPU` 时间分配给队首的进程。

  时间片轮转算法的效率和时间片的大小有很大关系：因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。 而如果时间片过长，那么实时性就不能得到保证。

- **优先级调度**：为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

> 进程状态

进程一共有`5`种状态，分别是创建、就绪、运行（执行）、终止、阻塞。

- 运行状态就是进程正在`CPU`上运行。在单处理机环境下，每一时刻最多只有一个进程处于运行状态。
- 就绪状态就是说进程已处于准备运行的状态，即进程获得了除`CPU`之外的一切所需资源，一旦得到`CPU`即可运行。
- 阻塞状态就是进程正在等待某一事件而暂停运行，比如等待某资源为可用或等待`I/O`完成。即使`CPU`空闲，该进程也不能运行。

**运行态→阻塞态**：往往是由于等待外设，等待主存等资源分配或等待人工干预而引起的。 

**阻塞态→就绪态**：则是等待的条件已满足，只需分配到处理器后就能运行。

 **运行态→就绪态**：不是由于自身原因，而是由外界原因使运行状态的进程让出处理器，这时候就变成就绪态。例如时间片用完，或有更高优先级的进程来抢占处理器等。

 **就绪态→运行态**：系统按某种策略选中就绪队列中的一个进程占用处理器，此时就变成了运行态。

> 调度方式

有不可剥夺（或不可抢占）方式

可剥夺方式两种

> 调度算法

解决以何种次序对就绪进程进行处理机的分配，以及按何种比例让进程占有处理机。

进程调度算法是实现进程调度策略的具体方法和步骤



## 26、说一下死锁

死锁是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象

> 死锁的产生需要满足以下四个条件

- 互斥条件：每个资源在同一时刻只能被一个进程占用。
- 占有和等待条件：已经占有资源的进程可以再请求新的资源，而不释放已占有的资源。
- 不剥夺条件：已经分配给进程的资源不能被其他进程强行夺走，只能由占有者自愿释放。
- 循环等待条件：存在一个进程等待资源的环路，每个进程都在等待下一个进程所占有的资源。

> 死锁解决的方法

- 死锁防止：在程序运行之前防止发生死锁，通过破坏死锁产生的四个条件之一来实现。
- 死锁避免：在程序运行时避免发生死锁，通过动态地分析资源分配情况，避免进入不安全状态。
- 死锁检测和恢复：不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复，如撤销或回滚进程，剥夺或释放资源等。

> 银行家算法

银行家算法是一种避免死锁的经典算法，它模拟了银行贷款的过程，通过判断资源分配是否安全，来决定是否满足进程的请求。

它的基本原理是在分配资源之前，检查系统是否处于安全状态，即是否存在一个安全序列，使得每个进程都能得到所需的资源并顺利完成。

它需要维护四个数据结构：可利用资源向量、最大需求矩阵、分配矩阵和需求矩阵。它的具体步骤如下：

1. 当一个进程提出资源请求时，先检查请求是否超过其最大需求和系统可用资源，如果超过则拒绝请求，否则转到下一步。
2. 系统试探性地分配资源给进程，并更新相应的数据结构。
3. 系统执行安全性检查算法，判断是否存在一个安全序列，如果存在则正式分配资源，否则撤销试探性分配，并让进程等待。
4. 当进程完成任务后，释放所有占用的资源，并通知系统



## 27、说一下操作系统对内存的管理

> 分页

把内存空间划分为**大小相等且固定的块**，作为主存的基本单位。

因为程序数据存储在不同的页面中，而页面又离散的分布在内存中，**因此需要一个页表来记录映射关系，以实现从页号到物理块号的映射。**

访问分页系统中内存数据需要**两次的内存访问** (一次是从内存中访问页表，从中找到指定的物理块号，加上页内偏移得到实际物理地址；第二次就是根据第一次得到的物理地址访问内存取出数据)。

> 分段

分段是为了满足程序员在编写代码的时候的一些逻辑需求(比如数据共享，数据保护，动态链接等)。

分段内存管理当中，地址是二维的，一维是段号，二维是段内地址；其中每个段的长度是不一样的，而且每个段内部都是从0开始编址的

每个段内部是连续内存分配，但是段和段之间是离散分配的，因此也存在一个逻辑地址到物理地址的映射关系，相应的就是段表机制。

> 分页和分段有什区别

- 分页对程序员是透明的，但是分段需要程序员显式划分每个段。
- 分页的地址空间是一维地址空间，分段是二维的。
- 页的大小不可变，段的大小可以动态改变。
- 分页主要用于实现虚拟内存，从而获得更大的地址空间；
- 分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。

> 交换空间

当内存资源不足时，**Linux把某些页的内容转移至硬盘上的一块空间上，以释放内存空间**。

硬盘上的那块空间叫做**交换空间**(swap space),而这一过程被称为交换(swapping)。

**物理内存和交换空间的总容量就是虚拟内存的可用容量。**

用途：

- 物理内存不足时一些不常用的页可以被交换出去，腾给系统。
- 程序启动时很多内存页被用来初始化，之后便不再需要，可以交换出去。

> 快表

快表是一种特殊的高速缓冲存储器（Cache），用来存放页表中的一部分或全部内容，以加速虚拟地址到物理地址的转换过程。

快表的作用是利用局部性原理，把最近使用过的页表项缓存起来，当下次访问同一个虚拟地址时，可以直接从快表中查找对应的物理地址，而不需要访问内存中的页表，从而提高了地址转换的效率。

快表的工作原理是，当CPU访问一个虚拟地址时，首先根据虚拟页号计算出在快表中的索引，然后比较快表中该索引位置的标记位和虚拟页号是否匹配，如果匹配，则说明快表命中，直接从快表中读取物理页号，并结合虚拟地址的页内偏移得到物理地址。如果不匹配，则说明快表未命中，需要访问内存中的页表，找到对应的物理页号，并更新快表中的内容。当快表已满时，需要按照一定的策略替换掉其中一个页表项



> 页面替换算法

页面替换算法是一种在虚拟存储管理中，当发生缺页中断时，从内存中选择一个页面换出到外存，以便为新调入的页面腾出空间的方法。常见的页面替换算法有以下几种¹²：

- 随机算法（RAND）：随机地选择一个页面进行置换，简单但效率低。
- 先进先出算法（FIFO）：选择最早进入内存的页面进行置换，实现简单，但可能会淘汰常用的页面。
- 最佳算法（OPT）：选择在未来最长时间内不再被访问的页面进行置换，可以保证最低的缺页率，但无法实现，只能用于评估其他算法。
- 最近最少使用算法（LFU）：选择在最近一段时间内被访问次数最少的页面进行置换，反映了页面的使用频率，但可能会忽略了页面的使用时间。
- 最近最久未使用算法（LRU）：选择最久没有被访问的页面进行置换，反映了页面的使用时间，但需要记录每个页面的访问时间戳，开销较大。
- 时钟算法（CLOCK）：维护一个类似时钟的环形链表，每个页面有一个访问位，当发生缺页中断时，检查指针指向的页面的访问位，如果为0则置换该页面，如果为1则清零并移动指针，直到找到一个访问位为0的页面。这是一种对LRU算法的近似实现。
- 改进型时钟算法：在时钟算法的基础上，增加了一个修改位，用来表示页面是否被修改过。在选择置换页面时，优先淘汰没有修改过的页面，避免写回外存的开销。



> 虚拟内存

虚拟内存就是说，让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。

基于局部性原理，虚拟内存使用部分加载的技术，让一个进程或者资源的某些页面加载进内存，从而能够加载更多的进程，甚至能加载比内存大的进程，这样看起来好像内存变大了，这部分内存其实包含了磁盘或者硬盘，并且就叫做虚拟内存。

虚拟内存的实需要建立在离散分配的内存管理方式的基础上。

虚拟内存的实现有以下三种方式：

- 请求分页存储管理。
- 请求分段存储管理。
- 请求段页式存储管理。



## 28、说一下IO多路复用

IO多路复用是一种同步IO模型，它可以让一个线程同时处理多个IO请求。

它的原理是通过一个函数（如select、poll或epoll）来监控多个文件描述符（Socket），当其中有一个或多个文件描述符就绪（可读、可写或有错误）时，函数返回，通知应用程序进行相应的读写操作。

这样可以避免不必要的阻塞和轮询，提高IO效率和并发能力。

> select、poll和epoll

- select的最大缺点是单个进程能监视的文件描述符数量有限，一般为1024或2048，而poll和epoll没有这个限制¹²³⁴⁵。
- select每次调用都要把用户态的文件描述符集合拷贝到内核态，而poll和epoll只需要拷贝一次¹²³⁴⁵。
- select和poll都是采用轮询的方式来检查文件描述符的就绪状态，时间复杂度为O(n)，而epoll是基于事件通知的方式，时间复杂度为O(1)¹²³⁴⁵。
- select和poll返回的是整个文件描述符集合，应用程序需要遍历所有的文件描述符来找出就绪的，而epoll返回的是就绪的文件描述符列表，应用程序可以直接处理¹²³⁴⁵。
- epoll支持水平触发和边沿触发两种模式，而select和poll只支持水平触发¹²。水平触发是指只要文件描述符有就绪事件，就会通知应用程序；边沿触发是指只有文件描述符的就绪事件发生变化时，才会通知应用程序。

> 水平触发和边沿触发

水平触发和边沿触发是两种不同的事件通知模式，常用于epoll等IO多路复用技术中。¹²

水平触发（Level Triggered，LT）是指只要文件描述符有可读或可写的数据，就会一直触发事件通知，直到数据被处理完毕。¹²³ 水平触发的优点是简单易用，不会漏掉任何事件，缺点是可能会重复触发多次，浪费资源。²⁴

边沿触发（Edge Triggered，ET）是指只有文件描述符的状态发生变化（如从空变为非空，或从满变为不满），才会触发一次事件通知。¹²³ 边沿触发的优点是高效，只关注状态变化，缺点是需要一次性处理完所有数据，否则可能会丢失事件。²⁴

在epoll中，可以通过设置events参数来选择水平触发或边沿触发模式。默认情况下，epoll使用水平触发模式。如果要使用边沿触发模式，需要在events中加上EPOLLET标志。

> 高并发场景

select、poll和epoll都是多路复用技术，可以让一个线程同时监听多个文件描述符（fd），从而提高网络IO效率。

一般来说，epoll更适合高并发的场景，因为它有以下优势：

- epoll不需要**每次调用时都传输要监听的fd集合**，而是在内核中维护一个红黑树来存储要监听的fd，这样可以减少用户空间和内核空间的数据拷贝。
- epoll不需要**遍历所有的fd来检查哪些发生了事件**，而是通过回调函数和双向链表的方式，只返回发生了事件的fd，这样可以避免无效的轮询。
- epoll支持**边沿触发（ET）模式**，这种模式下，只有当fd的状态发生变化时才会触发事件通知，这样可以进一步减少事件的重复触发。
- epoll利用**内存映射（mmap**）的方式，让用户空间和内核空间共享同一块内存，这样可以避免返回事件时的数据拷贝。

select和poll相比较，主要有以下缺点：

- select和poll每次调用时都需要传输要监听的fd集合，并且select的fd集合大小受到FD_SETSIZE宏定义的限制
- select和poll每次返回时都需要遍历所有的fd来检查哪些发生了事件，这样会浪费很多CPU时间
- select和poll只支持水平触发（LT）模式，这种模式下，只要fd有可读或可写的数据，就会一直触发事件通知，直到数据被处理完毕。¹²
- select和poll返回事件时需要拷贝数据到用户空间，这样会增加内存开销



## 29、说一下中断

中断是指计算机运行过程中，出现某些意外情况或者特殊事件，需要主机干预或处理时，机器能自动停止正在运行的程序并转入处理新情况的程序，处理完毕后又返回原被暂停的程序继续运行。

> 分类

硬件中断是由外部设备或内部故障引起的，如键盘输入、鼠标点击、时钟信号、电源掉电等。

硬件中断可以进一步分为可屏蔽中断和不可屏蔽中断。可屏蔽中断是指可以通过程序控制是否响应的中断，如硬盘读写、打印机输出等。不可屏蔽中断是指必须立即处理的中断，如电源故障、硬件错误等。¹²

软件中断是由程序执行过程中引起的，如系统调用、异常、陷阱等。

系统调用是一种有意的、预先安排的异常事件，用于实现用户程序和操作系统之间的交互。

异常是一种意外的、非法的事件，如除零错误、缺页错误、越界访问等。

陷阱是一种用于调试或测试的事件，如断点设置、单步执行等。

> 中断管理

为了管理和响应不同的中断源，计算机系统需要使用中断控制器和中断描述符表。

中断控制器是一种硬件设备，用于接收和发送中断信号，并根据优先级进行排队和选择。

中断描述符表是一种数据结构，用于存放不同中断向量对应的中断描述符。每个中断描述符包含了相应的中断服务程序的起始地址和处理器状态字。当处理器收到一个中断向量号时，就会根据该号在中断描述符表中查找相应的描述符，并转入相应的服务程序。

> 中断流程

当一个中断发生时，一般会经历以下几个步骤：

- 中断源发出中断请求信号，通知处理器有新的事件需要处理。
- 处理器判断当前是否允许响应该中断，并根据优先级选择一个最高优先级的中断。
- 处理器执行完当前指令后，保存当前程序的状态信息（如寄存器值、标志位等），并根据特权级判断是否需要切换栈。
- 处理器根据中断向量号在中断描述符表中查找相应的描述符，并转入相应的服务程序。
- 处理器执行服务程序，完成对事件的处理。
- 处理器恢复被保存的状态信息，并执行“中断返回”指令，回到被暂停的程序继续运行。

> 中断和轮询

中断和轮询是两种不同的实现多任务处理的方式。

中断是一种硬件机制，可以让CPU在执行一个任务的过程中，暂时停止该任务，转而去执行另一个任务，称为中断服务程序。当中断服务程序执行完毕后，CPU再恢复原来的任务继续执行。这样，CPU就可以在不同的任务之间切换，实现多任务处理。

轮询是一种协议，可以让CPU定时或适当地检查每一个设备是否需要其服务。如果有设备需要服务，CPU就会暂时停止当前的任务，转而去执行相应的服务程序。当服务程序执行完毕后，CPU再恢复原来的任务继续执行。这样，CPU也可以在不同的任务之间切换，实现多任务处理。

中断和轮询之间的主要区别有以下几点：

- 中断是由设备主动通知CPU的，而轮询是由CPU主动查询设备的。
- 中断可以随时发生，而轮询是按照一定的顺序或间隔进行的。
- 中断是由中断处理程序提供服务的，而轮询是由CPU提供服务的。
- 中断需要中断控制器和中断描述符表来管理和响应不同的中断源，而轮询只需要检查设备的命令就绪位来判断是否需要服务。
- 中断可以提高系统的效率和响应性，但也会增加系统的复杂性和开销。而轮询可以简化系统的设计和实现，但也会浪费CPU的时间和资源。

> 软中断和软件中断

软中断和软件中断是两个不同的概念，虽然都是由软件触发的，但是有以下区别：

- 软中断是中断处理程序的下半部，用来延迟处理上半部未完成的工作，通常是耗时较长且复杂的事情。
- 软件中断是一种利用硬件中断的概念，用软件方式进行模拟，实现宏观上的异步执行效果。
- 软中断是在内核线程上下文中运行的，而软件中断是在进程上下文中运行的。
- 软中断可以被其他中断打断，而软件中断会屏蔽其他同级或低级的中断。
- 软中断可以睡眠，而软件中断不能睡眠。

在Linux系统中，一种典型的软件中断是系统调用，它通过汇编指令 int 0x80 来触发异常，切换CPU特权级，实现用户态到内核态的切换。

在Linux系统中，一种典型的软中断是网络接收中断，它由内核触发，在内核线程 ksoftirqd/CPU编号 上运行，用来从内存中读取网络数据，并按照网络协议栈进行逐层解析和处理。

> 软中断

软中断是一种内核提供的**延迟执行机制**，它完全由软件触发，不依赖于硬件设备。

软中断是**中断处理程序的下半部**，用来完成上半部未完成的工作，通常是耗时较长且复杂的事情。

软中断是**以内核线程的方式运行**，每个CPU都有一个对应的软中断内核线程，名字通常为 ksoftirqd/CPU编号 。

软中断不只是包括硬件设备中断处理程序的下半部，一些内核自定义事件也属于软中断，比如内核调度、RCU锁等。

软中断可以**通过查看 /proc/softirqs 文件来了解其运行情况**，文件中显示了每个CPU上不同类型的软中断的累计运行次数



## 30、说一下Cache

Cache用于存放一些经常使用或者最近使用的数据，减少对慢速存储器（如内存、硬盘等）的访问次数，从而提高系统的性能。

> 类型层次

根据Cache与CPU的距离，分为L1 Cache（一级缓存）、L2 Cache（二级缓存）、L3 Cache（三级缓存）

根据Cache与主存的映射关系，分为直接映射Cache、组相联Cache和全相联Cache

根据Cache中存储的数据类型，分为指令Cache（I-Cache）和数据Cache（D-Cache）

> 映射方式

直接映射Cache是指主存中的每个块只能映射到Cache中的一个固定位置，这种方式简单高效，但是容易发生冲突。

组相联Cache是指主存中的每个块可以映射到Cache中的一组位置中的任意一个，这种方式可以减少冲突，但是需要更多的比较电路。

全相联Cache是指主存中的每个块可以映射到Cache中的任意位置，这种方式可以最大程度地利用Cache空间，但是需要复杂的搜索算法和硬件支持

> 缓存一致性

缓存和主存之间的一致性是指缓存中的数据与主存中的数据保持相同的值。

缓存和主存之间的一致性问题主要是由于以下两个原因引起的：

- 缓存更新策略：当缓存中的数据被修改时，是否立即写回主存，或者等到缓存被替换时才写回主存。
- 缓存共享问题：当多个处理器或者核心都有各自的缓存时，如何保证它们对同一块主存数据的访问和修改不会造成冲突或者不一致。

解决方法：MESI 协议

- 将缓存中的每个数据块标记为四种状态：Modified（已修改）、Exclusive（独占）、Shared（共享）和 Invalid（无效），并根据不同的操作来改变状态和传输数据。

> 提高命中率

要想写出让 CPU 跑得更快的代码，就需要写出缓存命中率高的代码，CPU L1 Cache 分为数据缓存和指令缓存，因而需要分别提高它们的缓存命中率：

- 对于数据缓存，我们在遍历数据的时候，应该按照内存布局的顺序操作，这是因为 CPU Cache 是根据 CPU Cache Line 批量操作数据的，所以顺序地操作连续内存数据时，性能能得到有效的提升；
- 对于指令缓存，有规律的条件分支语句能够让 CPU 的分支预测器发挥作用，进一步提高执行的效率；

另外，对于多核 CPU 系统，线程可能在不同 CPU 核心来回切换，这样各个核心的缓存命中率就会受到影响，于是要想提高线程的缓存命中率，可以考虑把线程绑定 CPU 到某一个 CPU 核心。



## 31、说一下磁盘调度

磁盘调度是指操作系统根据磁盘的访问请求，选择合适的顺序来处理这些请求，以提高磁盘的访问性能。

磁盘调度的目标是减少磁头的移动距离和等待时间，从而缩短磁盘的平均存取时间。

常见的磁盘调度算法有以下几种：

- 先来先服务（FCFS）算法：按照请求到达的先后顺序，依次处理请求。这种算法比较公平，但是效率不高，可能会产生大量的寻道时间。
- 最短寻道时间优先（SSTF）算法：每次选择距离当前磁头位置最近的请求进行处理。这种算法可以减少寻道时间，但是可能会导致一些远离磁头位置的请求长期得不到服务，产生饥饿现象。
- 扫描（SCAN）算法：也称为电梯算法，磁头在一个方向上移动，处理所有未完成的请求，直到到达该方向上的最后一个柱面，然后改变方向，继续处理。这种算法可以避免饥饿现象，但是对于中间部分的柱面响应较快，边缘部分响应较慢。
- 循环扫描（C-SCAN）算法：与扫描算法类似，但是当磁头到达一个方向上的最后一个柱面时，不改变方向，而是直接返回到另一端的第一个柱面，并继续同一方向上的移动。这种算法可以使每个柱面的响应频率更加平均。
- LOOK和C-LOOK算法：这两种算法是对扫描算法和循环扫描算法的优化，它们不需要磁头移动到最远的柱面，而是在没有更多请求的方向上提前改变方向或返回。LOOK算法在改变方向或返回时仍然会处理请求，而C-LOOK算法则不会。



## 32、说一下锁的种类

- 根据锁的实现方式，可以分为**互斥锁**和**自旋锁**。互斥锁是指当一个线程获取锁后，其他线程会被阻塞挂起，直到锁被释放。自旋锁是指当一个线程获取锁后，其他线程会不断地循环检查锁是否可用，而不会被挂起²⁴。
- 根据锁的粒度，可以分为**对象锁**和**类锁**。对象锁是指针对某个对象实例加锁，只有该对象的同步方法或同步代码块才会受到影响。类锁是指针对某个类加锁，该类的所有对象实例的同步方法或同步代码块都会受到影响¹。
- 根据锁的访问规则，可以分为**独占锁**和**共享锁**。独占锁是指一次只能有一个线程持有该锁，其他线程必须等待。共享锁是指一次可以有多个线程同时持有该锁，但是可能会受到一定的限制¹。
- 根据锁的重入性，可以分为**可重入锁**和**不可重入锁**。可重入锁是指在同一个线程中，可以多次获得同一个锁，而不会被自己所持有的锁所阻塞。不可重入锁是指在同一个线程中，只能获得同一个锁一次，如果再次尝试获取该锁，就会造成死锁¹²。
- 根据锁的公平性，可以分为**公平锁**和**非公平锁**。公平锁是指多个线程按照申请锁的顺序来获取锁，遵循先来先得的原则。非公平锁是指多个线程获取锁的顺序并不固定，有可能后来的线程先获取到锁¹²。
- 根据对写操作的处理方式，可以分为**悲观锁**和**乐观锁**。悲观锁是指在对共享数据进行写操作之前，先对数据加上排他性的独占锁，防止其他线程对数据进行修改。乐观锁是指在对共享数据进行写操作之前，并不加任何锁，而是通过一些机制（如版本号、CAS等）来判断数据是否被修改过

> 应用场景

- 共享数据的访问模式：如果你的共享数据主要是读操作，而写操作很少，那么你可以考虑使用**读写锁**，这样可以提高读操作的并发性。如果你的共享数据既有读操作又有写操作，那么你可以考虑使用**独占锁**，这样可以保证数据的一致性。
- 共享数据的修改频率：如果你的共享数据经常被修改，那么你可以考虑使用**悲观锁**，这样可以避免频繁的冲突检测和回滚操作。如果你的共享数据很少被修改，那么你可以考虑使用**乐观锁**，这样可以减少加锁和解锁的开销。
- 线程竞争的程度：如果你的线程竞争很激烈，那么你可以考虑使用**公平锁**，这样可以避免某些线程长时间等待或饥饿。如果你的线程竞争不太激烈，那么你可以考虑使用**非公平锁**，这样可以减少线程切换和调度的开销。
- 线程持有锁的时间：如果你的线程持有锁的时间很长，那么你可以考虑使用**互斥锁**，这样可以避免其他线程浪费CPU资源。如果你的线程持有锁的时间很短，那么你可以考虑使用**自旋锁**，这样可以避免线程切换和挂起的开销。
- 线程重复获取同一把锁的次数：如果你的线程需要重复获取同一把锁多次，那么你可以考虑使用**可重入锁**，这样可以避免死锁和递归调用的问题。如果你的线程不需要重复获取同一把锁多次，那么你可以考虑使用**不可重入锁**，这样可以简化锁的实现和管理。

## 33、说一下DMA

在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，

CPU 不再参与任何与数据搬运相关的事情，可以去处理别的事务

> DMA过程

- 用户进程调用 read 方法，向操作系统发出 I/O 请求，请求读取数据到自己的内存缓冲区中，进程进入阻塞状态；
- 操作系统收到请求后，进一步将 I/O 请求发送 DMA，然后让 CPU 执行其他任务；
- DMA 进一步将 I/O 请求发送给磁盘；
- 磁盘收到 DMA 的 I/O 请求，把数据从磁盘读取到磁盘控制器的缓冲区中，当磁盘控制器的缓冲区被读满后，向 DMA 发起中断信号，告知自己缓冲区已满；
- **DMA 收到磁盘的信号，将磁盘控制器缓冲区中的数据拷贝到内核缓冲区中，此时不占用 CPU，CPU 可以执行其他任务**；
- 当 DMA 读取了足够多的数据，就会发送中断信号给 CPU；
- CPU 收到 DMA 的信号，知道数据已经准备好，于是将数据从内核拷贝到用户空间，系统调用返回；





## 34、说一下零拷贝

零拷贝是一种IO优化技术，它的目的是减少数据在用户空间和内核空间之间的拷贝次数，以及减少CPU的上下文切换次数，从而提高数据传输的效率

零拷贝的原理是利用虚拟内存的特性，让多个虚拟地址指向同一个物理地址，从而避免不必要的数据复制。零拷贝还可以利用DMA技术，让外设和内存之间直接进行数据交换，而不需要CPU的参与

> 实现方式

例如mmap+write、sendfile、带有DMA收集拷贝功能的sendfile

> 项目

Kafka、Netty、RocketMQ、nginx

一般来说，使用零拷贝的项目都会调用一些系统函数或库函数，如mmap、sendfile、transferTo等，来实现内存映射或直接从文件到网络的数据传输，从而减少用户态和内核态之间的上下文切换和数据拷贝



## 35、说一下文件存储

> 磁盘空间分配方式

- 连续分配：文件的数据块在磁盘上是连续存放的，每个文件只需要记录起始块号和长度即可。这种方式简单且方便检索，但是会造成外部碎片，即磁盘上有许多小的空闲块无法利用。
- 链接分配：文件的数据块在磁盘上可以是不连续的，每个数据块除了存储数据外，还要存储下一个数据块的地址，形成一个链表。这种方式不会产生外部碎片，但是会增加存储开销和检索时间，而且容易造成内部碎片，即数据块中有未使用的空间。
- 索引分配：文件的数据块在磁盘上可以是不连续的，但是不需要在每个数据块中存储下一个数据块的地址，而是在一个单独的索引块中存储所有数据块的地址。这种方式克服了链接分配的缺点，但是需要额外的索引块，并且索引块的大小有限制。

> 存储格式

- 文本格式：文件的数据以文本的形式存储，每个字符占用一个字节，每行以换行符结束。文本格式的文件易于阅读和编辑，但是占用空间较大，且不适合存储复杂的结构化数据。
- 二进制格式：文件的数据以二进制的形式存储，每个字节由8个位组成，可以表示不同的数据类型，如整数、浮点数、字符等。二进制格式的文件占用空间较小，且可以存储复杂的结构化数据，但是不易于阅读和编辑。
- 序列化格式：文件的数据以一种特定的规则将对象或结构转换为二进制流的形式存储，可以实现对象或结构的持久化和传输。序列化格式的文件可以存储复杂的结构化数据，并且可以跨平台和语言使用，但是需要特定的工具或库来进行序列化和反序列化操作。
- 压缩格式：文件的数据以一种特定的算法将原始数据进行压缩，减少冗余信息，降低存储空间。压缩格式的文件可以节省存储空间，并且可以提高传输速度，但是需要特定的工具或库来进行压缩和解压缩操作。

> 文件存储过程

- 文件系统为文件分配一个唯一的标识符，称为inode号，用来存储文件的元数据，如文件名、大小、权限、时间戳等。
- 文件系统在存储设备上寻找空闲的空间，称为块或簇，用来存储文件的数据。一个文件可能占用一个或多个块或簇，根据文件的大小和存储设备的特性而定。
- 文件系统将文件的inode号和块或簇号之间建立映射关系，称为索引或链接，用来记录文件的物理位置。索引或链接可以有多种形式，如连续分配、链接分配、索引分配等。
- 文件系统将文件的元数据和数据写入到存储设备上对应的inode和块或簇中，完成文件的存储。

> 空闲空间管理

- 空闲表法：用一张表来记录磁盘上的所有空闲区域，每个表项包含空闲区的起始块号和长度。分配时，按照某种策略（如首次适应、最佳适应、最坏适应等）从表中选择一个合适的空闲区，修改表项和分区表。回收时，将回收的区域加入到表中，合并相邻的空闲区，修改表项和分区表。
- 空闲链表法：用一条链表来记录磁盘上的所有空闲区域，每个链表节点包含空闲区的起始块号和长度，以及指向下一个节点的指针。分配时，按照某种策略（如首次适应、最佳适应、最坏适应等）从链表中选择一个合适的空闲区，修改链表节点和分区表。回收时，将回收的区域插入到链表中，合并相邻的空闲区，修改链表节点和分区表。
- 位示图法：用一个位数组来记录磁盘上的所有块的使用情况，每个块对应一个位，0表示空闲，1表示占用。分配时，按照某种策略（如顺序扫描、随机扫描等）从位数组中找到一个或多个连续的0位，将其置为1，返回对应的块号。回收时，将回收的块对应的位置为0。
- 成组链接法：用一种类似于散列的方法来记录磁盘上的所有空闲块，将磁盘划分为若干组，每组包含若干个连续的块。每组中第一个块用来存储本组中剩余空闲块的数量和块号，以及下一组第一个块的块号。分配时，从当前组中选择一个空闲块分配出去，修改当前组第一个块的信息。如果当前组没有空闲块了，则转到下一组，并将原来的当前组加入到新当前组中。回收时，将回收的块插入到当前组中，并修改当前组第一个块的信息。



## 36、说一下Mysql索引

> 类型

从物理存储的角度来看，索引分为聚簇索引（主键索引）、二级索引（辅助索引）。

这两个区别在前面也提到了：

- **主键索引**的 B+Tree 的叶子节点存放的是实际数据，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里；
- **二级索引**的 B+Tree 的叶子节点存放的是主键值，而不是实际数据。

所以，在查询时使用了二级索引，如果查询的数据能在二级索引里查询的到，那么就不需要回表，这个过程就是覆盖索引。如果查询的数据不在二级索引里，就会先检索二级索引，找到对应的叶子节点，获取到主键值后，然后再检索主键索引，就能查询到数据了，这个过程就是回表。



从字段特性的角度来看

**主键索引**

主键索引就是建立在主键字段上的索引，通常在创建表的时候一起创建，一张表最多只有一个主键索引，索引列的值不允许有空值。

在创建表时，创建主键索引的方式如下：

```sql
CREATE TABLE table_name  (
  ....
  PRIMARY KEY (index_column_1) USING BTREE
);
```

**唯一索引**

唯一索引建立在 UNIQUE 字段上的索引，一张表可以有多个唯一索引，索引列的值必须唯一，但是允许有空值。

在创建表时，创建唯一索引的方式如下：

```sql
CREATE TABLE table_name  (
  ....
  UNIQUE KEY(index_column_1,index_column_2,...) 
);
```

建表后，如果要创建唯一索引，可以使用这面这条命令：

```sql
CREATE UNIQUE INDEX index_name
ON table_name(index_column_1,index_column_2,...); 
```

**普通索引**

普通索引就是建立在普通字段上的索引，既不要求字段为主键，也不要求字段为 UNIQUE。

在创建表时，创建普通索引的方式如下：

```sql
CREATE TABLE table_name  (
  ....
  INDEX(index_column_1,index_column_2,...) 
);
```

建表后，如果要创建普通索引，可以使用这面这条命令：

```sql
CREATE INDEX index_name
ON table_name(index_column_1,index_column_2,...); 
```

**前缀索引**

前缀索引是指对字符类型字段的前几个字符建立的索引，而不是在整个字段上建立的索引，前缀索引可以建立在字段类型为 char、 varchar、binary、varbinary 的列上。

使用前缀索引的目的是为了减少索引占用的存储空间，提升查询效率。

在创建表时，创建前缀索引的方式如下：

```sql
CREATE TABLE table_name(
    column_list,
    INDEX(column_name(length))
); 
```

建表后，如果要创建前缀索引，可以使用这面这条命令：

```sql
CREATE INDEX index_name
ON table_name(column_name(length)); 
```



从字段个数的角度来看，索引分为**单列索引**、**联合索引**（复合索引）。

- 建立在单列上的索引称为单列索引，比如主键索引；
- 建立在多列上的索引称为联合索引

> 联合索引匹配原则

使用联合索引时，存在**最左匹配原则**，也就是按照最左优先的方式进行索引的匹配。

**联合索引的最左匹配原则，在遇到范围查询（>、<、between、like 包括like '林%'这种）的时候，就会停止匹配，也就是范围列可以用到联合索引，但是范围列后面的列无法用到联合索引**。

- 在 MySQL 5.6 之前，只能从 ID2 （主键值）开始一个个回表，到「主键索引」上找出数据行，再对比 b 字段值。
- 而 MySQL 5.6 引入的**索引下推优化**（index condition pushdown)， **可以在联合索引遍历过程中，对联合索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数**。

> 实现原理

B+Tree 是一种多叉树，叶子节点才存放数据，非叶子节点只存放索引，而且每个节点里的数据是**按主键顺序存放**的。每一层父节点的索引值都会出现在下层子节点的索引值中，因此在叶子节点中，包括了所有的索引值信息，并且每一个叶子节点都指向下一个叶子节点，形成一个链表。

1、B+Tree vs B Tree

B+Tree 只在叶子节点存储数据，而 B 树 的非叶子节点也要存储数据，所以 B+Tree 的单个节点的数据量更小，在相同的磁盘 I/O 次数下，就能查询更多的节点。

另外，B+Tree 叶子节点采用的是双链表连接，适合 MySQL 中常见的基于范围的顺序查找，而 B 树无法做到这一点。

***2、B+Tree vs 二叉树***

对于有 N 个叶子节点的 B+Tree，其搜索复杂度为`O(logdN)`，其中 d 表示节点允许的最大子节点个数为 d 个。

在实际的应用当中， d 值是大于100的，这样就保证了，即使数据达到千万级别时，B+Tree 的高度依然维持在 3~4 层左右，也就是说一次数据查询操作只需要做 3~4 次的磁盘 I/O 操作就能查询到目标数据。

而二叉树的每个父节点的儿子节点个数只能是 2 个，意味着其搜索复杂度为 `O(logN)`，这已经比 B+Tree 高出不少，因此二叉树检索到目标数据所经历的磁盘 I/O 次数要更多。

***3、B+Tree vs Hash***

Hash 在做等值查询的时候效率贼快，搜索复杂度为 O(1)。

但是 Hash 表不适合做范围查询，它更适合做等值的查询，这也是 B+Tree 索引要比 Hash 表索引有着更广泛的适用场景的原因

> 使用场景

适用索引

- 字段有**唯一性限制**的，比如商品编码；
- 经常**用于 `WHERE` 查询条件的字段**，这样能够提高整个表的查询速度，如果查询条件不是一个字段，可以建立联合索引。
- **经常用于 `GROUP BY` 和 `ORDER BY` 的字段**，这样在查询的时候就不需要再去做一次排序了，因为我们都已经知道了建立索引之后在 B+Tree 中的记录都是排序好的。

不需要创建索引

- **`WHERE` 条件，`GROUP BY`，`ORDER BY` 里用不到的字段**，索引的价值是快速定位，如果起不到定位的字段通常是不需要创建索引的，因为索引是会占用物理空间的。
- 字段中存在**大量重复数据**，不需要创建索引，比如性别字段，只有男女，如果数据库表中，男女的记录分布均匀，那么无论搜索哪个值都可能得到一半的数据。在这些情况下，还不如不要索引，因为 MySQL 还有一个查询优化器，查询优化器发现某个值出现在表的数据行中的百分比很高的时候，它一般会忽略索引，进行全表扫描。
- 表**数据太少**的时候，不需要创建索引；
- **经常更新的字段**不用创建索引，比如不要对电商项目的用户余额建立索引，因为索引字段频繁修改，由于要维护 B+Tree的有序性，那么就需要频繁的重建索引，这个过程是会影响数据库性能的。

> 索引失效

- 当我们使用左或者左右模糊匹配的时候，也就是 `like %xx` 或者 `like %xx%`这两种方式都会造成索引失效；
- 当我们在查询条件中对**索引列做了计算、函数、类型转换操**作，这些情况下都会造成索引失效；
- 联合索引要能正确使用需要遵循**最左匹配原则**，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效。
- 在 WHERE 子句中，如果在 **OR 前**的条件列是索引列，而在 **OR 后**的条件列不是索引列，那么索引会失效。

> 索引优化

- 前缀索引优化；
- 覆盖索引优化；
- 主键索引最好是自增的；
- 防止索引失效；
- 主键字段的长度不要太大
- 索引最好设置为 NOT NULL

> 查看执行计划

在查询语句前加explain查看执行计划

对于执行计划，参数有：

- possible_keys 字段表示可能用到的索引；
- key 字段表示实际用的索引，如果这一项为 NULL，说明没有使用索引；
- key_len 表示索引的长度；
- rows 表示扫描的数据行数。
- type 表示数据扫描类型，我们需要重点看这个。、



## 37、说一下Mysql事务

> 事务的特性

- **原子性（Atomicity）**：一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样，就好比买一件商品，购买成功时，则给商家付了钱，商品到手；购买失败时，则商品在商家手中，消费者的钱也没花出去。
- **一致性（Consistency）**：是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态。比如，用户 A 和用户 B 在银行分别有 800 元和 600 元，总共 1400 元，用户 A 给用户 B 转账 200 元，分为两个步骤，从 A 的账户扣除 200 元和对 B 的账户增加 200 元。一致性就是要求上述步骤操作后，最后的结果是用户 A 还有 600 元，用户 B 有 800 元，总共 1400 元，而不会出现用户 A 扣除了 200 元，但用户 B 未增加的情况（该情况，用户 A 和 B 均为 600 元，总共 1200 元）。
- **隔离性（Isolation）**：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致，因为多个事务同时使用相同的数据时，不会相互干扰，每个事务都有一个完整的数据空间，对其他并发事务是隔离的。也就是说，消费者购买商品这个事务，是不影响其他消费者购买的。
- **持久性（Durability）**：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。

> 并行事务问题

**脏读**：如果一个事务「读到」了另一个「未提交事务修改过的数据」，就意味着发生了「脏读」现象。

**不可重复读：**在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了「不可重复读」现象。

**幻读：**在一个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了「幻读」现象，通过锁机制解决幻读问题。

> 事务隔离级别

**读未提交（read uncommitted）**，指一个事务还没提交时，它做的变更就能被其他事务看到；

**读提交（read committed）**，指一个事务提交之后，它做的变更才能被其他事务看到；

**可重复读（repeatable read）**，指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，**MySQL InnoDB 引擎的默认隔离级别**；

**串行化（serializable ）**，会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；

> 实现原理

- 对于「读未提交」隔离级别的事务来说，因为可以读到未提交事务修改的数据，所以直接读取最新的数据就好了；

- 对于「串行化」隔离级别的事务来说，通过加读写锁的方式来避免并行访问；

- 对于「读提交」和「可重复读」隔离级别的事务来说，它们是通过Read View 来实现的，它们的区别在于创建 Read View 的时机不同，然后通过MVCC机制实现记录的是否可见。

  「读提交」隔离级别是在「每个语句执行前」都会重新生成一个 Read View。

  「可重复读」隔离级别是「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View

> 两阶段提交

MySQL两阶段提交是指在事务提交时，MySQL需要将事务的修改操作记录到两种日志中，分别是redo log和binlog，以保证事务的持久性和一致性。

MySQL两阶段提交的流程如下：

- 当事务执行修改数据的操作时，InnoDB存储引擎会先记录redo log，并修改内存中的数据页，此时redo log处于prepare状态，表示准备提交。
- 当事务执行commit命令时，MySQL服务器会先记录binlog，并将binlog写入磁盘，此时binlog处于commit状态，表示已经提交。
- 然后MySQL服务器会通知InnoDB存储引擎提交事务，InnoDB存储引擎会将redo log改为commit状态，并将数据页刷新到磁盘上，完成事务的提交。

MySQL两阶段提交的目的是为了保证redo log和binlog的一致性，避免在数据库发生异常重启或崩溃时，出现数据丢失或不一致的情况。

如果只有redo log而没有binlog，那么在恢复数据时，无法进行主从复制或者点查恢复。

如果只有binlog而没有redo log，那么在恢复数据时，可能出现数据不完整或者不正确的情况。

> 两阶段提交问题

两阶段提交虽然保证了两个日志文件的数据一致性，但是性能很差，主要有两个方面的影响：

- **磁盘 I/O 次数高**：对于“双1”配置，每个事务提交都会进行两次 fsync（刷盘），一次是 redo log 刷盘，另一次是 binlog 刷盘。
- **锁竞争激烈**：两阶段提交虽然能够保证「单事务」两个日志的内容一致，但在「多事务」的情况下，却不能保证两者的提交顺序一致，因此，在两阶段提交的流程基础上，还需要加一个锁来保证提交的原子性，从而保证多事务的情况下，两个日志的提交顺序一致。

解决办法：组提交

## 38、说一下Mysql锁机制

Mysql锁机制是一种用于协调多个事务并发访问同一共享资源的机制。

Mysql锁机制可以按照不同的标准进行分类，例如锁的粒度、锁的方式、锁的思想等。

Mysql锁机制的实现也取决于存储引擎的类型，例如MyISAM只支持表级锁，而InnoDB支持表级锁和行级锁。

> 锁分类

- 按照锁的粒度或范围，可以分为全局锁、表级锁、页级锁和行级锁。全局锁是对整个数据库实例加锁，表级锁是对某个表加锁，页级锁是对某个数据页加锁，行级锁是对某个数据行加锁。一般来说，锁的粒度越小，发生冲突的概率越低，但是开销越大。

- 按照锁的使用方式，可以分为共享锁和排他锁。共享锁是允许多个事务同时读取同一个资源，但不允许写操作。排他锁是只允许一个事务对资源进行读写操作，其他事务都不能访问。一般来说，共享锁和排他锁是互斥的，也就是说一个资源上不能同时存在共享锁和排他锁。

- 按照锁的思想，可以分为乐观锁和悲观锁。乐观锁是指在读写数据时，认为其他事务不会修改数据，所以不会加任何锁，只在提交更新时检查数据是否被修改过。悲观锁是指在读写数据时，认为其他事务会修改数据，所以会加相应的共享锁或排他锁，阻止其他事务的访问。一般来说，乐观锁适合于读多写少的场景，可以提高并发性能；悲观锁适合于写多读少的场景，可以保证数据的一致性。

- 行锁的具体分类：

  记录锁（Record Lock）：记录锁锁定索引中的一条记录。

  间隙锁（Gap Lock）：间隙锁要么锁住索引记录中间的值，要么锁住第一个索引记录前面的值或最后一个索引记录后面的值。

  Next-Key Lock：Next-Key锁时索引记录上的记录锁和在记录之前的间隙锁的组合。

> 如何选择合适的锁类型和粒度

需要根据具体的场景和需求来进行权衡和优化

- 存储引擎的选择。不同的存储引擎支持不同的锁类型和粒度，例如MyISAM只支持表级锁，InnoDB支持表级锁和行级锁。存储引擎的选择也会影响数据的一致性、完整性、可靠性等方面，例如InnoDB支持ACID事务，MyISAM不支持
- 事务隔离级别的选择。不同的事务隔离级别会影响锁的行为和性能，例如在READ COMMITTED级别下，读操作需要加共享锁，但是在语句执行完以后释放共享锁；而在REPEATABLE READ级别下，读操作需要加共享锁，但是在事务提交之前并不释放共享锁。事务隔离级别的选择也会影响数据的一致性和并发性，例如在READ UNCOMMITTED级别下，可能出现脏读问题；而在SERIALIZABLE级别下，可能出现并发性能低下的问题。
- 索引设计的选择。索引可以提高查询效率，但也会影响锁的粒度和范围，例如InnoDB是**基于索引来完成行锁**的，如果没有合适的索引，可能导致全表扫描和全表锁定。索引设计的选择也会影响数据的更新效率和空间占用，例如过多或过大的索引会增加数据修改的开销和磁盘空间的消耗。
- SQL语句编写的选择。SQL语句编写的方式会影响锁的获取和释放时机和方式，例如使用SELECT ... FOR UPDATE或SELECT ... LOCK IN SHARE MODE可以显式地加排他锁或共享锁；使用START TRANSACTION WITH CONSISTENT SNAPSHOT可以避免加任何锁；使用COMMIT或ROLLBACK可以释放所有事务中的锁等。SQL语句编写的选择也会影响数据的正确性和效率，例如避免使用不必要或冗余的查询条件、子查询、连接等。

> mysql是如何加锁的如何加锁

+ 分为查询语句和修改语句 
+ 查询分为快照读和当前读
+ 当前读才会出现幻读

前提一：id列是不是主键？

前提二：当前系统的隔离级别是什么？

前提三：id列如果不是主键，那么id列上有索引吗？

前提四：id列上如果有二级索引，那么这个索引是唯一索引吗？

前提五：两个SQL的执行计划是什么？索引扫描？全表扫描？

组合一：id列是主键，RC隔离级别

+ 将主键上，id = 10的记录加上X锁

组合二：id列是二级唯一索引，RC隔离级别

+ 由于id是unique索引，因此delete语句会选择走id列的索引进行where条件的过滤，在找到id=10的记录后，首先会将unique索引上的id=10索引记录加上X锁，同时，会根据读取到的name列，回主键索引(聚簇索引)，然后将聚簇索引上的name = ‘d’ 对应的主键索引项加X锁

组合三：id列是二级非唯一索引，RC隔离级别

+ 若id列上有非唯一索引，那么对应的所有满足SQL查询条件的记录，都会被加锁。同时，这些记录在主键索引上的记录，也会被加锁。

组合四：id列上没有索引，RC隔离级别

+ 若id列上没有索引，SQL会走聚簇索引的全扫描进行过滤，由于过滤是由MySQL Server层面进行的。因此每条记录，无论是否满足条件，都会被加上X锁。但是，为了效率考量，MySQL做了优化，对于不满足条件的记录，会在判断后放锁，最终持有的，是满足条件的记录上的锁，但是不满足条件的记录上的加锁/放锁动作不会省略

组合五：id列是主键，RR隔离级别

+ 将主键上，id = 10的记录加上X锁

组合六：id列是二级唯一索引，RR隔离级别

+ 由于id是unique索引，因此delete语句会选择走id列的索引进行where条件的过滤，在找到id=10的记录后，首先会将unique索引上的id=10索引记录加上X锁，同时，会根据读取到的name列，回主键索引(聚簇索引)，然后将聚簇索引上的name = ‘d’ 对应的主键索引项加X锁

组合七：id列是二级非唯一索引，RR隔离级别

+ 首先，通过id索引定位到第一条满足查询条件的记录，加记录上的X锁，加GAP上的GAP锁，然后加主键聚簇索引上的记录X锁，然后返回；然后读取下一条，重复进行。直至进行到第一条不满足条件的记录[11,f]，此时，不需要加记录X锁，但是仍旧需要加GAP锁，最后返回结束。
+ GAP锁的目的，是为了防止同一事务的两次当前读，出现幻读的情况。

组合八：id列上没有索引，RR隔离级别

+ 首先，聚簇索引上的所有记录，都被加上了X锁。其次，聚簇索引每条记录间的间隙(GAP)，也同时被加上了GAP锁。
+ 全表锁死

组合九：Serializable隔离级别

+ 在MySQL/InnoDB中，所谓的读不加锁，并不适用于所有的情况，而是隔离级别相关的。Serializable隔离级别，读不加锁就不再成立，所有的读操作，都是当前读。



## 39、说一下MVCC

Mysql的MVCC是多版本并发控制的缩写，它是一种提高数据库并发性能的机制，主要用于解决读写冲突的问题。

MVCC在Mysql的InnoDB引擎中实现，它基于两个隐藏的列（trx_id和roll_ptr）和undo log来构建每行记录的版本链，以及一个ReadView来存储当前活跃的事务id列表。

MVCC只在read-committed和repeatable-read两个隔离级别下工作，它通过比较事务id和ReadView来判断哪个版本的记录对当前事务可见。

> 实现原理

MVCC的具体原理是利用每行记录的两个隐藏字段（trx_id和roll_ptr），undo log和ReadView来实现多版本并发控制的。

具体过程如下：

- 当一个事务开始时，它会从数据库获取一个自增的事务ID，作为该事务的版本号。
- 当一个事务要修改一行记录时，它会先把该行记录的原始数据复制到undo log中，并记录该行记录的trx_id和roll_ptr。
- 然后，它会修改该行记录的数据，并更新该行记录的trx_id为当前事务的版本号。
- 当一个事务要读取一行记录时，它会先生成一个ReadView，保存当前活跃的事务列表和最大最小的事务ID。
- 然后，它会根据该行记录的trx_id和ReadView中的信息来判断该行记录是否对当前事务可见。
- 如果不可见，它会沿着该行记录的roll_ptr指针找到undo log中的历史版本，并重复上述判断过程，直到找到一个可见的版本或者没有更早的版本为止。

> MVCC和乐观锁

MVCC可以和乐观锁结合使用，也可以和悲观锁结合使用。例如，在InnoDB中，MVCC是基于乐观并发控制实现的，即在提交更新时检查版本号或时间戳是否发生变化，如果变化则说明有冲突，否则就提交。而在PostgreSQL中，MVCC是基于悲观并发控制实现的，即在更新数据时加锁，防止其他事务修改同一行数据。²⁴

因此，MVCC和乐观锁并不是完全等价或对立的概念，而是有交叉和区别的。MVCC是一种具体的技术方案，而乐观锁是一种抽象的思想原则。MVCC可以利用乐观锁的思想来实现，并发控制，也可以利用悲观锁的思想来实现，并发控制。

## 40、说一下Mysql事务日志

redolog和undolog是InnoDB存储引擎的两种日志，用于实现事务的原子性和持久性，以及多版本并发控制（MVCC）。

redolog是重做日志，用于记录对数据页的物理修改，以二进制格式保存在磁盘上。redolog采用循环写入的方式，分为多个固定大小的文件组成。redolog的作用是在数据库发生异常重启或崩溃时，根据日志内容恢复数据，保证事务的持久性。redolog也称为前滚日志，因为它是按照时间顺序重做修改操作。

undolog是回滚日志，用于记录数据页的逻辑修改，以链表结构保存在表空间中。undolog有两个作用：一是在事务回滚时，根据日志内容撤销修改，恢复数据到原始状态，保证事务的原子性；二是在MVCC中，提供行的旧版本数据给其他事务读取，保证事务的隔离性和一致性。undolog也称为后滚日志，因为它是按照逆序取消修改操作。

> redolog和undolog的区别

- redolog记录的是数据页的物理修改，undolog记录的是数据页的逻辑修改。
- redolog保存在磁盘上的二进制文件中，undolog保存在表空间中的链表结构中。
- redolog用于恢复数据，保证事务的持久性，undolog用于回滚数据，保证事务的原子性和隔离性。
- redolog是按照时间顺序重做修改操作，undolog是按照逆序取消修改操作。

> 刷盘时机

- redolog的刷盘时机，由参数innodb_flush_log_at_trx_commit控制，该参数有三个可选值：0、1、2。

  1表示在每次事务提交时，将redolog buffer中的内容刷到redolog文件中，并且调用fsync()函数将文件缓冲区的内容刷到磁盘上，这是最安全但也最慢的方式；

  2表示在每次事务提交时，只将redolog buffer中的内容刷到redolog文件中，不调用fsync()函数，而是由操作系统定期刷盘，这是比较快但也比较危险的方式；

  0表示不在每次事务提交时刷盘，而是每秒钟刷一次，这是最快但也最不安全的方式。

- undolog的刷盘时机，由参数innodb_flush_method控制，该参数有三个可选值：fsync、O_DSYNC、O_DIRECT。

  fsync表示在每次事务提交时，将undolog buffer中的内容刷到undolog文件中，并且调用fsync()函数将文件缓冲区的内容刷到磁盘上，这是最安全但也最慢的方式；

  O_DSYNC表示在每次事务提交时，只将undolog buffer中的内容刷到undolog文件中，不调用fsync()函数，而是使用O_DSYNC标志打开文件，让操作系统保证数据写入磁盘后才返回，这是比较快但也比较危险的方式；

  O_DIRECT表示在每次事务提交时，直接将undolog buffer中的内容绕过文件缓冲区写入磁盘上，这是最快但也最不安全的方式



## 41、说一下Mysql主从复制

> binlog

binlog是MySQL的二进制日志，用于记录数据库执行的写入性操作（不包括查询）信息，以二进制的形式保存在磁盘中。binlog是MySQL的逻辑日志，并且由Server层进行记录，使用任何存储引擎的MySQL数据库都会记录binlog日志。

binlog的主要使用场景有两个，分别是主从复制和数据恢复。主从复制：在Master端开启binlog，然后将binlog发送到各个Slave端，Slave端重放binlog从而达到主从数据一致。数据恢复：通过使用mysqlbinlog工具来恢复数据。

binlog有三种格式，分别为STATMENT、ROW和MIXED。

STATMENT：基于SQL语句的复制 (statement-based replication, SBR)，每一条会修改数据的sql语句会记录到binlog中。ROW：基于行的复制 (row-based replication, RBR)，不记录每条sql语句的上下文信息，仅需记录哪条数据被修改了。MIXED：基于STATMENT和ROW两种模式的混合复制 (mixed-based replication, MBR)，一般的复制使用STATEMENT模式保存binlog，对于STATEMENT模式无法复制的操作使用ROW模式保存binlog。

> 实现原理

MySQL主从复制是指数据可以从一个MySQL数据库服务器主节点复制到一个或多个从节点。主从复制的目的是为了实现数据的备份、负载均衡、高可用性和故障恢复。

MySQL主从复制的原理是基于binlog日志的，主节点必须启用二进制日志，记录任何修改数据库数据的事件。

从节点开启一个线程I/O Thread把自己扮演成mysql的客户端，通过mysql协议，请求主节点的二进制日志文件中的事件，并将其保存到本地的中继日志（relay log）中。

从节点还开启另一个线程SQL Thread，从中继日志中读取事件，并在本地数据库中重放，从而实现与主节点的数据同步¹。

> 配置模型

MySQL主从复制有多种模型，常见的有以下几种：

- 一主一从模式：一个主节点对应一个从节点，这是最简单的模式，可以实现数据的备份和读写分离，提高数据的安全性和可用性。
- 主主模式：两个主节点互为对方的从节点，这是一种双向复制的模式，可以实现数据的双向同步和负载均衡，提高数据的一致性和性能。
- 一主多从模式：一个主节点对应多个从节点，这是一种单向复制的模式，可以实现数据的分布式备份和读写分离，提高数据的安全性和可扩展性。
- 多主一从模式：多个主节点对应一个从节点，这是一种多向复制的模式，可以实现数据的集中备份和负载均衡，提高数据的安全性和性能。
- 联级复制模式：一个主节点对应一个或多个中间节点，中间节点再对应一个或多个从节点，这是一种层次化的模式，可以实现数据的分级备份和读写分离，提高数据的安全性和可扩展性。



## 42、说一下Mysql缓存

> 缓存机制

MySQL缓存是指MySQL服务器在内存中缓存SQL文本及查询结果，以提高查询的性能和效率。

- MySQL缓存是以键值对的形式保存在内存中，键是SQL文本和一些其他条件，值是查询结果集。
- MySQL缓存是对大小写敏感的，SQL文本必须完全相同（包括空格、注释等）才能命中缓存。
- MySQL缓存只适用于SELECT语句，其他类型的语句不会被缓存。
- MySQL缓存只适用于确定性的查询，如果查询中包含不确定的函数（如NOW()，CURRENT_DATE()等），则结果不会被缓存。
- MySQL缓存是跨会话共享的，不同的客户端可以使用相同的缓存结果。
- MySQL缓存会在表的结构或数据发生变化时失效，任何修改表的操作（如INSERT，UPDATE，DELETE，ALTER TABLE等）都会导致该表相关的缓存被清空。
- MySQL缓存可以通过配置参数来开启、关闭或调优，也可以通过SQL命令来手动清理或控制缓存。

> 预读机制

MySQL缓存预读机制是指MySQL在读取数据时，根据一定的算法，提前将可能需要的数据页从磁盘读取到缓冲池中，以提高查询效率¹²³。

MySQL缓存预读机制有两种类型：

- 线性预读（linear read-ahead）：当MySQL顺序访问一个extent（64个连续的数据页）中的一定数量（由参数innodb_read_ahead_threshold控制）的数据页时，会触发线性预读请求，将下一个extent的数据页异步地读取到缓冲池中。
- 随机预读（random read-ahead）：当MySQL在一个extent中发现一些数据页已经在缓冲池中时，会触发随机预读请求，将该extent中的剩余数据页异步地读取到缓冲池中

> 预读失效

MySQL预读失效是指MySQL在缓存预读机制中，提前把数据页放入了缓冲池，但最终MySQL并没有从页中读取数据，导致缓冲池的空间浪费和热数据的淘汰¹²⁴。

MySQL预读失效的原因可能有以下几种：

- 查询语句使用了不确定的函数，如NOW()，CURRENT_DATE()等，导致缓存预读无法命中。
- 查询语句使用了全表扫描，如LIKE操作符，导致缓存预读将大量数据页加载到缓冲池中，但只访问一次。
- 查询语句使用了prepared statement，导致缓存预读无法识别相同的SQL文本。

MySQL预读失效的解决方法可能有以下几种：

- 优化查询语句，避免使用不确定的函数和全表扫描，尽量使用索引和确定的条件。
- 调整缓存预读相关的参数，如innodb_read_ahead_threshold（线性预读触发阈值），innodb_random_read_ahead（随机预读开关），innodb_old_blocks_time（老生代停留时间窗口）等。
- 使用SQL_NO_CACHE关键字强制不使用缓存预读，比较有无缓存预读时的查询性能差异。



## 43、说一下redis数据类型及其底层实现

> 数据类型

- string（字符串）：最基本的数据类型，可以存储任何二进制数据，如文本、图片、对象等，最大能存储512MB。
- hash（哈希）：类似于Java中的Map，可以存储一个对象的多个字段和值，适合用于存储用户信息、商品信息等。
- list（列表）：类似于Java中的LinkedList，可以在头尾两端进行插入和删除操作，适合用于实现栈、队列、消息列表等。
- set（集合）：类似于Java中的HashSet，可以存储多个不重复的元素，支持交集、并集、差集等操作，适合用于实现标签、好友关系等。
- zset（有序集合）：类似于Java中的TreeSet，可以存储多个不重复的元素，并给每个元素赋予一个分数（score），根据分数进行排序，适合用于实现排行榜、延时队列等。
- Bitmap：位图，Bitmap想象成一个以位为单位数组，数组中的每个单元只能存0或者1，数组的下标在Bitmap中叫做偏移量。使用Bitmap实现统计功能，更省空间。如果只需要统计数据的二值状态，例如商品有没有、用户在不在等，就可以使用 Bitmap，因为它只用一个 bit 位就能表示 0 或 1。
- Hyperloglog。HyperLogLog 是一种用于统计基数的数据集合类型，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基 数。场景：统计网页的UV（即Unique Visitor，不重复访客，一个人访问某个网站多次，但是还是只计算为一次）。要注意，HyperLogLog 的统计规则是基于概率完成的，所以它给出的统计结果是有一定误差的，标准误算率是 0.81%。
- Geospatial ：主要用于存储地理位置信息，并对存储的信息进行操作，适用场景如朋友的定位、附近的人、打车距离计算等。

> 数据类型匹配的底层数据结构

![image-20230402153834107](https://ningct.oss-cn-hangzhou.aliyuncs.com/image-20230402153834107.png)

> 底层数据结构

**SDS**

- sds是Redis底层所使用的字符串表示，它是一个结构体，包含了长度、空闲空间和字节数组三个属性。
- sds可以动态地调整字符串的大小，避免缓冲区溢出，并且获取字符串长度的复杂度为O(1)。
- sds可以兼容C语言传统的字符串表示（以空字符结尾的字符数组），因为它在字节数组的末尾也添加了一个空字符。
- sds可以存储任意二进制数据，不仅仅是文本数据，因为它不依赖于空字符来判断字符串是否结束。
- sds可以减少修改字符串时带来的内存重分配次数，因为它会预分配一定量的未使用空间，并且根据修改后的字符串长度来决定是否释放多余的空间。



**quicklist**

- Redis的quicklist是一种数据结构，它是一个双向链表，每个节点是一个ziplist（压缩列表）。
- Redis的quicklist是在3.2版本后引入的，它取代了原来的ziplist和linkedlist（双端链表）作为列表类型的底层实现。
- Redis的quicklist可以节省内存空间，因为它可以对节点进行LZF压缩算法，从而减少节点占用的字节数。
- Redis的quicklist可以配置compress参数，表示从两端开始有多少个节点不进行压缩。compress为0表示所有节点都不压缩。



**跳表**

- Redis的跳表是一种有序的多层链表，它通过在每个节点中增加多个指向后续节点的指针，来实现快速查找、插入和删除操作。
- Redis使用跳表作为有序集合键的底层实现之一，当有序集合包含的元素数量比较多或者元素成员是比较长的字符串时，Redis就会使用跳表来节省空间和提高效率。
- Redis的跳表由zskiplistNode和zskiplist两个结构定义，其中zskiplistNode表示跳表节点，而zskiplist表示跳表本身，包含了节点数量、头尾指针等信息。
- Redis的跳表在创建和插入节点时，使用随机算法来决定节点的层数，并且保证每层链表中节点个数是下层链表中节点个数的1/4（P=0.25），这样可以使得查找过程类似于二分查找，时间复杂度为O(logN)。



**压缩列表**

- Redis的压缩列表是一种线性数据结构，它是一个字节数组，可以包含任意多个元素，每个元素可以是一个字节数组或一个整数。
- Redis的压缩列表是为了节约内存而设计的，它使用特殊的编码方式来减少每个元素占用的字节数。
- Redis的压缩列表由多个字段组成，包括zlbytes（压缩列表总长度）、zltail（尾元素偏移量）、zllen（元素个数）、entryX（各个元素）和zlend（结束标志）。
- Redis的压缩列表在创建新列表时默认使用，当列表中有超过一定长度或者数量的元素时，会转换成双向链表或者快速列表。



**listpack**

- Redis的listpack是一种字符串列表的序列化格式，它是Redis5.0引入的一个全新的数据结构，设计用来取代ziplist。
- Redis的listpack和ziplist类似，都是使用特殊的编码方式来压缩存储字符串或整数，但是listpack解决了ziplist存在的级联更新的问题。
- Redis的listpack由多个字段组成，包括tot-bytes（总字节数）、num-elements（元素个数）和element-X（各个元素），每个元素都记录自己的长度，并放在节点尾部。
- Redis目前使用listpack作为t_hash和stream中radix tree节点中存储前缀的底层结构。



**整数集合**

- 整数集合（intset）是Redis用于保存整数值的集合抽象数据结构，它可以保存类型为int16_t、int32_t或者int64_t的整数值，并且保证集合中不会出现重复元素。
- 整数集合是集合键的底层实现之一，当一个集合只包含整数值元素，并且这个集合的元素数量不多时，Redis就会使用整数集合作为集合键的底层实现。
- 整数集合由一个intset结构和一个contents数组组成，其中intset结构保存了编码方式、元素数量等信息，而contents数组按照从小到大的顺序保存了所有元素。
- 整数集合在添加或删除元素时，会根据需要动态地调整contents数组的大小和编码方式，以节省空间和提高效率。



**哈希表**

- Redis的哈希表是一种数据类型，它是一个字符串类型的字段和值的映射表，特别适合用于存储对象。
- Redis中每个哈希表可以存储2 32 - 1个键值对（40多亿）。
- Redis提供了多种命令来操作哈希表，例如HMSET、HGET、HDEL等。
- Redis的哈希表使用字典作为底层实现，字典是一个包含两个哈希表的结构体，其中一个用于正常存储数据，另一个用于扩展或收缩空间时进行数据迁移。
- Redis的哈希表使用链地址法来解决键冲突问题，并且使用随机数种子和乘法散列算法来计算键的索引位置。



> 应用场景

- 缓存：利用Redis的高速读写和过期策略，可以缓存一些热点数据，提高系统的响应速度和并发能力。
- 排行榜：利用Redis的有序集合（sorted set）数据类型，可以实现各种排行榜功能，如热门商品、热门文章、积分排名等。
- 计数器：利用Redis的原子操作和位图（bitmap）数据类型，可以实现各种计数器功能，如在线用户数、网站访问量、用户签到等。
- 分布式锁：利用Redis的setnx命令和过期时间，可以实现分布式锁功能，解决多个进程或服务器对同一资源的并发访问问题。
- 消息队列：利用Redis的列表（list）数据类型和阻塞弹出命令（blpop/brpop），可以实现消息队列功能，解决生产者和消费者之间的异步通信问题

## 44、说一下redis持久化机制

Redis的持久化机制是指将内存中的数据保存到硬盘中，以防止服务器宕机或断电导致数据丢失。Redis有两种持久化机制，分别是RDB和AOF¹。

RDB是指按照一定的时间间隔，将内存中的数据以快照的形式保存到一个二进制文件中，文件名为dump.rdb。RDB的优点是文件体积小，恢复速度快，容灾性好；缺点是可能会丢失最近一次快照之后的数据，而且文件格式可能不兼容不同版本的Redis²。

AOF是指将Redis执行的所有写命令记录到一个日志文件中，文件名为appendonly.aof。AOF的优点是数据安全性高，可以通过配置设置同步频率，而且文件格式易于理解和修复；缺点是文件体积大，恢复速度慢，而且写入性能受硬盘限制²。

如果同时开启了RDB和AOF，那么Redis会优先使用AOF来恢复数据²。

> 混合持久化

Redis混合持久化是指在AOF文件的开头使用RDB的格式来保存内存中的数据，然后在后面追加AOF的写命令¹。这种方式是在Redis 4.0之后引入的，可以通过配置项aof-use-rdb-preamble来开启或关闭²。

混合持久化的优点是可以结合RDB和AOF的优点，既可以快速加载数据，又可以避免丢失过多的数据³。混合持久化的缺点是可能会导致AOF文件过大，而且如果AOF文件出现损坏，可能会影响RDB部分的加载

混合持久化的执行是在AOF重写的时候触发的，也就是说，当AOF文件的大小超过了配置的阈值，或者当用户手动执行BGREWRITEAOF命令时，Redis会创建一个子进程来进行混合持久化。子进程会先将内存中的数据以RDB的格式写入AOF文件的开头，然后再将缓冲区中的AOF写命令追加到文件的末尾。当子进程完成混合持久化后，父进程会用新的AOF文件替换旧的AOF文件，并继续记录后续的写命令。

## 45、说一下redis过期策略和内存淘汰机制

过期删除策略是指Redis如何检测和删除已经过期的键的方法

内存淘汰机制是指Redis在内存不足以容纳新写入数据时，如何选择删除哪些键的方法。

- Redis的过期删除策略
  - 定期删除是指Redis每隔一定时间（默认100ms）就随机抽取一些设置了过期时间的键，检查其是否过期，如果过期就删除。
  - 惰性删除是指当客户端访问某个键时，Redis会检查该键是否已经过期，如果过期就立即删除，不会返回任何值。
  - Redis中同时使用了定期删除和惰性删除两种过期策略。
- Redis的内存淘汰机制有以下几种：
  - noeviction表示当内存不足以容纳新写入数据时，新写入操作会报错，不会驱逐任何键。
  - allkeys-lru表示当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的键。
  - volatile-lru表示当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的键。
  - allkeys-random表示当内存不足以容纳新写入数据时，在键空间中，随机移除某个键。
  - volatile-random表示当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个键。
  - volatile-ttl表示当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的键优先移除。
  - volatile-lfu表示从所有配置了过期时间的键中驱逐使用频率最少的键。
  - allkeys-lfu表示从所有键中驱逐使用频率最少的键。



## 46、说一下redis主从复制

Redis主从复制是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点，后者称为从节点。数据的复制是单向的，只能由主节点到从节点。默认情况下，每台Redis服务器都是主节点，且一个主节点可以有多个从节点，但一个从节点只能有一个主节点。

Redis主从复制的作用主要有数据冗余、故障恢复、负载均衡和高可用基石。

Redis主从复制的实现原理可以分为以下几个步骤：

- 设置主节点的地址和端口：从节点可以通过配置文件、启动命令或客户端命令来设置需要同步的主节点的IP和端口。
- 建立套接字连接：从节点会根据设置的IP和端口，向主节点建立socket连接。
- 发送PING命令：从节点会向主节点发送PING命令，检查socket连接是否可用，以及主节点当前是否能够处理请求。如果返回PONG，说明连接正常，复制过程继续；如果超时或返回其他结果，说明连接不可用，从节点断开连接，并重连。
- 权限验证：如果从节点设置了masterauth选项，则从节点需要向主节点发送AUTH命令进行身份验证。如果验证通过，复制过程继续；如果验证失败，从节点断开连接，并重连。
- 同步：同步就是将从节点的数据库状态更新成主节点当前的数据库状态。具体执行的方式是：从节点向主节点发送PSYNC命令（Redis2.8以前是SYNC命令），开始同步。根据主从节点当前状态的不同，可以分为全量复制和部分复制。全量复制是指主节点将自己的所有数据发送给从节点，让从节点与主节点完全一致；部分复制是指主节点只将从上次断开后执行的写命令发送给从节点，让从节点追赶上落后的数据。
- 命令传播：经过上面同步操作，此时主从的数据库状态已经一致了，但这种一致的状态并不是一成不变的。在完成同步之后，也许主服务器马上就接受到了新的写命令，执行完该命令后，主从的数据库状态又不一致了。数据同步阶段完成后，主从节点进入命令传播阶段；在这个阶段主节点将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据的一致性。



## 47、说一下redis哨兵机制

Redis哨兵机制是Redis的高可用性解决方案，由一个或多个哨兵实例组成的哨兵系统可以监视任意多个主服务器，以及这些主服务器属下的所有从服务器，当Redis主服务器出现故障时，能够自动地恢复服务，选举新的主服务器，避免数据丢失和服务中断

Redis哨兵机制的底层原理可以分为以下几个方面：

- 哨兵实例之间的通信：哨兵实例之间不会直接建立连接，而是通过订阅一个名为"_sentinel_:hello"的频道来进行通信，每个哨兵实例都会向这个频道发送自己的信息（IP+port），并接收其他哨兵实例发送的信息，从而互相感知对方的存在。
- 主从服务器信息的获取：哨兵实例会周期性地向被监视的主服务器和从服务器发送INFO命令，并通过分析返回的数据来获取主从服务器的当前信息，如运行状态、角色、复制偏移量等。
- 主观下线和客观下线的判断：哨兵实例会周期性地向被监视的主服务器和从服务器发送PING命令，检查它们是否存活。如果一个哨兵实例在一定时间内没有收到某个主服务器的回复，那么它会将该主服务器标记为主观下线（sdown）。如果一个哨兵实例收到了足够数量（由quorum参数指定）的其他哨兵实例也认为某个主服务器是主观下线的，那么它会将该主服务器标记为客观下线（odown）。只有当一个主服务器被标记为客观下线时，才会触发故障转移。
- 故障转移：当一个主服务器被标记为客观下线时，哨兵系统会从其所属的从服务器中选举一个作为新的主服务器，并让其他从服务器去复制新的主服务器。故障转移过程中涉及到多个步骤，如领导者选举、新主选举、复制重置、配置更新等。
- 客户端通知：当故障转移完成后，哨兵系统会将新主服务器的信息通知给客户端，让客户端与新的主服务器建立连接。

> 发布订阅机制

Redis发布和订阅机制是一种消息模式，消息的发送者（称为发布者）不会将消息直接发送给特定的接收者（称为订阅者），而是通过消息通道（channel）广播出去，让订阅了该通道的订阅者消费到¹²³。

Redis发布和订阅机制的实现原理可以分为以下几个方面²³⁴：

- 通道的发布和订阅：Redis将所有通道的订阅关系都保存在服务器状态的pubsub_channels字典，字典的键是某个被订阅的通道，而对应值则是一个链表，链表里记录了所有订阅这个通道的客户端。当客户端执行SUBSCRIBE命令订阅某个或某些通道时，服务器会在字典中为每个被订阅的通道创建一个键，并将客户端添加到链表中。当客户端执行UNSUBSCRIBE命令退订某个或某些通道时，服务器会从字典中删除客户端与被退订通道之间的关联，如果某个通道已无任何订阅者，那么服务器也会从字典中删除该通道对应的键。
- 模式的发布和订阅：Redis将所有模式的订阅关系都保存在服务器状态的pubsub_patterns链表，链表的每个节点都包含着一个pubsubPattern结构，这个结构的pattern属性记录了被订阅的模式，而client属性则记录了订阅模式的客户端。当客户端执行PSUBSCRIBE命令订阅某个或某些模式时，服务器会为每个被订阅的模式创建一个pubsubPattern结构，并将结构添加到链表中。当客户端执行PUNSUBSCRIBE命令退订某个或某些模式时，服务器会从链表中查找并删除那些pattern属性为被退订模式，并且client属性为执行退订命令的客户端的pubsubPattern结构。
- 消息的发布：当客户端执行PUBLISH命令将消息发送给某个通道时，服务器会执行以下两个操作：1）在pubsub_channels字典里找到通道对应的订阅者列表，然后将消息发送给列表上所有客户端；2）遍历pubsub_patterns链表，查找与通道相匹配的模式，并将消息发送给订阅了这些模式的客户端。



## 48、说一下redis高并发场景

Redis高并发场景是指在短时间内有大量的请求同时访问Redis服务器，例如秒杀、抢购、热点数据查询等场景¹²。Redis高并发场景下，可能会遇到以下几个问题：

- 缓存穿透：指的是请求的数据在缓存和数据库中都不存在，导致每次请求都要访问数据库，造成数据库压力过大。
- 缓存击穿：指的是请求的数据在缓存中不存在，但在数据库中存在，且该数据是热点数据，导致在缓存过期的瞬间，有大量的请求同时访问数据库，造成数据库压力过大，即很多请求同时访问一个过期数据。
- 缓存雪崩：指的是缓存中的大量数据在同一时间过期失效，导致在这个时间段内，有大量的请求同时访问数据库，造成数据库压力过大，即很多请求同时访问多个过期数据

针对这些问题，可以采用以下一些解决方案：

- 缓存穿透：可以使用布隆过滤器来过滤掉不存在的数据请求，或者对不存在的数据设置一个空值或者标识符，并设置一个较短的过期时间，避免频繁访问数据库。
- 缓存击穿：可以使用分布式锁来保证对同一个数据只有一个线程去查询数据库，并将查询结果回写到缓存中，其他线程等待锁释放后从缓存中获取数据。
- 缓存雪崩：可以给缓存中的数据设置不同的过期时间，避免同一时间大量数据失效，或者使用集群或者分布式缓存来提高缓存的可用性和容错性。

> 优化

我觉得Redis高并发场景还有以下一些优化方法：

- 使用异步队列：可以将一些耗时的操作或者非实时性的操作放入到异步队列中，由专门的线程或者进程来处理，避免阻塞主线程或者进程，提高响应速度。
- 使用读写分离：可以将Redis服务器分为主从结构，主服务器负责写操作，从服务器负责读操作，这样可以提高Redis的吞吐量和负载能力。
- 使用集群或者分片：可以将Redis服务器分为多个节点，根据一定的规则将数据分散到不同的节点上，这样可以提高Redis的可扩展性和容错性。

## 49、说一下redis的线程模型

Redis线程模型是指Redis**如何使用单线程或多线程来处理客户端的请求和响应**，以及执行其他的内部任务¹²³。

Redis线程模型可以分为以下几个方面：

- 文件事件处理器：Redis基于Reactor模式开发了网络事件处理器，这个处理器被称为文件事件处理器。它的组成结构为四个部分：多个套接字、IO多路复用程序、文件事件分派器、事件处理器。**文件事件处理器使用单线程来监听多个套接字上的事件，并根据事件类型调用相应的事件处理器来处理**。文件事件处理器是Redis实现高性能的关键所在。
- 多线程I/O：Redis 6.0引入了多线程I/O的特性，可以让Redis在处理网络请求时使用多个工作线程，而不是只使用主线程。这样可以减少主线程的负担，提高网络吞吐量。**多线程I/O只负责读写套接字缓冲区，不涉及数据的解析和处理，也不影响Redis的单线程语义**。多线程I/O是可选的，可以通过配置io-threads和io-threads-do-reads来开启或关闭。
- 定时任务：Redis还有一些定时任务，如持久化、过期键删除、集群维护等，这些任务也是由主线程来执行的，但是为了避免阻塞主线程，**Redis会控制每次执行定时任务的时长，如果超过了预设的阈值，就会中断任务，等待下一次继续执行**。这样可以保证主线程有足够的时间来处理网络事件。

> redis线程模型工作过程

Redis线程模型的工作过程。假设有以下几个条件：

- Redis服务器监听了6379端口，并且有三个客户端A、B、C分别连接到了这个端口。
- Redis服务器开启了多线程I/O，设置了io-threads为4，io-threads-do-reads为yes。
- Redis服务器有一个定时任务，每隔一秒执行一次，用来检查是否有过期的键需要删除。

那么Redis线程模型的工作过程大致如下：

- 主线程使用文件事件处理器监听6379端口上的读写事件，并根据事件类型调用相应的事件处理器来处理。
- 当客户端A发送了一个GET命令请求时，主线程会将这个请求放入到一个全局的读队列中，并通知一个空闲的工作线程来处理这个请求。
- 工作线程从全局的读队列中取出这个请求，从套接字缓冲区中读取命令内容，然后将命令内容放入到主线程的待处理队列中，并通知主线程来处理这个命令。
- 主线程从待处理队列中取出这个命令，解析并执行命令，得到命令的结果，然后将结果放入到客户端A的写队列中，并通知一个空闲的工作线程来处理这个结果。
- 工作线程从客户端A的写队列中取出这个结果，将结果写入到套接字缓冲区中，然后通知主线程已经完成写入操作。
- 主线程收到通知后，会向客户端A发送一个可写事件，让客户端A从套接字缓冲区中读取结果，并返回给客户端A。
- 同时，主线程还会定期地执行定时任务，检查是否有过期的键需要删除。如果发现有过期的键，就会删除它们，并将删除操作记录到AOF文件或RDB文件中。如果执行定时任务的时间超过了预设的阈值，就会中断任务，等待下一次继续执行。



## 50、说一下redis事务

Redis事务是指Redis可以一次执行多个命令，并且带有以下三个重要的保证¹²：

- 批量操作在发送EXEC命令前被放入队列缓存。
- 收到EXEC命令后进入事务执行，**事务中任意命令执行失败，其余的命令依然被执行**。
- 在事务执行过程，**其他客户端提交的命令请求不会插入到事务执行命令序列中**。

Redis事务可以分为以下几个阶段¹²：

- 开始事务：使用MULTI命令来开启一个事务，标记一个事务块的开始。
- 命令入队：在MULTI命令之后，所有的命令都不会立即执行，而是被放入到一个队列中，等待执行。每个命令都会返回一个QUEUED的响应，表示命令已入队。
- 执行事务：使用EXEC命令来触发事务，一并执行事务中的所有命令。如果事务中没有任何错误，那么EXEC命令返回一个数组，数组中包含了每个命令的返回值。如果事务中有语法错误或者类型错误，那么EXEC命令返回一个EXECABORT错误，并且不执行任何命令。如果事务中有运行时错误，那么EXEC命令返回一个数组，数组中包含了每个命令的返回值或者错误信息。

Redis事务还可以使用以下几个命令：

- DISCARD：取消事务，放弃执行事务块内的所有命令。
- WATCH：监视一个或多个key，如果在事务执行之前，这些key被其他命令修改了，那么事务将被打断，不会执行任何命令。
- UNWATCH：取消WATCH对所有key的监视。

> 优缺点

Redis事务的优点主要有以下几个：

- 简单易用：Redis事务的命令都很简单，只需要使用MULTI、EXEC等命令就可以实现一个事务，不需要复杂的语法和逻辑。
- 高性能：Redis事务的执行是非阻塞的，不会影响其他客户端的请求，也不会占用过多的资源，保证了Redis的高性能。
- 一致性：Redis事务可以保证在事务执行过程中，其他客户端提交的命令请求不会插入到事务执行命令序列中，避免了数据的不一致。

Redis事务的缺点主要有以下几个：

- 非原子性：Redis事务并不是原子性的，如果事务中有运行时错误，那么事务不会回滚，而是跳过错误命令继续执行，这可能导致数据的不完整或者不正确。
- 不支持隔离性：Redis事务并不支持隔离性，如果事务中有对同一个key的多次操作，那么这些操作可能会被其他客户端的命令打断，导致结果的不确定。
- 不支持嵌套：Redis事务并不支持嵌套，如果在一个事务中再开启一个事务，那么之前的事务会被覆盖，只有最后一个事务会被执行。

> 优化技巧

- 避免语法错误和类型错误：在执行事务之前，要检查命令的语法和参数是否正确，避免因为语法错误或者类型错误导致事务失败。
- 避免运行时错误：在执行事务之前，要检查命令的逻辑和条件是否合理，避免因为运行时错误导致事务不完整。
- 使用WATCH命令：在执行事务之前，可以使用WATCH命令来监视事务中涉及的key，如果这些key在事务执行之前被其他客户端修改了，那么事务将被打断，不会执行任何命令，这样可以保证数据的完整性和正确性。
- 减少事务中的命令数量：在执行事务时，要尽量减少事务中的命令数量，避免因为命令过多导致事务执行时间过长或者占用过多的资源。



## 51、说一下spring有哪些优点

Spring框架有很多优点，可以简化Java企业级应用程序的开发，提高开发效率和系统可维护性。

- 低侵入式设计，代码污染极低，不强制应用完全依赖于Spring，可以灵活地选择使用哪些模块⁴。
- 独立于各种应用服务器，基于Spring框架的应用，可以真正实现Write Once,Run Anywhere的承诺⁴。
- 通过控制反转（IoC）和依赖注入（DI）实现松耦合，降低了业务对象替换的复杂性，提高了组件之间的解耦⁴¹。
- 通过面向切面（AOP）的支持，允许将一些通用任务如安全、事务、日志等进行集中式管理，从而提供了更好的复用⁴¹。
- 方便集成各种优秀的开源框架，如Struts2、Hibernate、MyBatis等，提供了对这些框架的直接支持¹²。
- 降低Java EE API的使用难度，对一些难用的API如JDBC、JavaMail、远程调用等提供了封装，使这些API应用的难度大大降低¹²。
- 方便程序的测试，支持JUnit4，可以通过注解方便地测试Spring程序¹²。
- 声明式事务的支持，只需要通过配置就可以完成对事务的管理，而无需手动编程¹²。

## 52、说一下spring主要模块

- 核心容器（Core Container）：它是Spring框架的基础，包括Beans模块、Core模块、Context模块、Context-support模块和SpEL模块。它提供了控制反转（IoC）和依赖注入（DI）功能，以及对第三方库的集成支持¹²。
- 数据访问/集成（Data Access/Integration）：它包括JDBC模块、ORM模块、OXM模块、JMS模块和Transactions模块。它提供了对数据库操作、对象关系映射、对象/XML映射、消息传递和事务管理的支持¹²。
- Web：它包括WebSocket模块、Servlet模块、Web模块和Portlet模块。它提供了基于Web的开发功能，如多文件上传、WebSocket和SockJS实现、RESTful Web服务、MVC框架等¹²。
- 面向切面编程（AOP）：它提供了面向切面编程的实现，允许定义方法拦截器和切入点，将代码按照功能进行分离，以降低耦合性¹²。
- Aspects：它提供了与AspectJ的集成功能，AspectJ是一个功能强大且成熟的面向切面编程（AOP）框架¹²。
- Instrumentation：它提供了类工具的支持和类加载器的实现，可以在特定的应用服务器中使用¹²。
- Messaging：它提供了对消息传递体系结构和协议的支持¹²。
- Test：它提供了对单元测试和集成测试的支持

## 53、说一下IOC

控制反转（IoC）和依赖注入（DI）是Spring框架的核心概念，它们是实现对象之间的松耦合的关键。

控制反转（IoC）是一种设计原则，它的思想是**将对象的创建和依赖关系的管理从程序代码中转移到外部容器中**，从而实现对象之间的解耦。控制反转的目的是让程序员专注于业务逻辑，而不用关心对象的创建和维护¹²。

依赖注入（DI）是一种**实现控制反转的方式**，它的主要思想是通过容器自动将所需的依赖注入到需要它们的对象中，从而实现对象之间的解耦。依赖注入可以通过接口注入、Setter方法注入或构造器注入三种方式来实现¹²³。

控制反转和依赖注入是相辅相成的，控制反转是目标，依赖注入是手段。控制反转还有其他的实现方式，例如服务定位器（Service Locator），但是依赖注入是更优雅和更灵活的方式⁴

> IOC和spring容器

Spring容器和IOC有什么区别呢？其实，Spring容器就是一个实现了IOC的容器，它可以根据配置文件或注解来创建和管理对象，以及实现对象之间的依赖注入。

IOC是一种设计原则，它的思想是将对象的创建和依赖关系的管理从程序代码中转移到外部容器中，从而实现对象之间的解耦。Spring容器是IOC的一种实现方式，但不是唯一的方式¹²。

Spring容器有两种类型：BeanFactory和ApplicationContext。BeanFactory是最基本的容器，提供了基本的依赖注入功能。ApplicationContext是BeanFactory的子接口，提供了更多的功能，如AOP、事件支持、国际化等¹²。

> BeanFactory和ApplicationContext区别

- 功能上，ApplicationContext是BeanFactory的子接口，所以它包含了BeanFactory的所有功能，但是还提供了更多的扩展功能，如AOP、事件支持、国际化等 。
- 加载时机上，BeanFactory是延迟加载的，也就是说只有当需要获取某个Bean时，才会去创建和初始化该Bean。ApplicationContext是预加载的，也就是说在容器启动时就会创建和初始化所有的单例Bean 。
- 资源消耗上，BeanFactory相对于ApplicationContext更轻量级，因为它只提供了基本的依赖注入功能，而不涉及其他的复杂功能。ApplicationContext相对于BeanFactory更重量级，因为它提供了更多的功能，但也消耗了更多的资源 。

一般来说，如果只需要基本的依赖注入功能，可以使用BeanFactory。如果需要更多的功能，可以使用ApplicationContext 。

> 容器的初始化流程

Spring容器的启动流程大致可以分为以下几个步骤：

- **创建Spring容器对象**，如AnnotationConfigApplicationContext，传入配置类或扫描路径等参数。
- **调用容器对象的构造方法**，初始化BeanFactory，AnnotatedBeanDefinitionReader和ClassPathBeanDefinitionScanner等组件。
- **调用容器对象的register方法**，将配置类或其他组件的BeanDefinition注册到容器中。
- **调用容器对象的refresh方法**，刷新容器，执行以下操作：
  - 调用BeanFactoryPostProcessor的**后置处理方法**，对BeanFactory进行修改或增强。
  - 调用BeanDefinitionRegistryPostProcessor的后置处理方法，对BeanDefinition进行修改或增强。
  - 调用MergedBeanDefinitionPostProcessor的后置处理方法，对BeanDefinition进行合并或缓存。
  - 注册BeanPostProcessor到容器中，用于对Bean进行后置处理。
  - **注册**ApplicationListener到容器中，用于监听事件。
  - 初始化MessageSource和ApplicationEventMulticaster等组件，用于国际化和事件广播。
  - 获取容器中所有的**单例非懒加载的Bean**名称，按照依赖顺序进行排序。
  - 遍历所有的单例非懒加载的Bean名称，调用getBean方法创建和初始化Bean对象，并放入单例池中。
  - 调用SmartInitializingSingleton的afterSingletonsInstantiated方法，**对单例Bean进行后置处理**。
  - 发布ContextRefreshedEvent事件，**通知所有的监听器容器已经刷新完成**。
  - **注册ShutdownHook线程**，用于在JVM关闭时销毁容器中的单例Bean。



## 54、说一下spring been

> 生命周期

Spring bean生命周期指的是bean从创建到初始化再到销毁的过程，这个过程由IOC容器管理。Spring bean生命周期大致可以分为以下几个步骤：

- 实例化：通过反射或工厂方法创建bean对象。
- 属性赋值：通过配置文件或注解为bean对象设置属性值和依赖关系。
- 初始化：调用bean对象的初始化方法，如afterPropertiesSet()或自定义的init-method，以及BeanPostProcessor的前置和后置处理方法。
- 销毁：调用bean对象的销毁方法，如destroy()或自定义的destroy-method，以及DestructionAwareBeanPostProcessor的后置处理方法。

在这个过程中，Spring还提供了一些扩展点，让我们可以在不同的阶段对bean进行定制化处理，如：

- **Aware接口**：让bean对象可以感知到容器的一些信息，如BeanNameAware、BeanFactoryAware、ApplicationContextAware等。
- **BeanFactoryPostProcessor**：在bean定义被加载到容器之后，但在bean实例化之前，对bean定义进行修改或增强。
- **BeanDefinitionRegistryPostProcessor**：在BeanFactoryPostProcessor之前执行，可以对bean定义进行注册或移除。
- MergedBeanDefinitionPostProcessor：在bean定义被合并或缓存之后，对bean定义进行修改或增强。
- InstantiationAwareBeanPostProcessor：在bean实例化之前和之后，对bean进行修改或增强。
- SmartInstantiationAwareBeanPostProcessor：在InstantiationAwareBeanPostProcessor之前执行，可以决定使用哪种方式实例化bean，以及提供代理对象。
- **BeanPostProcessor**：在bean初始化之前和之后，对bean进行修改或增强。
- **DestructionAwareBeanPostProcessor**：在bean销毁之前，对bean进行修改或增强。
- SmartInitializingSingleton：在所有单例非懒加载的bean初始化完成后，对单例bean进行修改或增强。

> 作用域

Spring bean作用域指的是bean在Spring整个框架中的某种行为模式，比如singleton单例作用域，就表示bean在整个Spring中只有一份，它是全局共享的，那么当其他人修改了这个值之后，那么另一个人读取到的就是被修改的值。Spring支持以下五种作用域：

- singleton：单例模式，在整个Spring IoC容器中，使用singleton定义的bean将只有一个实例，这是默认的作用域。
- prototype：原型模式，每次通过容器的getBean方法获取prototype定义的bean时，都将产生一个新的bean实例，创建后Spring将不再对其管理。
- request：对于每次HTTP请求，使用request定义的bean都将产生一个新实例，即每次HTTP请求将会产生不同的bean实例。只有在Web应用中使用Spring时，该作用域才有效。
- session：对于每次HTTP Session，使用session定义的bean都将产生一个新实例。同样只有在Web应用中使用Spring时，该作用域才有效。
- application：在一个HTTP Servlet Context中，定义一个bean实例。只有在Web应用中使用Spring时，该作用域才有效。

Bean作用域的设置可以通过@Scope注解或XML配置文件来指定。例如：

```java
@Scope("prototype")
@Component
public class User {
    // ...
}
```

```xml
<bean id="user" class="com.example.User" scope="prototype"/>
```

一般来说，可以根据以下几个原则来选择合适的作用域：

- 如果bean是无状态的，即不包含任何可变的属性或依赖，那么可以使用singleton作用域，这样可以提高性能和内存利用率，也可以避免多线程问题。
- 如果bean是有状态的，即包含一些可变的属性或依赖，那么可以使用prototype作用域，这样可以保证每次获取bean都是一个新的实例，不会受到其他请求的影响，也可以避免多线程问题。
- 如果bean是与HTTP请求相关的，即需要根据不同的请求参数或用户信息来创建或修改bean，那么可以使用request作用域，这样可以保证每次请求都有一个独立的bean实例，不会与其他请求冲突。
- 如果bean是与HTTP会话相关的，即需要根据不同的用户会话来创建或修改bean，那么可以使用session作用域，这样可以保证每个用户都有一个独立的bean实例，不会与其他用户冲突。
- 如果bean是与HTTP应用相关的，即需要在整个应用范围内共享或修改bean，那么可以使用application作用域，这样可以保证所有的请求和用户都使用同一个bean实例，但是需要注意多线程问题和内存消耗。

> 装配

Spring bean装配指的是将bean的定义信息与bean的实例化、初始化和销毁相结合的过程，也就是将bean放入Spring IoC容器中管理的过程。Spring提供了多种方式来实现bean的装配，主要有以下三种：

- 基于XML的装配：通过在XML配置文件中使用<bean>元素和其子元素<property>或<constructor-arg>来定义bean的属性或构造器参数，从而实现bean的依赖注入。这种方式比较直观和灵活，但是也比较繁琐和冗余，需要手动指定每个bean的依赖关系。
- 基于注解的装配：通过在Java类中使用注解来标注bean的组件类型、属性或构造器参数，从而实现bean的依赖注入。这种方式比较简洁和方便，但是也比较隐式和不易控制，需要让Spring扫描指定的包或类来发现和注册bean。常用的注解有@Component、@Repository、@Service、@Controller、@Autowired、@Resource、@Qualifier等。
- 自动装配：通过让Spring根据bean的类型或名称来自动匹配其依赖关系，从而实现bean的依赖注入。这种方式比较高效和智能，但是也比较模糊和不准确，可能会出现歧义或冲突的情况。自动装配可以通过XML配置文件中使用autowire属性或Java类中使用@Autowired注解来开启

> 循环依赖

Spring循环依赖指的是在Spring IoC容器中，两个或多个bean相互依赖对方的属性或构造器参数，从而形成一个环形的依赖关系

Spring提供了一种机制来处理循环依赖，主要是利用三级缓存和提前暴露对象的引用来实现。具体的流程如下：

- 当Spring创建一个bean时，首先会调用其无参构造器来实例化对象，并将其放入三级缓存（singletonFactories）中，这个缓存中保存的是一个ObjectFactory对象，可以用来获取bean的引用。
- 然后Spring会对bean进行属性注入，如果发现有其他bean的依赖，就会去一级缓存（singletonObjects）中查找，这个缓存中保存的是已经完成实例化、注入和初始化的bean对象。
- 如果一级缓存中没有找到，就会去二级缓存（earlySingletonObjects）中查找，这个缓存中保存的是已经完成实例化但还没有完成注入和初始化的bean对象。
- 如果二级缓存中也没有找到，就会去三级缓存中查找，并将获取到的ObjectFactory对象从三级缓存移动到二级缓存中，并通过它获取bean的引用。
- 如果三级缓存中也没有找到，就会抛出异常，表示无法解决循环依赖。
- 如果成功获取到bean的引用，就会继续进行属性注入，直到所有的依赖都被注入。
- 最后Spring会对bean进行初始化操作，并将其从二级缓存移动到一级缓存中，并从三级缓存中删除。

通过这种方式，Spring可以在一定程度上解决循环依赖的问题，但是也有一些限制和注意事项：

- 这种机制只适用于单例作用域（singleton）的bean，对于原型作用域（prototype）的bean无法解决循环依赖。
- 这种机制只适用于属性注入（setter injection）或字段注入（field injection），对于构造器注入（constructor injection）无法解决循环依赖。
- 这种机制可能会导致某些bean被提前暴露出去，在注入和初始化之前被其他bean使用，这可能会引发一些意想不到的问题。



## 55、说一下AOP

Spring AOP是Spring框架中提供的一种面向切面编程（Aspect Oriented Programming）的功能，它可以让我们在不修改原有代码的情况下，增加一些额外的功能或逻辑，从而实现横切关注点（cross-cutting concerns）的模块化和解耦。

> 主要功能

- 日志记录：可以在方法的执行前后记录日志，方便调试和监控。
- 权限检查：可以在方法的执行前检查用户是否有权限访问该方法，如果没有则拒绝执行。
- 事务管理：可以在方法的执行前后进行事务的开启、提交或回滚，保证数据的一致性。
- 异常处理：可以在方法的执行出现异常时进行统一的异常处理，避免代码重复。
- 缓存管理：可以在方法的执行前后进行缓存的读取或更新，提高性能。

> 要概念和术语

- Aspect（切面）：一个模块化的横切关注点，通常由一个类或一个注解来定义，包含了一些通知（Advice）和切点（Pointcut）。
- Advice（通知）：在特定的连接点（Joinpoint）上执行的动作或逻辑，通常由一个方法来实现。根据执行时机的不同，通知可以分为前置通知（Before）、后置通知（After）、返回通知（AfterReturning）、异常通知（AfterThrowing）和环绕通知（Around）。
- Pointcut（切点）：一个表达式或一个注解，用来匹配连接点（Joinpoint），确定通知（Advice）要在哪些方法上执行。Spring AOP支持AspectJ风格的切点表达式语法。
- Joinpoint（连接点）：程序执行过程中的某个特定位置，如方法调用、异常抛出等。Spring AOP只支持方法级别的连接点。
- Target Object（目标对象）：被一个或多个切面所通知的对象，也就是包含业务逻辑的对象。Spring AOP通过运行时生成代理对象来实现对目标对象的增强。
- Introduction（引入）：一种特殊的通知，用来为目标对象添加一些额外的属性或方法，从而扩展目标对象的功能。
- Weaving（织入）：将切面和目标对象连接起来，并创建出代理对象的过程。织入可以发生在编译期、类加载期或运行期。Spring AOP默认使用运行时织入

> 优缺点

Spring AOP的优点有：

- 可以实现横切关注点的模块化和解耦，提高代码的可读性和可维护性。
- 可以在不修改原有代码的情况下，增加一些额外的功能或逻辑，提高代码的复用性和扩展性。
- 可以利用Spring IoC容器和AOP框架的集成，方便地配置和管理切面和目标对象。
- 可以利用AspectJ的强大的切点表达式语法，灵活地匹配连接点和通知。

Spring AOP的缺点有：

- 只支持方法级别的连接点，无法实现对字段或构造器的增强。
- 使用运行时织入的方式，会增加运行时的开销和内存消耗。
- 使用代理对象的方式，会导致目标对象的类型发生变化，可能会引发一些类型转换或自动装配的问题。
- 使用注解或XML配置的方式，会增加配置的复杂度和冗余性。

> AOP和AspectJ

Spring AOP和AspectJ的区别和联系有：

- Spring AOP是基于**动态代理技术**实现的，它可以在运行时动态地生成代理对象，从而实现AOP。AspectJ是基于**编译器技术**实现的，它可以在编译期或类加载期修改字节码，从而实现AOP。
- Spring AOP只支持**方法级别的连接点**，即只能在方法执行前后进行增强。AspectJ支持更多的连接点，如**字段访问、构造器调用、异常抛出**等，可以在更多的位置进行增强。
- Spring AOP需要**依赖于Spring IoC容器来管理切面和目标对象**，并且只能作用于Spring容器中的bean。AspectJ可以单独使用，也可以整合到其他框架中，不受Spring容器的限制。
- Spring AOP**使用注解或XML配置文件来声明切面和通知**，使用AspectJ风格的切点表达式语法来匹配连接点。AspectJ使用注解或特殊的关键字来声明切面和通知，使用更强大的切点表达式语法来匹配连接点。
- Spring AOP使用**运行时织入**的方式，会增加运行时的开销和内存消耗，但是不需要特殊的编译器或类加载器。AspectJ使用静态织入的方式，会降低运行时的开销和内存消耗，但是需要特殊的编译器或类加载器。

> AOP和AspectJ使用场景

- 如果只需要对方法进行简单的增强，如日志、事务、权限等，而且目标对象都是Spring容器中的bean，那么可以使用Spring AOP，因为它更简单、方便和集成。
- 如果需要对非方法的连接点进行增强，如字段、构造器、异常等，或者目标对象不是Spring容器中的bean，那么可以使用AspectJ，因为它更强大、灵活和独立。
- 如果对性能和内存有较高的要求，或者需要在编译期或类加载期进行织入，那么可以使用AspectJ，因为它更高效、轻量和优化。
- 如果对配置和管理有较高的要求，或者需要与Spring IoC容器和其他框架进行集成，那么可以使用Spring AOP，因为它更统一、易用和兼容。

## 56、说一下spring使用的设计模式

- **工厂模式**：Spring 使用工厂模式通过 BeanFactory 和 ApplicationContext 创建 bean 对象，根据传入的参数来决定返回哪个类型的 bean 实例。
- **代理模式**：Spring AOP 功能的实现，使用了 JDK 的动态代理或者 CGlib 的字节码生成技术，来为目标对象创建代理对象，实现横切关注点的织入。
- **单例模式**：Spring 中的 bean 默认都是单例的，也就是说在整个容器中只有一个 bean 实例，这样可以节省资源和提高性能。
- **原型模式**：Spring 中也可以将 bean 的作用域设置为 prototype，这样每次获取 bean 时都会返回一个新的实例，对原型对象的修改不会影响其他对象。
- **模板方法模式**：Spring 中的 JdbcTemplate、HibernateTemplate 等以 Template 结尾的类，都使用了模板方法模式，定义了操作数据库的通用步骤，将具体的操作交给子类或回调方法实现。
- **观察者模式**：Spring 中的事件和监听器机制，使用了观察者模式，当一个事件发生时，会通知所有注册的监听器进行相应的处理。
- **适配器模式**：Spring 中的 AOP 中 AdvisorAdapter 类，它有三个实现：MethodBeforeAdviceAdapter、AfterReturningAdviceAdapter、ThrowsAdviceAdapter。它们将不同类型的通知（Advice）适配成 MethodInterceptor 接口，以便在代理对象上执行。

## 57、说一下spring事务

Spring 事务是指 Spring 框架对数据库事务的管理和封装，它可以让我们在业务层使用声明式或编程式的方式来控制事务的提交或回滚，而不需要直接操作底层的数据库连接。根据搜索结果¹，Spring 事务的使用和原理如下：

- Spring 事务的本质是基于 Spring AOP 技术，在合适的地方开启、提交或回滚事务，从而实现了业务编程层面的事务操作。
- Spring 事务支持两种使用方式，分别是声明式事务（注解方式）和编程式事务（代码方式）。一般来说，声明式事务比较简单方便，只需要在方法或类上添加 @Transactional 注解，并配置相应的属性，如传播行为、隔离级别、回滚规则等。编程式事务则需要手动获取和操作 TransactionTemplate 或 PlatformTransactionManager 对象，更加灵活但也更加繁琐。
- Spring 事务有五个重要的属性，分别是传播行为、隔离级别、回滚规则、超时时间和是否只读。传播行为定义了一个事务方法被另一个事务方法调用时，事务应该如何传播，例如继续在当前事务中运行，或者开启一个新的事务。隔离级别定义了一个事务可能受其他并发事务影响的程度，例如是否允许脏读、不可重复读或幻读。回滚规则定义了哪些异常会导致事务回滚而哪些不会，默认情况下，只有未检查异常（RuntimeException 和 Error 类型的异常）会导致事务回滚。超时时间定义了一个事务允许执行的最长时间，如果超过该时间限制，事务将被回滚。是否只读定义了一个事务是否只对数据库进行读操作，如果是，则可以进行一些优化，提高性能。
- Spring 事务有时候会失效，常见的原因有：没有开启注解扫描或者没有配置 AOP 代理；没有将数据源注入到事务管理器中；在同一个类中调用带有 @Transactional 注解的方法；使用了不支持事务的数据库引擎；使用了不恰当的传播行为或隔离级别等。要避免 Spring 事务失效，需要注意以上这些问题，并且在必要时候检查日志或者数据库状态来确认事务是否生效。

## 58、说一下springMVC

Spring MVC 是 Spring 框架的一个模块，它实现了 MVC（模型-视图-控制器）模式，用于开发基于 Web 的应用程序。根据搜索结果¹²³，Spring MVC 的特点和原理如下：

- Spring MVC 基于前端控制器模式，使用 **DispatcherServlet** 作为主要的请求分发器，它会**根据不同的配置和策略，将请求转发给相应的处理器**（Handler），例如基于 @Controller 和 @RequestMapping 注解的控制器类和方法。
- Spring MVC **支持多种视图技术**，例如 JSP、Velocity、Freemarker、Thymeleaf 等，可以通过 ViewResolver 接口来配置视图解析器，将逻辑视图名映射为具体的视图实现。Spring MVC 还支持直接生成 XML、JSON、Atom 等格式的响应内容，通过使用不同的 HttpMessageConverter 实现。
- Spring MVC 的**模型（Model）**是一个 Map 接口，它允许完全抽象出视图技术，可以**在控制器中向模型中添加数据**，然后在视图中访问这些数据。Spring MVC 还支持使用 @ModelAttribute 注解来绑定请求参数到模型对象中，或者使用 @SessionAttributes 注解来将模型对象存储在会话中。
- Spring MVC 支持使用 Java 配置或者 XML 配置来搭建 Web 应用程序，可以通过 WebApplicationInitializer 接口或者 web.xml 文件来注册 DispatcherServlet，并指定其加载的配置类或者配置文件。Spring MVC 还提供了一些注解和接口来简化和定制配置，例如 @EnableWebMvc、WebMvcConfigurer 等。
- Spring MVC 充分利用了 Spring 框架的核心特性，例如依赖注入、AOP、声明式事务等，可以与其他 Spring 模块无缝集成，也可以与其他 Web 框架协作。
- Spring MVC 还提供了灵活的**拦截器、异常处理器、验证器、类型转换器**等机制，来增强 Web 开发的功能和效率。

> 拦截器

Spring 拦截器是 Spring MVC 框架提供的一种机制，可以在请求到达控制器之前或之后，或者在视图渲染之前或之后，执行一些自定义的逻辑。

- Spring 拦截器需要实现 org.springframework.web.servlet.HandlerInterceptor 接口或者继承 org.springframework.web.servlet.handler.HandlerInterceptorAdapter 类，并重写其中的三个方法：

  preHandle、postHandle 和 afterCompletion。preHandle 方法在请求处理之前被调用，可以进行一些前置初始化操作或者预处理，也可以进行一些判断来决定请求是否要继续进行下去。

  postHandle 方法在请求处理完成之后被调用，但是在视图渲染之前执行，可以对控制器返回的 ModelAndView 对象进行修改或者添加额外的数据。

  afterCompletion 方法在整个请求结束之后被调用，也就是在视图渲染完成之后执行，可以进行一些资源的清理工作。

- Spring 拦截器可以通过 J**ava 配置或者 XML 配置**来注册到拦截器链中，可以指定拦截器要拦截的路径模式，也可以指定拦截器的顺序。拦截器链中的拦截器会按照顺序依次执行 preHandle 方法，如果所有的 preHandle 方法都返回 true，则继续执行控制器的方法和后续的 postHandle 方法。如果有任何一个 preHandle 方法返回 false，则中断请求的处理，直接返回响应，并且只执行已经通过 preHandle 方法的拦截器的 afterCompletion 方法。

- Spring 拦截器可以用来实现一些通用的功能，例如**日志记录、权限检查、性能监控、国际化、主题切换**等。Spring 拦截器也可以基于 URL 或者注解来实现不同的拦截逻辑，例如根据正则表达式匹配 URL 的路径模式，或者根据自定义的注解来标记需要拦截的控制器方法。Spring 拦截器与 Servlet 过滤器类似，但是它更加灵活和强大，因为它可以访问更多的上下文信息，例如控制器对象、方法参数、返回值、异常等。

> 拦截器和过滤器

Spring 拦截器和 Servlet 过滤器都是用来实现请求的拦截和预处理的机制，但是它们之间有一些区别，主要有以下几点：

- Spring 拦截器是 Spring MVC 框架的一部分，它只能拦截经过 DispatcherServlet 的请求，也就是只能拦截 Spring MVC 处理的请求。Servlet 过滤器是 Java Web 规范的一部分，它可以拦截任何类型的请求，包括静态资源、图片、CSS、JS 等。
- Spring 拦截器可以访问 Spring MVC 的上下文信息，例如控制器对象、方法参数、返回值、异常等，它可以对这些信息进行修改或者添加额外的逻辑。Servlet 过滤器只能访问 Servlet API 提供的信息，例如请求对象、响应对象、过滤器链等，它不能对控制器或者视图层进行干预。
- Spring 拦截器可以利用 Spring 框架的特性，例如依赖注入、AOP、声明式事务等，可以与其他 Spring 组件进行协作和集成。Servlet 过滤器是独立于 Spring 框架的，它不能使用 Spring 提供的功能，也不能直接调用其他 Spring 组件。
- Spring 拦截器可以通过注解或者 Java 配置来注册和配置，可以指定拦截器的顺序和路径模式，也可以使用自定义的注解来标记需要拦截的控制器方法。Servlet 过滤器通常需要在 web.xml 文件中进行注册和配置，也可以使用 @WebFilter 注解来注册，但是不能指定过滤器的顺序和路径模式。

> 前后端传参

Spring MVC 是一个基于 MVC 模式的 Web 开发框架，它提供了多种方式来实现前后端的参数传递。根据搜索结果¹²³⁴，Spring MVC 的参数传递方式有以下几种：

- 前端向后端传递参数的方式：
  - 通过 Servlet API 中的 HttpServletRequest 对象，可以使用 request.getParameter() 方法来获取请求参数的值，或者使用 request.setAttribute() 方法来设置请求属性的值。
  - 通过基本数据类型或 String 类型的方法参数，可以直接接收请求参数的值，只要参数名和请求参数名一致，Spring MVC 会自动进行类型转换和赋值。
  - 通过数组、Java Bean、List 或 Map 类型的方法参数，可以接收多个请求参数的值，只要参数名和请求参数名一致或者符合一定的规则，Spring MVC 会自动进行封装和赋值。
  - 通过 @RequestParam 注解，可以指定方法参数接收的请求参数名、是否必须、默认值等属性，可以对请求参数进行更加灵活的处理。
  - 通过 @PathVariable 注解，可以接收 URL 中的路径变量的值，例如 /user/{id}，可以用 @PathVariable("id") 来获取 id 的值。
  - 通过 @RequestBody 注解，可以接收请求体中的数据，例如 JSON、XML 等格式的数据，可以用 @RequestBody User user 来获取 User 对象。
- 后端向前端传递参数的方式：
  - 通过 Servlet API 中的 HttpServletRequest 对象，可以使用 request.setAttribute() 方法来设置请求属性的值，或者使用 request.getSession() 方法来获取会话对象并设置会话属性的值。
  - 通过 ModelAndView 对象，可以同时设置视图名称和模型数据，可以使用 addObject() 方法来添加模型数据，或者使用 setViewName() 方法来设置视图名称。
  - 通过 Model、ModelMap 或 Map 类型的方法参数或返回值，可以设置模型数据，可以使用 addAttribute() 方法来添加模型数据，或者直接使用 Map 的 put() 方法来添加模型数据。
  - 通过 @ModelAttribute 注解，可以将方法参数或返回值绑定到模型数据中，可以指定模型属性的名称或者是否暴露到 URL 中等属性。
  - 通过 @ResponseBody 注解，可以将方法返回值直接写入到响应体中，例如 JSON、XML 等格式的数据，可以用 @ResponseBody User user 来返回 User 对象。

> REST的理解

通俗地解释，REST 是一种让 Web 应用程序更简单、更灵活、更高效的设计方法。

它的核心思想是，把 Web 应用程序中的各种**内容和功能看作是资源**，每个**资源都有一个地址**，就像网页的 URL 一样。客户端可以通过不同的 HTTP 方法（如 GET、POST 等）来**访问和操作这些资源**，就像浏览器访问和操作网页一样。**服务器端只负责提供和处理资源，不需要保存客户端的状态，也不需要使用复杂的协议或者格式**。这样，客户端和服务器端就可以分开开发和部署，只要遵循统一的接口规范，就可以实现互通和协作。



## 59、说一下springboot

> 理解

**1、** 用来简化spring应用的初始搭建以及开发过程 使用特定的方式来进行配置（properties或yml文件）

**2、** 创建独立的spring引用程序 main方法运行

**3、** 嵌入的Tomcat 无需部署war文件

**4、** 简化maven配置

> 读取配置的方式

SpringBoot 可以通过 @PropertySource,@Value,@Environment, @ConfigurationProperties 来绑定变量

> 自动配置原理

SpringBoot启动的时候通过@EnableAutoConfiguration注解找到META-INF/spring.factories配置文件中所有的自动配置类，

并对其进行加载，而这些自动配置类的类名都是以AutoConfiguration结尾来命名的，

它实际上就是一个javaConfig形式的Spring容器配置类，

都有一个@EnableConfigurationPerperties的注解，通过这个注解启动XXXProperties命名的类去加载全局配置中的属性，

将全局配置文件中的属性与自己的属性进行绑定。

> 配置加载顺序

**1、** properties文件 2、YAML文件 3、系统环境变量 4、命令行参数

> 项目运行方式

打包用命令或者放到容器中运行

**1、** 打成jar包，使用java -jar xxx.jar运行

**2、** 打成war包，放到tomcat里面运行

直接用maven插件运行 maven spring-boot：run

直接执行main方法运行

> stater工作原理

总结一下，其实就是 SpringBoot 在启动的时候，按照约定去读取 SpringBoot Starter 的配置信息，再根据配置信息对资源进行初始化，并注入到 Spring 容器中。



## 60、说一下springcloud

而Spring Cloud是一个基于Spring Boot实现的分布式系统开发工具集，它提供了一些常见的微服务架构模式的实现，例如服务发现、服务网关、服务路由、链路追踪等。

Spring Cloud可以帮助开发者快速搭建和管理分布式系统，提高系统的可用性和可扩展性。

## 61、说一下linux的基本命令

Linux基本命令是一些在Linux操作系统中执行各种任务的文本指令。它们通常由程序名、选项和参数组成，例如 `ls -l /home`。

- `pwd`：打印当前工作目录的绝对路径。
- `cd`：切换当前工作目录。
- `ls`：列出当前目录或指定目录下的文件和子目录。
- `touch`：创建一个空白文件或更新一个文件的修改时间。
- `cp`：复制一个文件或目录到另一个位置。
- `mv`：移动或重命名一个文件或目录。
- `rm`：删除一个文件或目录。
- `cat`：显示或连接一个或多个文件的内容。
- `grep`：在一个或多个文件中搜索匹配的文本模式。
- `find`：在一个目录树中查找符合条件的文件或目录。
- `ps`：显示当前运行的进程的信息。
- `kill`：发送信号给一个进程，使其终止。
- `ping`：发送数据包到一个网络主机，测试其连通性。
- `ssh`：使用安全壳协议（Secure Shell）远程登录到另一台计算机。
- `scp`：使用安全壳协议（Secure Shell）复制文件到另一台计算机。
- `tar`：创建或解压缩一个压缩归档文件。
- `top`：显示系统资源使用情况和活动进程的动态视图。
- `date`：显示或设置系统日期和时间。

> 命令组合

组合使用不同的命令和选项参数是一种提高Linux命令行效率和灵活性的方法。它可以让您实现更复杂和更强大的功能，而不需要写脚本或程序。组合使用不同的命令和选项参数的基本方法是使用管道符`|`或重定向符`>`。

管道符`|`可以将一个命令的输出作为另一个命令的输入，从而实现数据的流式处理。例如，您可以使用以下命令来查找当前目录下所有包含hello的文本文件，并显示它们的文件名和行号：

`grep -n hello *.txt | cut -d: -f1,2`

这个命令的含义是：

- `grep -n hello *.txt`：在当前目录下的所有txt文件中查找包含hello的行，并在每行前面显示行号，用冒号分隔。
- `cut -d: -f1,2`：以冒号为分隔符，只显示每行的第一和第二个字段，即文件名和行号。
- `|`：将前一个命令的输出作为后一个命令的输入。

重定向符`>`可以将一个命令的输出保存到一个文件中，而不是显示在屏幕上。例如，您可以使用以下命令来将当前目录下所有txt文件的内容合并到一个新文件中：

`cat *.txt > new.txt`

这个命令的含义是：

- `cat *.txt`：显示当前目录下所有txt文件的内容。
- `>`：将前一个命令的输出保存到后面指定的文件中，如果文件不存在则创建，如果文件已存在则覆盖。
- `new.txt`：指定要保存输出的文件名。





## 62、说一下linux网络分析命令

- `hostname`：显示或设置主机名。
- `ping`：发送数据包到指定的主机或IP地址，并显示回应时间和丢包率。
- `ifconfig`：显示或配置网络接口的参数，如IP地址，子网掩码，广播地址等。
- `iwconfig`：显示或配置无线网络接口的参数，如SSID，信号强度，频道等。
- `netstat`：显示网络连接，路由表，接口状态，多播组成员等信息。
- `nslookup`：查询域名系统（DNS）服务器，解析域名或IP地址。
- `traceroute`：显示数据包从本地主机到目标主机经过的路由器列表和延迟时间。
- `telnet`：使用telnet协议远程登录到另一台主机或测试某个端口的连接情况。
- `ethtool`：显示或修改以太网设备的设置，如速度，双工模式，自动协商等。
- `tcpdump`：捕获并打印通过指定网络接口的数据包，并支持各种过滤条件和选项。
- `wireshark`：一个图形化的网络分析工具，可以捕获并解析各种协议的数据包，并提供丰富的统计功能和可视化界面。

## 63、说一下linux内存分析命令

- `free`：显示当前系统未使用的和已使用的物理内存和交换内存的数量，以及被内核使用的缓冲区和缓存的数量。
- `vmstat`：显示虚拟内存的统计信息，包括进程，内存，分页，阻塞IO，中断，磁盘和CPU。
- `/proc/meminfo`：显示/proc文件系统中与内存相关的信息，包括物理内存，交换内存，缓冲区，缓存，活动内存，非活动内存等。
- `top`：显示系统中CPU和内存使用情况的动态视图，包括每个进程的CPU占用率和内存占用率。
- `htop`：显示系统中CPU和内存使用情况的动态视图，类似于top，但提供了更多的功能和选项。
- `pmap`：显示进程的内存映射关系，包括每个内存段的地址，大小，权限，映射文件等。



## 64、说一下linux日志分析命令

Linux日志分析命令可以分为不同的类别，根据它们的功能和用途。例如，有些命令用于显示日志文件的内容，有些用于过滤或搜索日志文件中的特定信息，有些用于统计或排序日志文件中的数据等等。¹

以下是一些常见的Linux日志分析命令的例子和简要说明：

- `tail`：显示日志文件的最后几行内容，可以指定行数或持续监控。
- `head`：显示日志文件的最前几行内容，可以指定行数。
- `cat`：显示日志文件的全部内容，从第一行到最后一行。
- `tac`：显示日志文件的全部内容，从最后一行到第一行。
- `more`：分页显示日志文件的内容，支持向上和向下滚动。
- `less`：分页显示日志文件的内容，支持向上和向下滚动，以及搜索和跳转等功能。
- `grep`：搜索日志文件中匹配指定模式的行，并显示出来。
- `sed`：对日志文件中的内容进行编辑或替换，并输出结果。
- `awk`：对日志文件中的内容进行分析或处理，并输出结果。
- `sort`：对日志文件中的内容进行排序，并输出结果。
- `uniq`：对日志文件中的内容进行去重，并输出结果。
- `cut`：对日志文件中的内容进行切割，并输出结果。
- `wc`：统计日志文件中的行数，单词数，字符数等，并输出结果。

> 查看错误日志

Linux错误日志是记录系统或应用程序出现错误的文件，通常存放在/var/log目录下

- `ls /var/log`：列出/var/log目录下的所有日志文件，找出可能包含错误信息的文件，如syslog，messages，dmesg等。
- `cd /var/log`：进入/var/log目录，然后使用其他命令来查看具体的错误日志文件。
- `tail /var/log/syslog`：查看系统日志的最后几行内容，可以指定行数或持续监控，看是否有错误信息。
- `grep error /var/log/syslog`：查找系统日志中包含error的行，并显示出来。
- `less /var/log/syslog`：分页显示系统日志的内容，支持向上和向下滚动，以及搜索和跳转等功能，可以查找和定位错误信息。



## 65、说一下设计模式基本原则

- 单一职责原则（Single Responsibility Principle，SRP）：一个类或模块只负责一个功能领域中的相应职责，避免出现一个类或模块负责过多职责的情况。¹²
- 开放-关闭原则（Open-Closed Principle，OCP）：一个软件实体（类、模块、函数等）应该对扩展开放，对修改关闭。也就是说，当软件需要变化时，应该通过扩展已有的代码来实现变化，而不是修改原有的代码。¹²
- 里氏替换原则（Liskov Substitution Principle，LSP）：所有引用基类的地方必须能透明地使用其子类的对象。也就是说，子类对象可以替换父类对象，而程序逻辑不变。¹²
- 依赖倒转原则（Dependency Inversion Principle，DIP）：高层模块不应该依赖于低层模块，二者都应该依赖于抽象；抽象不应该依赖于细节，细节应该依赖于抽象。也就是说，要针对接口编程，而不是针对实现编程。¹²
- 接口隔离原则（Interface Segregation Principle，ISP）：使用多个专门的接口，而不使用单一的总接口，即客户端不应该依赖那些它不需要的接口。¹²
- 合成/聚合复用原则（Composite/Aggregate Reuse Principle，CARP）：尽量使用合成/聚合方式，而不是通过继承达到复用的目的。也就是说，在一个新的对象里面使用一些已有的对象，使之成为新对象的一部分；新对象通过向这些对象的委派达到复用已有功能的目的。¹²
- 迪米特法则（Law of Demeter，LOD）或最少知识原则（Least Knowledge Principle，LKP）：一个软件实体应当尽可能少地与其他实体发生相互作用。也就是说，每个软件实体应当尽可能少地了解其他实体，并且只与它们直接相关的实体发生交互。



## 66、说一下桥接模式

桥接模式是一种结构型设计模式，它可以将抽象部分和实现部分分离，使它们可以独立地变化

 它通过提供一个桥接接口，来实现抽象和实现之间的解耦

桥接模式可以避免在多个维度变化的情况下，使用继承导致的类爆炸问题，提高了系统的扩展性和灵活性。

桥接模式的主要角色有：

- 抽象化（Abstraction）角色：定义抽象类，并包含一个对实现化对象的引用。
- 修正抽象化（RefinedAbstraction）角色：扩展抽象化角色，改变和修正父类对抽象化的定义。
- 实现化（Implementor）角色：定义实现化角色的接口，供抽象化角色调用。
- 具体实现化（ConcreteImplementor）角色：给出实现化角色接口的具体实现。

桥接模式的使用场景有：

- 如果一个系统需要在抽象化和具体化之间增加更多的灵活性，避免在两个层次之间建立静态的继承关系，可以通过桥接模式将它们在抽象层建立一个关联关系。
- 如果一个类存在两个或多个独立变化的维度，且这些维度都需要进行扩展，可以使用桥接模式将这些维度分离出来，让它们独立变化，减少它们之间的耦合。





## 67、说一下单例模式

单例模式是一种创建型的设计模式，它保证一个类在整个系统中只有一个实例对象，并提供一个全局访问点。

单例模式的目的是为了控制实例的数量，节省系统资源，避免对资源的多重占用，保证数据的一致性和安全性。

单例模式有多种实现方式，常见的有以下几种：

- 饿汉式：在类加载时就创建唯一的实例对象，优点是简单且线程安全，缺点是可能造成内存浪费。
- 懒汉式：在第一次调用时才创建唯一的实例对象，优点是实现了懒加载，缺点是需要加锁保证线程安全，可能影响性能。
- 双重检查锁：在懒汉式的基础上，使用双重判断和同步锁来避免多次创建实例对象，优点是既实现了懒加载又保证了线程安全，缺点是需要使用volatile关键字防止指令重排。
- 静态内部类：使用一个静态内部类来持有唯一的实例对象，优点是利用了类加载机制保证了线程安全和懒加载，缺点是可能被反射破坏单例。
- 枚举：使用枚举类型来实现单例模式，优点是简洁且能防止反射和反序列化破坏单例，缺点是没有延迟加载。



## 68、说一下工厂模式

工厂模式是一种创建型的设计模式，它使用工厂方法代替直接使用new操作符来创建对象，从而实现了对象的创建和对象的使用分离。¹

工厂模式有三种常见的形式，分别是：

- 简单工厂模式：定义一个工厂类，根据不同的参数返回不同类型的对象实例，客户端只需要知道参数即可，无需关心对象的创建细节。
- 工厂方法模式：定义一个抽象的工厂接口或类，让其**子类或实现类决定具体创建哪一种类型**的对象实例，客户端只需要知道工厂即可，无需关心对象的创建细节。
- 抽象工厂模式：定义一个抽象的工厂接口或类，让其**子类或实现类负责创建一系列相关或相互依赖的对象**实例，客户端只需要知道工厂即可，无需关心对象的创建细节。



## 69、说一下代理模式

代理模式是一种设计模式，它的思路是为其他对象提供一种代理，以控制对这个对象的访问。代理模式可以分为静态代理和动态代理，静态代理是在编译时就确定了代理类和被代理类的关系，动态代理是在运行时动态生成代理类，可以实现更灵活的代理功能。

静态代理的实现思路是：

- 定义一个抽象角色，通过接口或抽象类声明真实角色实现的业务方法。
- 定义一个真实角色，实现抽象角色，定义真实角色所要实现的业务逻辑，供代理角色调用。
- 定义一个代理角色，实现抽象角色，持有真实角色的引用，并在调用真实角色的方法前后进行一些增强操作。

动态代理的实现思路有两种：

- JDK动态代理：利用Java反射机制，通过接口创建代理类，并实现一个InvocationHandler接口，重写invoke方法，在该方法中调用被代理对象的方法，并进行一些增强操作。
- CGLib动态代理：利用第三方库CGLib，通过继承目标类创建子类，并实现一个MethodInterceptor接口，重写intercept方法，在该方法中调用父类的方法，并进行一些增强操作。



## 70、介绍一下项目

基于springboot构建，主要实现了一个社区互动的功能，包括用户的注册登录，权限控制，用户发帖，浏览帖子，对帖子进行评论，回复，点赞，对其他用户进行关注和私信，以及系统通知，帖子搜索，热榜排行，管理员对帖子进行加管理和统计数据等功能。

在技术栈上，前端使用thyleaf作为模板引擎，使用ajax实现一些异步请求的发送，后端使用springboot搭建项目，使用maven进行依赖管理，使用github进行版本控制，使用mysql存储网站数据，使用mybatics-plus实现mysql的存取等操作，使用redis还有本地缓存存储频繁存取的数据，使用kafka来处理一些后台的事件，使用elasticsearch做了一个全文搜索，使用springsecurity对不同的用户以及状态进行权限管理，使用对象存储作为网站的图床，使用quartz实现定时任务，去更新帖子的热榜，去更新全文搜索的内容，使用docker来将项目部署到linux环境。



## 71、权限管理是如何实现的

用户有多种身份，在数据库中通过一个字段来标识，使用自己的登录逻辑，构建一个用户认证的结果。

使用security根据用户认证实现不同权限的用户可以访问不同的服务，并处理权限不足的访问，以及在页面上控制不同的展示。



> security如何实现全局上下文

Spring Security所谓的全局上下文是指SecurityContext，它是一个接口，用于存储当前执行线程的最少量的安全信息，如Authentication对象。

SecurityContext是通过SecurityContextHolder来管理的，SecurityContextHolder是一个类，提供了一组静态方法来操作SecurityContext²。

SecurityContextHolder可以根据系统变量spring.security.strategy的值来选择不同的策略来保存SecurityContext，有三种策略可选：ThreadLocal、InheritableThreadLocal和Global²。

ThreadLocal模式是默认的，它使用ThreadLocal来存储每个线程的SecurityContext¹。

> Spring Security是如何完成身份认证的？

用户名和密码被过滤器获取到，封装成Authentication,通常情况下是UsernamePasswordAuthenticationToken这个实现类。

AuthenticationManager 身份管理器负责验证这个Authentication

认证成功后，AuthenticationManager身份管理器返回一个被填充满了信息的（包括上面提到的权限信息，身份信息，细节信息，但密码通常会被移除）Authentication实例。

 SecurityContextHolder安全上下文容器将第3步填充了信息的Authentication，设置到全局上下文。

>核心组件

- SecurityContext：是一个接口，它提供了访问当前用户的安全上下文的方法。 
- SecurityContextHolder：是一个用于存储SecurityContext的类，它提供了对SecurityContext的访问方法。 
- Authentication：是一个接口，它代表了一个用户的身份验证信息。 
- Userdetails：是一个接口，它提供了有关用户的基本信息。 
- AuthenticationManager：是一个接口，它负责处理身份验证请求¹.

> 核心过滤器

1. SecurityContextPersistenceFilter：负责在请求到达时创建SecurityContext安全上下文信息，并在请求结束时清空SecurityContextHolder。
2. LogoutFilter：处理注销的过滤器。
3. UsernamePasswordAuthenticationFilter：处理用户名密码登录认证的过滤器。
4. BasicAuthenticationFilter：处理HTTP Headers中呈现的基本身份验证凭据，并将结果放入SecurityContextHolder中。
5. ExceptionTranslationFilter：负责处理Spring Security抛出的异常。

## 72、搜索功能如何实现

将帖子存储到elasticsearch里边，配置elasticsearch的分词器，对查询的内容进行分词，然后进行内容检索，将检索的结果进行处理，对分词后的关键字进行高亮显示，最后将信息整合，做一下排序，响应给前端。

当帖子进行了更新和删除的时候，会更新es里的内容。

> 倒排索引

分词：分词用于检索，英文的分词是按单词之间空格区分，中文要考虑效率和准确分词率，防止出现歧义。

倒排：根据文档内容找文档，从关键字去找文档。

倒排索引是搜索引擎的核心。搜索引擎的主要目标是在查找发生搜索条件的文档时提供快速搜索。区别于传统的正向索引，倒排索引会再存储数据时将关键词和数据进行关联，保存到倒排表中，然后查询时，将查询内容进行分词后在倒排表中进行查询，最后匹配数据即可。



Elasticsearch 使用一种称为倒排索引的结构，ES中的倒排索引其实就是 **lucene 的倒排索引**，它适用于快速的全文搜索。

正向索引（forward index），就是搜索引擎会将待搜索的文件都对应一个文件 ID，搜索时将这个ID 和搜索关键字进行对应，形成 K-V 对，然后对关键字进行统计计数。但是互联网上收录在搜索引擎中的文档的数目是个天文数字，这样的索引结构根本无法满足**实时返回排名结果**的要求。

所以，搜索引擎会将正向索引重新构建为反向索引（inverted index，倒排索引），即**把文件ID对应到关键词的映射，转换为关键词到文件ID的映射**，每个关键词都对应着一系列的文件，并保存到倒排表中，查询时会将内容进行分词后在倒排表中进行查询，最后匹配数据即可。

> elasticsearch搜索过程

在 Elasticsearch 中，搜索过程分为查询阶段（Query Pahse）和获取阶段（Fetch Phase）。查询阶段是搜索的核心，它会广播到索引中每一个分片拷贝（主分片或者副本分片），每个分片在本地执行搜索并构建一个匹配文档的大小为 from + size 的优先队列。

获取阶段是将查询结果从每个分片中取回并组装成完整的结果集，然后返回给客户端。



## 73、如何统一异常处理

使用ControllerAdvice进行统一异常处理，拦截所有的controller响应，当controller发生异常时，捕获，根据请求的类型响应错误信息，并且将错误日志进行记录。





## 74、如何统一日志

使用Aspect对service做一个AOP增强，配置需要记录日志的切入点，编写一个在方法之前执行的切面进行日志的记录，当调用切入点时，会先执行切面，记录访问日志。





## 75、事务是如何实现的

在service层使用注解@Transactional，设置隔离级别和传播级别





## 76、敏感词过滤是如何实现的

将创建一棵敏感词的前缀树，对字符串进行过滤，以每一个字符为起点，在前缀树中检索关键词，若是关键词则使用**号代替，最后输出过滤后的字符串。

前缀树利用字符串的公共前缀来减少查询时间，最大限度地减少无谓的字符串比较。





## 77、注册是怎么做的

前端通过表单提交数据，对表单数据进行格式检查，然后进行用户的查重，如果是新用户就将用户信息存到mysql，在数据库中使用一个字段存储用户的激活状态，注册后需要验证邮箱，使用JavaMailSender向用户发送邮件，用户点击激活后将数据库里激活状态字段值进行更新即可。





## 78、评论、点赞、关注是如何实现的

评论存储在mysql，点赞和关注信息都是存储到redis，方便存取，查询点赞和关注信息时也都是从redis获取数据。

评论有两种，一种是评论帖子的，一种是回复给评论的，每个评论都保存有它评论的对象，在插入记录时使用事务同时更新被评论对象的相关信息。

评论点赞和专注都会触发事件机制，生成事件后到消息队列kafka排队，当消费到它时，会将事件的相关信息提取出来，给事件关联的对象发送一个系统通知，告诉它有人对他的帖子进行了评论，点赞还要关注。





## 79、私信、通知是如何实现的

私信和通知本质上是一样的，只不过通知的发送者是系统，消息存储在mysql数据库，当用户浏览时会在数据库表中进行查询。

在浏览私信和通知的时候，会在私信和通知列表显示未读消息的数量，当信息被浏览时，会将看到的信息设置为已读，更新到数据库。

私信是以会话为单位进行组织和管理，两个用户之间是一个对话。会话列表和消息列表都使用了分页管理，系统通知进行了分类。

系统通知的发送是通过消息队列Kafka来完成的，可以显著提高网站的响应速度，在后台空闲时消费，发送通知；

发送私信则是一个同步的请求，在对数据库进行更新后才会响应







## 80、定时任务是如何实现的

因为帖子的热度在实时变化，因此需要定时去更新帖子热度，更新数据库，还有es;

在引起热度变化的事件发生时，将需要更新热度的帖子的id存入redis，然后按照一定的时间去查看是否有需要更新的帖子，如果有就执行更新，将最新的帖子更新到mysql，还有es。

使用Quartz模块实现定时任务，配置一下mysql，设置定时执行的时间，使用的线程数量等，然后编写执行任务的逻辑，根据公式计算帖子的热度，然后更新mysql以及es。



quartz是一个开源项目，完全基于java实现。是一个优秀的开源调度框架。
特点：
1，强大的调度功能，例如支持丰富多样的调度方法
2，灵活的应用方式，例如支持任务和调度的多种组合方式
3，分布式和集群能力
专业术语：
scheduler：任务调度器 ， scheduler是一个计划调度器容器，容器里面有众多的JobDetail和trigger，当容器启动后，里面的每个JobDetail都会根据trigger按部就班自动去执行
trigger：触发器，用于定义任务调度时间规则
job：任务，即被调度的任务， 主要有两种类型的 job：无状态的（stateless）和有状态的（stateful）。一个 job 可以被多个 trigger 关联，但是一个 trigger 只能关联一个 job
misfire：本来应该被执行但实际没有被执行的任务调度





## 81、如何提升网站性能

首先是使用redis存储一些频繁操作的数据，redis的存取效率远高于mysq，其次利用redis代替session存储一些临时数据；



对于一些变化不大，但是经常使用的数据，使用本地缓存Caffeine，保存在服务器的机器上，降低响应的时间，比如将高热度的帖子保存在本地缓存，在查找的时候直接获取，不需要访问数据库和redis，极大提高效率。

Caffeine 是一个基于Java 8的高性能本地缓存框架
初始化cache：缓存保存的对象，使用Caffeine.newBuilder()创建，创建时设置缓存大小，过期时间，缓存未命中时的加载方式。



使用消息队列，将一些后台工作暂时保存起来，服务器空闲时处理，提高系统的响应速度

## 82、数据统计如何实现

使用redis快速存储，统计，使用拦截器对请求进行分析记录即可

可以对请求的IP进行统计，也可以对请求所属的用户进行统计。

利用redis的HyperLogLog数据结构实现快速计数。

## 83、部署是怎么做的

在linux环境部署项目，使用docker快速安装mysql，redis，es，kafka等服务，由于机器性能有限，以及项目规模不大，选择了部署到同一个虚拟机，使用maven打包，tomcat作为服务器，使用nginx做代理。

> 什么是Nginx

Nginx是一个 轻量级/高性能的反向代理Web服务器，他实现非常高效的反向代理、负载平衡，他可以处理2-3万并发连接数，官方监测能支持5万并发，现在中国使用nginx网站用户有很多，例如：新浪、网易、 腾讯等。

> 为什么要用Nginx？

+ 跨平台、配置简单、方向代理、高并发连接：处理2-3万并发连接数，官方监测能支持5万并发。
+ 健康检查功能：如果有一个服务器宕机，会做一个健康检查，再发送的请求就不会发送到宕机的服务器了。
+ 异步处理客户端请求
+ 占内存小，可实现高并发连接，处理响应快
+ 可实现http服务器、虚拟主机、方向代理、负载均衡
+ 不暴露正式的服务器IP地址

> 为什么Nginx性能这么高？

- 因为他的事件处理机制：异步非阻塞事件处理机制：运用了epoll模型，提供了一个队列，排队解决

> Nginx怎么处理请求的？

- nginx接收一个请求后，首先由listen和server_name指令匹配server模块，再匹配server模块里的location，location就是实际地址

  ```shell
      server {            						# 第一个Server区块开始，表示一个独立的虚拟主机站点
          listen       80；      					# 提供服务的端口，默认80
          server_name  localhost；       			# 提供服务的域名主机名
          location / {            				# 第一个location区块开始
              root   html；       				# 站点的根目录，相当于Nginx的安装目录
              index  index.html index.htm；      	# 默认的首页文件，多个用空格分开
          }          								# 第一个location区块结果
  
  ```

  

> 正向代理和反向代理

正向代理：代理的对象是客户端，客户端通过正向代理访问目标服务器，目标服务器无法直接访问客户端。正向代理可以用于翻墙、隐藏客户端IP等。

反向代理：代理的对象是服务端，客户端通过反向代理访问目标服务器，目标服务器无法直接访问客户端。反向代理可以用于负载均衡、缓存、安全防护等

> Nginx应用场景

+ http服务器。Nginx是一个http服务可以独立提供http服务。可以做网页静态服务器。
+ 虚拟主机。可以实现在一台服务器虚拟出多个网站，例如个人网站使用的虚拟机。
+ 反向代理，负载均衡。当网站的访问量达到一定程度后，单台服务器不能满足用户的请求时，需要用多台服务器集群可以使用nginx做反向代理。并且多台服务器可以平均分担负载，不会应为某台服务器负载高宕机而某台服务器闲置的情况。
+ nginz 中也可以配置安全管理、比如可以使用Nginx搭建API接口网关,对每个接口服务进行拦截。



> 为什么选用 Maven 进行构建

首先，Maven 是一个优秀的项目构建工具。使用maven，可以很方便的对项目进行分模块构建，这样在开发和测试打包部署时，效率会提高很多。

其次，Maven 可以进行依赖的管理。使用 Maven，可以将不同系统的依赖进行统一管理，并且可以进行依赖之间的传递和继承。

> maven仓库

Maven仓库是基于简单文件系统存储的，集中化管理Java API资源（构件）的一个服务。仓库中的任何一个构件都有其唯一的坐标，根据这个坐标可以定义其在仓库中的唯一存储路径。

本地仓库就是相当于加了一层jar包缓存，先到这里来查。如果这里查不到，那么就去私服上找，如果私服也找不到，那么去中央仓库去找，找到jar后，会把jar的信息同步到私服和本地仓库中。

私服，是公司内部局域网的一台服务器；

中央仓库存储了互联网上的jar，由Maven团队来维护

> maven的依赖原则

依赖路径最短优先原则

pom文件中申明顺序优先

覆写优先原则

> Maven的工程类型有哪些？

POM工程，POM工程是逻辑工程。用在父级工程或聚合工程中。用来做jar包的版本控制；

JAR工程，将会打包成jar用作jar包使用。即常见的本地工程 - Java Project；

WAR工程，将会打包成war，发布在服务器上的工程

> Maven常用命令

 maven clean：对项目进行清理，删除target目录下编译的内容

maven compile：编译项目源代码

maven test：对项目进行运行测试

maven packet：打包文件并存放到项目的target目录下，打包好的文件通常都是编译后的class文件

maven install：在本地仓库生成仓库的安装包，可供其他项目引用，同时打包后的文件放到项目的target目录下

> 什么是 Docker 容器

Docker 容器 在应用程序层创建抽象并**将应用程序及其所有依赖项打包**在一起，容器就是应用程序运行所需要的环境的集合ie，**仅依赖于底层的CPU和内存**

> 创建 Docker 容器

docker run -it -d <image_name>

> 如何启动、停止和终止容器

$docker start <container_id>

 docker stop <container_id>

 docker kill <container_id>

> 虚拟化和容器化有什么区别

虚拟化是一种技术，它可以在一台物理计算机上运行多个虚拟机，每个虚拟机都可以运行不同的操作系统和应用程序。

容器化是一种轻量级的虚拟化技术，它可以在一个操作系统上运行多个容器，每个容器都可以运行不同的应用程序。

容器化比传统虚拟化更加轻量级，因为它们共享主机操作系统的内核，而传统虚拟化需要为每个虚拟机提供一个完整的操作系统。

这意味着容器启动和停止速度更快，并且占用更少的资源。

> 访问正在运行的容器

docker exec -it <container_id> bash

> 所有正在运行的容器

docker ps





## 84、难点在哪些地方

在部署方面，在刚开始，使用云服务器部署，没有使用docker，就是一个服务一个服务的装上去，改配置，有时候出错了，就查看日志，鼓捣了好几天才跑通；后来使用docker部署后就好多了。

在模块的选择方面，由于各个模块的对应版本要求都不太一样，在选择elasticsearch的时候就冲突过，调试的过程还是比较费劲的。

前端页面的编写还是比较困难的，因为没有那么多提示，而且对于前端的代码经验不是很多，常常鼓捣半天搞不出想要的效果，也找不到哪里出的毛病，比如有一次通过ajax发送异步请求，响应函数不能成功执行，测试后端又是成功返回的，后来才想明白是异步的原因，执行响应函数的时候还没有返回结果，改成同步的就解决了问题；

在处理前后端参数传递的时候，对于几种传参方式，请求路径带参数，restful风格，异步请求传参，form表单穿数据，接受参数的方式有些小的差异，什么时候可以用对象接受，什么时候需要加注解，当时是比较迷惑的。

## 85、哪些方面可以优化

服务器主动推送(消息，私信)，前端可以获取实时数据，特别是私信模块；

可以将服务部署到多个服务器上，提高稳定性和系统带宽。

管理员的权限还不支持申请，可以开通这个成为管理员，或者版主的渠道

在帖子的详情页面可以设置一个返回的功能，返回进入详情之前的页面，可能是分页展示的其中一页，也可能是全文搜索的结果；

全文搜索应该提供一个过滤的条件选择，类似引流，发帖也可以为自己的帖子设置引流；

发帖和私信可以优化支持图片，表情包，文件等多元化的信息；

帖子可以支持后期修改，以及删除自己的帖子；

实现帖子浏览量的一个统计，以及在评论区显示楼主以及作者的一个标签；

可以提供一个举报帖子和用户的选项，管理员多设置一个页面来管理这些举报内容；

帖子评论的回复过多的时候可以选择折叠；

## 86、登录是怎么实现的

对于用户的首次登录需要进行账号密码的检查，以及验证码的核检，验证码是使用kaptcha生成的，然后存储到redis，并将key值存到cooike中，当用户登录的时候从cookie取出key，再从redis取出验证码进行比对。

成功登录后会生成一个登录凭证，保存到redis中，登录凭证没过期之前，都是不需要重新进行登录的，编写一个拦截器对所有需要登录操作的请求进行拦截，从redis取出ticket检查是否过期。

## 87、说一下kafka

> 简介

Kafka是一种高吞吐量的分布式发布订阅消息系统，它最初由LinkedIn公司开发，现在是Apache的顶级子项目。Kafka可以处理消费者规模的网站中的所有动作流数据，具有高性能、持久化、多副本备份、横向扩展能力

Kafka的基本原理是：生产者将消息发布到主题（topic）中，消费者从主题中订阅消息并消费。

> 架构

Kafka的架构包括生产者、消费者、broker和ZooKeeper集群。

生产者将消息发布到主题（topic）中，消费者从主题中订阅消息并消费。

Broker是Kafka集群中的一个节点，负责存储和转发消息。

> 性能

Kafka是一个具有高吞吐，可水平扩展，可持久化的流式数据处理平台¹。

Kafka性能体现在两个主要方面：吞吐量和延迟²。Kafka采用顺序写文件的方式来提高磁盘写入性能，基本减少了磁盘寻道和旋转的次数

> 工作流程

Kafka的工作流程如下¹：

1. 生产者将消息发送到Kafka集群中，每条消息追加到主题的分区中的末端。
2. 每个分区都有维护一个偏移量offset，由0开始，每条消息都有一个偏移量，每新增一条数据偏移量加一。
3. 消费者从Kafka集群中读取消息，消费者可以订阅一个或多个主题，并按照分区读取数据。
4. 消费者读取数据时，可以指定从哪个偏移量开始读取数据。
5. Kafka集群会保留所有发布的消息，无论这些消息是否已被消费。消费者可以多次读取同一条消息。

> 消息丢失

Kafka的消息丢失问题可能会发生在Broker、Producer和Consumer三种中的任意一种。Broker消息丢失是由Kafka自身原因造成的，也可以理解为由现有的操作系统组成方式造成的。kafka为了提高吞吐量和性能，采用异步批量的刷盘策略，也就是按照一定的消息量，和间隔时间进行刷盘。这种策略虽然提高了性能，但是也会带来消息丢失的风险⁴。

如果您想要避免消息丢失，可以考虑以下几种方案：

1. 使用同步发送方式，这样可以保证数据不会丢失，但是会影响性能。
2. 设置acks=all，这样可以保证数据不会丢失，但是会影响性能。
3. 设置重试次数，当发送失败时可以进行重试。
4. 设置备份机制，当主机宕机时可以使用备份机制来保证数据不会丢失。



## 88、redis为什么那么快

1. Redis是基于内存的，内存的读写速度非常快（纯内存）；
2. 数据存在内存中，数据结构用HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；
3. Redis是单线程的，省去了很多上下文切换线程的时间（避免线程切换和竞态消耗）；
4. 非阻塞IO、多路IO复用模型。

## 89、说一下Java线程

> 说说 sleep() 方法和 wait() 方法区别和共同点?

- 两者最主要的区别在于：**`sleep()` 方法没有释放锁，而 `wait()` 方法释放了锁** 。
- 两者都可以暂停线程的执行。
- `wait()` 通常被用于线程间交互/通信，`sleep() `通常被用于暂停执行。
- `wait()` 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 `notify() `或者 `notifyAll()` 方法。`sleep() `方法执行完成后，线程会自动苏醒。或者可以使用 `wait(long timeout)` 超时后线程会自动苏醒。

> 说一说自己对于 synchronized 关键字的了解

**`synchronized` 关键字解决的是多个线程之间访问资源的同步性，`synchronized`关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。**



在 Java 早期版本中，`synchronized` 属于 **重量级锁**，效率低下

因为监视器锁（monitor）是依赖于底层的操作系统的 `Mutex Lock` 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高。



DK1.6 对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。现在的 `synchronized` 锁效率也优化得很不错了



> synchronize和reentrantlock有什么区别？

`synchronized`和`ReentrantLock`都是Java中的锁机制，但是它们有一些区别。 

- 底层实现：`synchronized`是JVM层面的锁，是Java关键字，通过monitor对象来完成，而`ReentrantLock`是从JDK1.5以来提供的API层面的锁。
- 是否可手动释放：`synchronized`不需要用户去手动释放锁，系统会自动让线程释放对锁的占用；而`ReentrantLock`则需要用户去手动释放锁，如果没有手动释放锁，就可能导致死锁现象。



> 锁升级

级别从低到高依次是：

1. 无锁状态

2. 偏向锁状态

   偏向锁是针对于一个线程而言的，线程获得锁之后就不会再有解锁等操作了，这样可以省略很多开销。假如有两个线程来竞争该锁话，那么偏向锁就失效了，进而升级成轻量级锁了。

3. 轻量级锁状态

   如果线程发现对象头中Mark Word已经存在指向自己栈帧的指针，即线程已经获得轻量级锁，那么只需要将0存储在自己的栈帧中（此过程称为递归加锁）；在解锁的时候，如果发现锁记录的内容为0， 那么只需要移除栈帧中的锁记录即可，而不需要更新Mark Word。

4. 重量级锁状态

   重量级锁（`heavy weight lock`），是使用操作系统互斥量（`mutex`）来实现的传统锁。 当所有对锁的优化都失效时，将退回到重量级锁。它与轻量级锁不同竞争的线程不再通过自旋来竞争线程， 而是直接进入堵塞状态，此时不消耗CPU，然后等拥有锁的线程释放锁后，唤醒堵塞的线程， 然后线程再次竞争锁。

锁可以升级，但不能降级。即：无锁 -> 偏向锁 -> 轻量级锁 -> 重量级锁是单向的。

> volatile 关键字

把变量声明为 **`volatile`** ，这就指示 JVM，这个变量是共享且不稳定的，每次使用它都到主存中进行读取

 **除了防止 JVM 的指令重排 ，还有一个重要的作用就是保证变量的可见性**

> ThreadLocal 

通常情况下，我们创建的变量是可以被任何一个线程访问并修改的。**如果想实现每一个线程都有自己的专属本地变量该如何解决呢？** JDK 中提供的`ThreadLocal`类正是为了解决这样的问题。 **`ThreadLocal`类主要解决的就是让每个线程绑定自己的值，可以将`ThreadLocal`类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。**

**如果你创建了一个`ThreadLocal`变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是`ThreadLocal`变量名的由来。他们可以使用 `get（）` 和 `set（）` 方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。

> `ThreadPoolExecutor`

- **`corePoolSize` :** 核心线程数定义了最小可以同时运行的线程数量。
- **`maximumPoolSize` :** 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。
- **`workQueue`:** 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。

`ThreadPoolExecutor`其他常见参数:

1. **`keepAliveTime`**:当线程池中的线程数量大于 `corePoolSize` 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 `keepAliveTime`才会被回收销毁；
2. **`unit`** : `keepAliveTime` 参数的时间单位。
3. **`threadFactory`** :executor 创建新线程的时候会用到。
4. **`handler`** :饱和策略

> Java多线程的实现方式：

- 继承Thread类创建线程（重写run方法，用start ()开启线程）
- 实现Runable接口创建线程（重写run方法，也是start来开启线程）
- 使用Callable和Future创建线程（用 Lambda 表达式创建Callable<Integer>对象，用Future来包装该对象，可以有返回值）
- 使用线程池（Executore框架）

> execute()方法和 submit()方法的区别是什么呢？

1. **`execute()`方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否；**
2. **`submit()`方法用于提交需要返回值的任务。线程池会返回一个 `Future` 类型的对象，通过这个 `Future` 对象可以判断任务是否执行成功**，并且可以通过 `Future` 的 `get()`方法来获取返回值，`get()`方法会阻塞当前线程直到任务完成，而使用 `get(long timeout，TimeUnit unit)`方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。

## 90、说一下mybatics

> MyBatis是什么？

- Mybatis是一个半ORM（对象关系映射）框架，它内部封装了JDBC，加载驱动、创建连接、创建statement等繁杂的过程，开发者开发时只需要关注如何编写SQL语句，可以严格控制sql执行性能，灵活度高。
- 作为一个半ORM框架，MyBatis 可以使用 XML 或注解来配置和映射原生信息，将 POJO映射成数据库中的记录，避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。
- 通过xml 文件或注解的方式将要执行的各种 statement 配置起来，并通过java对象和 statement中sql的动态参数进行映射生成最终执行的sql语句，最后由mybatis框架执行sql并将结果映射为java对象并返回。（从执行sql到返回result的过程）。

> #{}和${}的区别？

- \#{}是占位符，预编译处理；${}是拼接符，字符串替换，没有预编译处理。
- Mybatis在处理#{}时，#{}传入参数是以字符串传入，会将SQL中的#{}替换为?号，调用PreparedStatement的set方法来赋值。
- Mybatis在处理时 ， 是 原 值 传 入 ， 就 是 把 {}时，是原值传入，就是把时，是原值传入，就是把{}替换成变量的值，相当于JDBC中的Statement编译
- 变量替换后，#{} 对应的变量自动加上单引号 ‘’；变量替换后，${} 对应的变量不会加上单引号 ‘’
- \#{} 可以有效的防止SQL注入，提高系统安全性；${} 不能防止SQL 注入
- \#{} 的变量替换是在DBMS 中；${} 的变量替换是在 DBMS 外

> Dao接口的工作原理

Dao接口即Mapper接口。

接口的全限名就是映射文件中的namespace的值；

接口的方法名，就是映射文件中Mapper的Statement的id值；

接口方法内的参数，就是传递给sql的参数。

Mapper接口是没有实现类的，当调用接口方法时，接口全限名+方法名的拼接字符串作为key值，可唯一定位一个MapperStatement。

Dao接口里的方法，是不能重载的，因为是全限名+方法名的保存和寻找策略。



Dao接口的工作原理是JDK动态代理，Mybatis运行时会使用JDK动态代理为Dao接口生成代理proxy对象，代理对象proxy会拦截接口方法，转而执行MappedStatement所代表的sql，然后将sql执行结果返回。

> 在Mapper中如何传递多个参数？

+ 若Dao层函数有多个参数，那么其对应的xml中，#{0}代表接收的是Dao层中的第一个参数，#{1}代表Dao中的第二个参数，以此类推。
+ 使用@Param注解：在Dao层的参数中前加@Param注解,注解内的参数名为传递到Mapper中的参数名。
+ 多个参数封装成Map，以HashMap的形式传递到Mapper中。

> 动态sql

Mybatis动态sql可以在xml映射文件内，以标签的形式编写动态sql，执行原理是根据表达式的值完成逻辑判断，并动态拼接sql的功能。

Mybatis提供了9种动态sql标签：trim、where、set、foreach、if、choose、when、otherwise、bind

> Mybatis的一级、二级缓存

+ 一级缓存：基于PerpetualCache的HashMap本地缓存，其存储作用域为Session，当Session flush或close之后，该Session中的所有Cache就将清空，默认打开一级缓存。
+ 二级缓存与一级缓存机制相同，默认也是采用PerpetualCache，HashMap存储，不同在于其存储作用域为Mapper（namespace），并且可自定义存储源，如Ehcache。默认打不开二级缓存，要开启二级缓存，使用二级缓存属性类需要实现Serializable序列化接口（可用来保存对象的状态），可在它的映射文件中配置。

+ 对于缓存数据更新机制，当某一个作用域（一级缓存Session/二级缓存Namespace）进行了增/删/改操作后，默认该作用域下所有select中的缓存将被clear。

> 使用MyBatis的Mapper接口调用时有哪些要求？

+ Mapper接口方法名和mapper.xml中定义的每个sql的id相同； 
+ Mapper接口方法的输入参数类型和mapper.xml中定义的每个sql的parameterType类型相同； 
+ Mapper接口方法的输出参数类型和mapper.xml中定义的每个sql的resultType的类型相同； 
+ Mapper.xml文件中的namespace即是mapper接口的类路径。



## 91、

## 92、

## 93、

## 94、

## 95、

## 96、

## 97、

## 98、

## 99、

## 100、