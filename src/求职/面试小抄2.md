### 1、Java8新特性

Java8新特性包括**Lambda表达式、Stream API、接口默认方法**等

Java11新特性包括**ZGC、Epsilon GC、HTTP Client API**等²

Java17新特性包括**Sealed Class**。

### 2、Java内存模型

Java内存模型（Java Memory Model，JMM）是一种**虚拟机规范**，用于**屏蔽掉各种硬件和操作系统的内存访问差异**，以实现让**Java程序在各种平台下都能达到一致的并发效果**。Java内存模型是通过**在变量修改后将新值同步回主内存**，**在变量读取前从主内存刷新变量值**的这种依赖主内存作为传递媒介的方式来实现的。Java 内存模型还规定了在执行八种基本操作时，必须满足如下规则：**不允许 read 和 load、store 和write 操作之一单独出现**；**不允许一个线程丢弃它的最近 assign 的操作，即变量在工作内存中改变了之后必须同步到主内存中**；**不允许一个线程无原因地（没有发生过任何相关的同步操作）看到另一个线程的操作结果**；**如果一个变量被 volatile 修饰，则对它的写操作就会立即刷新到主内存中，而读操作就会从主内存中读取最新值**。

### 3、**TCP 和 UDP 区别：**

*1. **连接***

- TCP 是面向连接的传输层协议，传输数据前先要建立连接。
- UDP 是不需要连接，即刻传输数据。

*2. 服务对象*

- TCP 是一对一的**两点服务**，即一条连接只有两个端点。
- UDP 支持**一对一、一对多、多对多**的交互通信

*3. 可靠性*

- TCP 是**可靠交付数据**的，数据可以无差错、不丢失、不重复、按序到达。
- UDP 是尽最大努力交付，不保证可靠交付数据。

*4. 拥塞控制、流量控制*

- TCP 有**拥塞控制和流量控制**机制，保证数据传输的安全性。
- UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。

*5. 首部开销*

- **TCP 首部长度较长**，会有一定的开销，首部在没有使用「选项」字段时是 `20` 个字节，如果使用了「选项」字段则会变长的。
- UDP 首部只有 8 个字节，并且是固定不变的，开销较小。

*6. 传输方式*

- TCP 是**流式传输**，没有边界，但保证顺序和可靠。
- UDP 是**一个包一个包的发送**，是有边界的，但可能会丢包和乱序。

*7. 分片不同*

- TCP 的数据大小如果大于 **MSS** 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。
- UDP 的数据大小如果大于 MTU 大小，则会**在 IP 层进行分片**，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。

### 3、TCP 和 UDP 应用场景

由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：

- `FTP` **文件传输**；
- **HTTP / HTTPS**；

由于 UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此经常用于：

- 包总量较少的通信，如 **`DNS` 、`SNMP`** 等；
- **视频、音频**等多媒体通信；
- **广播**通信；

### 4、kafka重复消费和消息丢失

**重复消费**

消费后的数据，offset没有提交（消费系统宕机、重启、自动提交）



**消息丢失**

producer发送消息后，由于网络等原因，没有到kafka;

Kafka为了提高吞吐量和性能，采用**异步批量的刷盘**策略，如果系统挂掉，数据就会丢失。

消费者先提交offset，再消费。



**解决办法**

重复消费：offset机制，保证幂等性

消息丢失：ACK确认机制；同步刷盘；先消费后提交；

### 5、数据库三范式

第一范式每一**列都是不可分割**的原子项。

第二范式，**非主键属性必须依赖于主键**属性。

第三范式，**非主键属性必须直接依赖于主键**，而不能间接依赖于主键。

### 6、mysql存储过程

MySQL存储过程是一种**在数据库中存储复杂程序，以便外部程序调用**的一种数据库对象。存储过程是为了**完成特定功能的SQL语句集**，经编译创建并保存在数据库中，用户可通过指定存储过程的名字并给定参数 (需要时)来调用执行。

### 7、mysql优缺点

- 优点：
    - **体积小、速度快、总体拥有成本低，开源，提供的接口支持多种语言连接操作**。
    - MySQL 的核心程序采用完全的**多线程编程**。
- 缺点：
    - 不支持**热备份**。
    - 不支持**自定义数据类型**。
    - MySQL最大的缺点是其**安全系统，主要是复杂**而非标准，另外只有到调用mysqladmin来重读用户权限时才发生改变。

### 8、进程和线程的区别

进程是操作系统**资源分配**的基本单位，而线程是**任务调度和执行**的基本单位。

线程是进程内的一个执行单元，进程内至少有一个线程，它们**共享进程的地址空间**，而进程有自己**独立的地址空间**。

同一个进程内的线程**共享进程的资源**，如内存、I/O等。

### 9、synchronized和 ReentrantLock区别

1. 用法不同：synchronized可以用来修饰普通方法、静态方法和代码块，而ReentrantLock**只能用于代码块**。
2. 获取锁和释放锁的机制不同：synchronized是**自动加锁和释放锁**，而ReentrantLock则需要手动获取和释放锁。
3. ReentrantLock可以实现**公平锁**，而synchronized只能是非公平锁。

### 10、堆和栈的区别

线程是否共享

存储的对象是什么

是否有垃圾回收机制

### 11、spring是什么

企业级应用程序开发框架，简化企业级应用程序开发。

+ 实现了IOC容器，对Java对象进行管理，降低对象替换的复杂性。
+ 使用AOP增强，实现事务，日志，异常的统一配置和管理。
+ 方便集成其它的优秀框架，例如mybatics
+ 降低JavaEEAPI的使用难度，例如JDBC，远程调用
+ 方便测试程序，支持Junit

### 12、spring主要模块

+ 核心容器：提供控制反转和依赖注入，管理been对象。
+ web：提供了web程序的开发功能，例如MVC框架。
+ 数据访问：提供了对数据库的操作等，例如JDBC，对象关系映射。
+ 测试：提供单元测试和集成测试
+ AOP：提供面向切面编程的实现，将代码按照功能进行分类

### 13、IOC

将对象的创建和依赖的管理从程序代码移动到外部容器。

### 14、AOP

在不修改原有代码的情况下动态增强某个类或方法的职责。

### 15、序列化和反序列化

序列化是指**将对象转换为字节序列**，而反序列化则是**将字节序列转换成目标对象**。

序列化最重要的作用是在**传递和保存对象**时保证对象的完整性和可传递性。

Java实现序列化有两种方式： 实现 **Serializable 接口** 和 实现 Externalizable 接口。

### 16、JVM内存分配方式

**指针碰撞**是指当堆中的**内存比较整齐**，即用过的内存和空闲内存有一条清晰的分界线（分界线处有个指针作为分界点指示器）时，可以使用这种方法。

**空闲列表**是指当堆中的**内存比较零散**，即用过的内存和空闲内存没有一条清晰的分界线时，可以使用这种方法。

### 17、操作系统如何管理文件和磁盘

操作系统管理磁盘的方式有很多，其中最常见的是文件系统。

文件系统是一种操作系统用来**管理和组织计算机上文件和目录**的方法。

创建一个新的文件或文件夹时，操作系统会将其存储在磁盘上，并将其添加到文件系统中。

需要访问这些文件时，操作系统会查找它们的位置并将它们加载到内存中

### 18、tcp可以看见https加密前的明文吗

不能，tls加密数据后才将加密数据交付给传输层传输，tcp看不到加密前的报文

### 19、servlet重要方法

1. **init()**方法：当Servlet被实例化时，容器会调用init()方法来初始化Servlet。在这个方法中，你可以执行一些初始化操作，例如读取配置文件、建立数据库连接等。
2. **service()**方法：当客户端发送请求时，容器会调用service()方法来处理请求。在这个方法中，你可以获取请求参数、执行业务逻辑等。
3. **destroy()**方法：当Servlet被销毁时，容器会调用destroy()方法来释放资源。在这个方法中，你可以关闭数据库连接、释放内存等。

### 20、InnoDB和MyISAM区别

1. InnoDB支持**事务**，而MyISAM不支持事务。

2. InnoDB支持**行级锁**，而MyISAM只支持表级锁。

3. InnoDB支持**外键约束**，而MyISAM不支持外键约束。

4. InnoDB支持**MVCC**（多版本并发控制），而MyISAM不支持MVCC。

5. InnoDB的数据**存储方式**是聚集索引，而MyISAM的数据存储方式是堆表。

### 21、什么是存储引擎

存储引擎是数据库管理系统中**负责数据存储和检索**的模块。它们负责将数据存储在磁盘上，并**提供一些API**来让用户对数据进行操作。

### 22、mysql语句执行过程

客户端通过连接器**建立连接**，这个操作进行**权限验证**，通过之后会先前往**缓存**，根据sql作为key去查询，查到直接返回，否者前往分析器，经过分析器对sql**语句的分析**、解析，得到一个mysql可以理解的**语法**，随后进入优化器，mysql会根据你查询的条件进行**适当的优化**，之后在经过**执行器**，这就真正的开始**前往存储引擎查询数据**，最后将查询到的数据**返回给客户端**，顺便写入缓存（不一定）

### 23、堆排序是怎么实现的

 **堆的性质**

+ 完全二叉树
+ 每个节点的值都大于或等于其子节点的值

 **基本思想**

+ 自底向上将待排序的序列**构造成一个最大堆**，此时序列的最大值为根节点
+ 每次从堆顶选择一个最值，放到堆的最下边，然后重新调整堆的结构，已经选出来的值不参与堆调整。一直重复直到最大堆只剩下一个元素，就完成了堆排序，本质上还是一个选择排序

### 24、事务隔离级别

+ 多事务并发执行时，会产生一些问题，根据不同的场景可能需要不同的解决策略，来隔离多个事务的执行
+ 有些事务要求的隔离性比较强，有些事务对隔离性的要求没有那么强，因此根据隔离事务的强弱制定了一些不同的隔离策略，这就是隔离级别
+ 读未提交、读提交 、可重复读、串行化
+ 讲含义，讲实现

### 25、BST树

> **介绍**

是一颗结点有序的二叉树，左子树的所有结点值都小于当前结点，右子树的所有结点值都大于当前结点，**平均查找效率是O(lgn)，但是在极端情况下会退化为链表。**

> **实现**

**数据结构：**

+ 结点的数据结构包含存储内容以及左右子节点。

**插入：**

+ 在插入结点时先进行二分检索，找到插入位置，插入即可。

**删除：**

+ 在删除结点时需要先找到一个**替代结点**，替代待删除结点，再递归的删除那个替代结点，替代结点会出现在左子树的最右边或者右子树的最左边，都在叶子结点，删除之后不会影响查找树的性质。

### 26、AVL树

> **介绍**

是一颗高度平衡的二叉查找树，**左右子树的高度差值**不超过1，可以保证**查找效率最坏也能达到O(lgn)**，但是高度平衡要求比较严格，需要**频繁的通过旋转来保持树的平衡**。

> **实现**

**数据结构**

+ 结点的数据结构中包含左右结点指针，存储的内容，以及**以当前结点为根的子树高度**。

**插入**：

+ 先按照二叉搜索树的插入方式递归的进行插入
+ 然后检测高度是否平衡，如果高度不再平衡，**通过旋转的方式调整**
  + 更新结点的高度

**删除**：

+ 先按照二叉搜索树的方式递归的进行删除
+ 删除后检测左右子树高度以及子树的左右子树高度确认不平衡的原因
+ 根据原因进行不同的旋转操作即可



**左旋**：

+ 旋转点下沉为左子结点，它的右子节点上升父节点，再交换彼此的子树。逆时针旋转

**右旋**：

+ 旋转点下沉为右子节点，它的左子节点上升为父节点，再交换彼此的子树。顺时针旋转

**旋转场景**：

+ LL：导致不平衡的结点在左结点的左结点后边：右旋
+ RR：导致不平衡的结点在右结点的右结点后边：左旋
+ LR：导致不平衡的结点在左结点的右结点后边：先对左节点左旋变成LL
+ RL：导致不平衡的结点在右结点的左结点后边：先对右节点右旋变成RR



### 26、B树

**介绍**

**实现**

### 26、红黑树

> **介绍**

红黑树**基于2-3树或者2-3-4实现的高度平衡的二叉查找树**，具有查找树的性质，也具有平衡树的性质，**查找、插入和删除在最坏情况下都能达到O(lgn)效率**。

在基于**2-3树的实现**里，不会出现4结点，也就是**黑结点不会有两个红子节点**，红节点只能作为左子结点，在这个限制下插入和删除的平衡调整会简单很多。

在基于**2-3-4树的实现**里，会出现**黑节点有两个红子结点**的情况，在插入和删除时需要考虑更加复杂的情况。

红黑树的高度是平衡的，因为**红节点的出现**是为了模拟2-3树中的3节点，3结点不会增加2-3树的高度，所以红黑树的**高度近似取决于黑节点**，而红黑树每一条**路径的黑色结点数量**都相等，所以红黑树是一个**黑色平衡**的树，左右子树高度差最大只能只能是比较矮的子树的高度。

红黑树结点不是黑色就是红色，**根节点是黑色，叶结点是黑色**的空结点，**红色结点不会连续出现**，任意**路径包含相同数量黑色结点**。

> **实现**

**数据结构**

+ 

**插入**：

+ 插入结点设置为红色的，因为红色结点的插入不会破坏黑平衡。

+ 先用二分检索找到插入位置，根据插入位置父亲和兄弟的颜色情况进行不同的调整。

+ 如果父亲是黑的，直接插入，如果形成了4结点，就将子节点分裂为黑节点，父节点变成红结点上升到上一层。

+ 如果父亲是红的，那就会出现两个连续红结点，如果是右倾，先进行一次左旋变成左倾连续红结点，如果是左倾，那就是连续左倾红结点，接下来对黑色父结点进行一次右旋，此时黑色平衡被破坏了，需要交换一下颜色变成4结点，保持黑色平衡，再对这个4结点进行分裂和上升结合即可。

**删除**：

+ 首先对结点进行搜索，同时进行非2结点化，将路径上的结点全部变成3结点或者临时4结点。
  + 根节点直接合并两个子节点，变成4结点；
  + 除了根节点以外，父亲都会是一个非2结点；
  + 如果兄弟是2结点，就把父亲下沉，合并两个子节点，变成4结点；
  + 如果兄弟是非2结点，就把父亲下沉，与当前结点变成一个3结点； 
+ 找到待删除结点后直接删除红节点即可，不会破坏黑色平衡



### 27、锁升级

在Java中，锁的升级是由虚拟机自动完成的，具体的过程如下：

1. 偏向锁： 当一个线程第一次访问一个没有锁定的对象时，JVM会将该对象的对象头设置为偏向锁，并且将线程id记录到对象头中。之后，该线程每次访问该对象时，都不需要进行同步操作，因为它已经拥有了偏向锁。
2. 轻量级锁： 当另一个线程尝试获取一个拥有偏向锁的对象时，JVM会将其升级为轻量级锁。轻量级锁是通过CAS（Compare And Swap）实现的，即线程尝试使用CAS操作把对象头中的线程ID替换成自己的ID，如果成功则获得锁，失败则表示有竞争，此时锁就会退化为重量级锁。
3. 重量级锁： 当一个线程获取锁失败时，就会进入到阻塞状态，此时锁就被升级为重量级锁。重量级锁是通过操作系统的互斥量实现的，即在内核态进行同步操作。重量级锁会导致线程的上下文切换，降低了程序的执行效率，因此尽量避免长时间持有重量级锁。



### 28、怎么维护线程安全

1. 使用锁机制： 通过在关键代码段或者资源上设置锁，保证同一时间只有一个线程可以访问它，其他线程必须等待锁的释放。Java提供了多种锁的实现方式，例如synchronized关键字、ReentrantLock类、ReadWriteLock类等。
2. 使用原子变量： 原子变量可以保证对共享变量的操作是原子性的，在同一时间只能有一个线程对它进行修改，从而保证线程安全。Java提供了多种原子变量的实现方式，例如AtomicInteger、AtomicLong、AtomicReference等。
3. 使用线程安全的集合类： Java中提供了多种线程安全的集合类，例如ConcurrentHashMap、CopyOnWriteArrayList、ConcurrentLinkedQueue等，这些集合类都是线程安全的，可以在多线程环境下安全地对其中的数据进行操作。
4. 使用可变对象的不可变副本： 如果需要在多线程环境下共享数据，为了避免数据被篡改，可以使用可变对象的不可变副本来保证线程安全。例如，可以将ArrayList封装为一个不可变的List，通过Collections.unmodifiableList()方法创建一个只读的List，从而避免多个线程同时修改数据。



### 29、什么是数字签名

验证数据完整性和身份认证

1. 密钥对生成：首先，需要生成一对密钥，包括私钥和公钥。私钥由签名者自己保留，用于生成数字签名；公钥公开给其他人用于验证签名。
2. 数据哈希：将待签名的数据使用哈希函数生成一个固定长度的摘要。哈希函数是将任意长度的数据映射为固定长度输出的算法，具有唯一性和不可逆性。
3. 数字签名生成：使用私钥对数据的哈希值进行加密，生成数字签名。加密过程使用的是非对称加密算法，如RSA或DSA。私钥只有签名者本人拥有，因此只有签名者才能生成正确的数字签名。
4. 数字签名验证：接收到带数字签名的数据后，接收方可以使用签名者的公钥对数字签名进行解密，得到数据的哈希值。然后，接收方自行对接收到的原始数据进行哈希运算，得到另一个哈希值。最后，接收方将解密得到的哈希值与自行计算的哈希值进行比较。如果两个哈希值完全一致，则说明数据未被篡改，数字签名有效。



### 30、Java中怎么加锁

除了 `synchronized` 关键字之外，Java 中还提供了其他几种方式来实现锁机制。下面简要介绍一些常见的锁实现：

1. ReentrantLock： `ReentrantLock` 是 `java.util.concurrent` 包中提供的可重入锁实现。与 `synchronized` 不同，`ReentrantLock` 提供了更多的灵活性和功能，例如可定时、可中断、公平/非公平等。使用 `ReentrantLock` 需要手动获取锁和释放锁。

   ```
   javaCopy Codeimport java.util.concurrent.locks.ReentrantLock;
   
   ReentrantLock lock = new ReentrantLock();
   
   public void myMethod() {
       lock.lock(); // 获取锁
       try {
           // 被锁定的代码块
       } finally {
           lock.unlock(); // 释放锁
       }
   }
   ```

2. ReadWriteLock： `ReadWriteLock` 是一个读写锁接口，它通过分离读操作和写操作，可以提高并发性能。`java.util.concurrent` 包中提供了 `ReentrantReadWriteLock` 类作为 `ReadWriteLock` 接口的实现。

   ```
   javaCopy Codeimport java.util.concurrent.locks.ReadWriteLock;
   import java.util.concurrent.locks.ReentrantReadWriteLock;
   
   ReadWriteLock rwLock = new ReentrantReadWriteLock();
   
   public void readData() {
       rwLock.readLock().lock(); // 获取读锁
       try {
           // 读取数据的代码
       } finally {
           rwLock.readLock().unlock(); // 释放读锁
       }
   }
   
   public void writeData() {
       rwLock.writeLock().lock(); // 获取写锁
       try {
           // 写入数据的代码
       } finally {
           rwLock.writeLock().unlock(); // 释放写锁
       }
   }
   ```

3. StampedLock： `StampedLock` 提供了一种乐观读的机制，在读操作不频繁、写操作较多的场景下，可以提高性能。`StampedLock` 也是 `java.util.concurrent` 包中的类。

   ```
   javaCopy Codeimport java.util.concurrent.locks.StampedLock;
   
   StampedLock stampedLock = new StampedLock();
   
   public void readData() {
       long stamp = stampedLock.tryOptimisticRead(); // 尝试乐观读
       // 读取数据的代码
   
       if (!stampedLock.validate(stamp)) { // 验证乐观读是否有效
           stamp = stampedLock.readLock(); // 若无效则获取读锁
           try {
               // 重新读取数据的代码
           } finally {
               stampedLock.unlockRead(stamp); // 释放读锁
           }
       }
   }
   
   public void writeData() {
       long stamp = stampedLock.writeLock(); // 获取写锁
       try {
           // 写入数据的代码
       } finally {
           stampedLock.unlockWrite(stamp); // 释放写锁
       }
   }
   ```



### 31、Java中怎么保证线程安全

要保证线程安全，可以采取以下几种方法：

1. 使用同步机制： 使用 `synchronized` 关键字或 `ReentrantLock` 类来实现加锁机制，确保在同一时间只有一个线程能够访问共享资源。这样可以避免多个线程同时修改数据导致的竞态条件和数据不一致。
2. 使用原子类： Java 提供了一些原子类，如 `AtomicInteger`、`AtomicLong` 等，它们使用了底层的 CAS（Compare-and-Swap）操作，可以实现线程安全的原子操作。
3. 使用线程安全的集合： Java 提供了线程安全的集合类，如 `ConcurrentHashMap`、`CopyOnWriteArrayList` 等，它们内部采用了加锁或其他并发控制机制，可以安全地在多线程环境下使用。
4. 使用 volatile 关键字： `volatile` 关键字可以确保变量的可见性和禁止指令重排序，但它不能保证复合操作的原子性。适合用于标识状态、控制开关等简单场景。
5. 使用线程安全的设计模式： 某些设计模式可以帮助保证线程安全，如单例模式中的双重检查锁定（Double-Checked Locking）、不可变对象（Immutable Object）等。这些模式在设计时就考虑了多线程环境下的安全性。
6. 避免共享可变状态： 尽量避免多个线程之间共享可变状态，通过将状态封装在对象内部，每个线程操作自己的对象实例，可以减少并发访问冲突。
7. 合理使用线程同步工具： Java 提供了一些线程同步工具，如 `CountDownLatch`、`CyclicBarrier`、`Semaphore` 等，它们可以用于协调多个线程的执行顺序和并发控制。



### 32、Java中的线程安全问题

在多线程环境下使用非线程安全的 ArrayList 可能会导致以下不安全的情况：

1. 数据不一致性：由于 ArrayList 不是线程安全的，当多个线程同时修改同一个 ArrayList 实例时，可能会导致数据不一致。例如，一个线程正在向 ArrayList 中添加元素，而另一个线程正在删除元素，这可能导致某些元素被意外删除或顺序混乱。
2. 并发修改异常：当一个线程正在修改 ArrayList 的同时，另一个线程正在对该列表进行迭代或读取操作，可能会导致 `ConcurrentModificationException` 异常被抛出。这是因为 ArrayList 在迭代期间检测到其他线程对其进行了修改。
3. 丢失更新：如果多个线程同时对同一个索引位置的元素进行修改，由于没有同步机制保护，可能会导致某些修改被覆盖，从而造成数据丢失或错误的更新结果。
4. 不确定的大小：当多个线程同时修改 ArrayList 的大小（添加或删除元素）时，由于没有同步机制，可能会导致不确定的列表大小或数组越界异常。



> HashMap的线程安全问题

**多线程下扩容死循环**

JDK1.7中的 HashMap 使用头插法插入元素，在多线程的环境下，扩容的时候有可能导致环形链表的出现，形成死循环

**多线程的put可能导致元素的丢失**

多线程同时执行 put 操作，如果计算出来的索引位置是相同的，那会造成前一个 key 被后一个 key 覆盖，从而导致元素的丢失。

**put和get并发时，可能导致get为null	**

线程1执行put时，因为元素个数超出threshold而导致rehash，线程2此时执行get，有可能导致这个问题。	



### 33、hashMap如何转红黑树

链表转换为红黑树的过程如下：

1. 当链表长度达到阈值时，HashMap会判断当前HashMap的容量是否达到了一个临界值（默认为64）。如果容量未达到临界值，则会先进行扩容操作。
2. 在扩容完成后，HashMap会遍历链表中的元素，并将这些元素重新分配到新的数组位置上。这个过程涉及到重新计算元素在新数组中的索引位置。
3. 如果链表长度仍然超过一定阈值（默认为8），则会将链表转换为红黑树。HashMap会调用`treeifyBin`方法进行转换。
4. `treeifyBin`方法会使用链表中的元素构建一个红黑树，然后将该红黑树设置为原先链表对应的数组位置上的元素。
5. 转换完成后，之前的链表结构就被替换为了红黑树结构，可以通过红黑树的特性来提高查找、插入和删除操作的效率。

需要注意的是，在HashMap中，当红黑树的节点个数少于一定的阈值（默认为6），又会将红黑树转换回链表结构，以保持内存的使用效率。



`treeifyBin`方法是用于将链表转换为红黑树的关键方法。下面是`treeifyBin`方法大致的处理流程：

1. 首先，`treeifyBin`方法会创建一个新的TreeNode数组，用于存储红黑树的节点。
2. 然后，方法会遍历原链表中的元素，逐个将元素从链表中取出，并构建一个红黑树节点。每个节点会记录元素的key、value以及哈希值。
3. 在构建红黑树节点的过程中，会根据元素的哈希值和树的大小进行插入操作。具体来说，方法会调用红黑树的插入方法，如`putTreeVal`。
4. `putTreeVal`方法会根据元素的哈希值和已有的红黑树节点进行比较，找到合适的位置插入新的节点。同时，在插入节点后，会进行红黑树平衡操作，以满足红黑树的性质。
5. 当所有元素都插入红黑树后，就完成了链表到红黑树的转换。新的红黑树会替换原先链表对应的数组位置上的元素。



### 34、sql优化

优化：select * from t where t.a > ? and t.b = ? or t.c = ? order by t.d desc limit 10;



对于该查询语句，可以考虑以下优化：

1. 索引优化：根据查询条件中涉及的列（t.a、t.b、t.c和t.d），创建合适的索引。例如，为t.a、t.b、t.c和t.d各自创建单列索引，可以加快查询的速度。
2. 查询条件重排：将具有相等性比较的条件（t.b = ? 和 t.c = ?）放在前面，并将范围比较的条件（t.a > ?）放在后面。这样可以避免不必要的范围扫描，提高查询的效率。
3. 限制结果集大小：在使用LIMIT子句时，可以限制结果集的大小。对于该查询语句，通过添加LIMIT 10来指定只返回前10条结果，避免不必要的数据传输和处理。
4. 避免使用SELECT *：只选择需要的列，而不是使用SELECT *。这样可以减少数据传输和处理的开销，并降低查询的延迟。



### 35、sql写一个死锁

首先，创建一个示例表 `orders`：

```sql
CREATE TABLE orders (
   order_id INT PRIMARY KEY,
   product_id INT,
   quantity INT
);
```

然后，在两个不同的会话中，分别执行以下 SQL 语句：

**会话1：**

```sql
-- 会话1
START TRANSACTION;
SELECT * FROM orders WHERE order_id = 1 FOR UPDATE;
SELECT SLEEP(10);

UPDATE orders SET quantity = quantity - 1 WHERE order_id = 2;
COMMIT;
```

**会话2：**

```sql
-- 会话2
START TRANSACTION;
SELECT * FROM orders WHERE order_id = 2 FOR UPDATE;

SELECT SLEEP(10);

UPDATE orders SET quantity = quantity + 1 WHERE order_id = 1;
COMMIT;
```

在上述情况中，会话1先获取 `order_id=1` 的行的排他锁，然后等待一段时间。同时，会话2也开始执行并获取了 `order_id=2` 的行的排他锁。

当会话1尝试更新 `order_id=2` 的行时，由于该行已经被会话2持有的锁保护，所以会话1需要等待会话2释放该锁。而会话2同样尝试更新 `order_id=1` 的行，却发现该行已经被会话1持有的锁保护，需要等待会话1释放锁。





### 36、有一个功能，按照文章的热度排序，文章量特别大，怎么做？

分布式存储计算：对数据做排序，可以通过分布式存储热度数据以及文章id，多台机器存储文章数据分片，每台机器负责排序，然后使用分布式排序算法合并排序结果；

预读机制：定时更新热度排行数据到缓存，请求直接访问缓存获取排序后的结果

设置索引和覆盖索引：对排序字段建立索引，查询字段为主键，对排序后结果进行limit限制，得到热度前xx条数据后从缓存读取完整数据。



### 37、Kafka怎么写磁盘

顺序写：日志文件末尾追加

页缓存：先写到操作系统的缓存也，之后在根据策略进行刷盘

零拷贝优化IO：数据发送到网络传输使用零拷贝技术，不再发生内核态和用户态的切换



### 38、redis实现分布式锁

不同的系统或同一个系统的不同主机之间共享了某个临界资源，往往需要互斥来防止彼此干扰，以保证一致性



> SETNX 是SET IF NOT EXISTS的简写.日常命令格式是SETNX key value，如果 key不存在，则SETNX成功返回1，如果这个key已经存在了，则返回0

**单机**：

+ 方案一：SETNX + EXPIRE

  **不是原子操作**，过期时间设置失败

  **锁过期释放了，业务还没执行完**

  **锁被别的线程误删**

+ 方案二：ETNX + value值是(系统时间+过期时间)

  客户端的时间必须同步

  **锁过期释放了，业务还没执行完**

  **锁被别的线程误删**

+ 方案三：Lua脚本(包含SETNX + EXPIRE两条指令)

  **锁过期释放了，业务还没执行完**

  **锁被别的线程误删**

+ 方案思：SET的扩展命令（SET EX PX NX）

  **锁过期释放了，业务还没执行完**

  **锁被别的线程误删**

锁的误删问题解决：

+ 给value值设置一个标记当前线程唯一的随机

锁过期太早的解决：

+ 后台线程，会每隔10秒检查一下，如果线程1还持有锁，那么就会不断的延长锁key的生存时间

**集群**：

+ 主从同步架构：主节点宕机，多个线程获取到锁
+ Redlock算法：多个Redis master部署，以保证它们不会同时宕掉。并且这些master节点是完全相互独立的，相互之间不存在数据同步。同时，需要确保在这多个master实例上，是与在Redis单实例，使用相同方法来获取和释放锁。
  - 按顺序向5个master节点请求加锁
  - 根据设置的超时时间来判断，是不是要跳过该master节点。
  - 如果大于等于三个节点加锁成功，并且使用的时间小于锁的有效期，即可认定加锁成功啦。
  - 如果获取锁失败，解锁！



### 39、ES存储原理

一份数据写入Elasticsearch 会产生多份数据用于不同查询方式，会比原数据占用更多磁盘空间。

对照上面的lucene文件表，进行简要归纳：

- 存储原文_source的文件.fdt .fdm .fdx;
- 存储倒排索引的文件.tim .tip .doc;
- 用于聚合排序的列存文件.dvd .dvm;
- 全文检索文件.pos .pay .nvd .nvm等;
- 加载到内存中的文件有.fdx .tip .dvm;

其中.tip占用内存最大，而.fdt、.tim、.dvd文件占用磁盘最大。



Elasticsearch对外提供的是index的概念，可以类比为MySQL DB，用户查询是在index上完成的，每个index由若干个shard组成，以此来达到分布式可扩展的能力



**lucene基本概念**

- segment : lucene内部的数据是由一个个segment组成的，写入lucene的数据并不直接落盘，而是先写在内存中，经过了refresh间隔，lucene才将该时间段写入的全部数据refresh成一个segment，segment多了之后会进行merge成更大的segment。lucene查询时会遍历每个segment完成。由于lucene 写入的数据是在内存中完成，所以写入效率非常高。但是也存在丢失数据的风险，所以Elasticsearch基于此现象实现了translog，只有在segment数据落盘后，Elasticsearch才会删除对应的translog。
- doc : doc表示lucene中的一条记录。
- field ：field表示记录中的字段概念，一个doc由若干个field组成。
- term ：term是lucene中索引的最小单位，某个field对应的内容如果是全文检索类型，会将内容进行分词，分词的结果就是由term组成的。如果是不分词的字段，那么该字段的内容就是一个term。
- 倒排索引(inverted index): lucene索引的通用叫法，即实现了term到doc list的映射



 

### 40、ES插入一条数据

当底层 Elasticsearch 插入一条数据时，以下是更详细的步骤：

1. 接收请求：客户端向 Elasticsearch 发送一个插入数据的请求。
2. 路由至主分片：Elasticsearch 首先确定该数据应该路由到哪个索引的主分片中。每个索引可以配置为拥有多个主分片，数据在插入时会被均匀地分布到这些主分片上。
3. 确定路由：根据配置和哈希算法，Elasticsearch 决定将数据路由到哪个主分片。路由策略可以基于数据的某个字段值或者自定义的路由逻辑。
4. 刷新写入缓冲区：数据首先会被写入主分片的写入缓冲区中，以提高写入性能。在缓冲区中，数据被暂存并排序以进行效率优化。
5. 文档ID生成：如果没有指定文档的ID，Elasticsearch 会自动生成一个唯一的文档ID。否则，使用指定的文档ID。
6. 文档序列化：数据以 JSON 格式进行序列化，以便在磁盘上存储和索引。
7. 索引写入：数据被写入到主分片的倒排索引中。倒排索引是一种将文档中的术语映射到文档的位置的数据结构，它支持快速的全文搜索。
8. 刷新到磁盘：在后台，Elasticsearch 定期刷新写入缓冲区的数据到磁盘上的段文件。刷新是一个轻量级的操作，它将数据从内存刷入磁盘，以确保数据的持久性。
9. 返回响应：一旦数据成功写入到索引中，Elasticsearch 返回一个响应给客户端，指示插入操作的结果，通常是包含文档ID的成功响应。



### 41、term和match的区别

在Elasticsearch中，"term"和"match"是两种不同的查询方式，用于不同的搜索需求。

1. Term 查询： Term 查询是一种精确匹配的查询，它在搜索时不会对关键词进行分词处理。它会直接将搜索条件与索引中的词项进行完全匹配。
2. Match 查询： Match 查询是一种通过分词来进行全文搜索的查询方式。它会对搜索条件进行分词，并将分词后的词项与索引中的词项进行匹配。

Match 查询具有更高的灵活性和智能性，它会根据相关性评分（score）对结果进行排序，并返回与搜索条件最匹配的文档。它适用于全文搜索需求，可以处理大部分的搜索场景。

总结来说，Term 查询用于精确匹配，不进行分词处理；而Match 查询用于全文搜索，进行了分词处理和相关性评分。



### 42、分词器的原理

分词器（Tokenizer）是在搜索引擎中用于将文本拆分成词项的组件。它是搜索引擎进行全文搜索和建立倒排索引的基础。分词器将输入的文本进行处理，将其拆分成一个个有意义的词项，以便搜索引擎能够对其进行索引和搜索。

分词器的原理如下：

1. 标记化（Tokenization）： 分词器首先将输入的文本进行标记化，将整个文本拆分成一个个的标记或词项（Tokens）。标记可以是单词、数字、符号、短语等，它们是搜索的基本单位。
2. 字符过滤（Character Filtering）： 分词器对每个标记进行字符过滤，去除掉文本中的无关字符。例如，可以去掉标点符号、特殊符号等。
3. 小写化（Lowercasing）： 分词器通常将标记转换为小写字母形式。这样可以忽略大小写的差异，使搜索更加灵活。
4. 分词（Token Filtering）： 接下来，分词器根据一定的规则和算法对标记进行进一步的分词处理。这包括词干提取（Stemming）、词形还原（Lemmatization）、停用词过滤（Stopword Removal）等。词干提取和词形还原是将单词还原为其原始形式，以便能够匹配更多的相关结果。停用词过滤是去除那些在搜索中没有实际意义的常见词语，如"的"、"是"等。
5. 输出词项： 最后，分词器将处理后的词项输出，供搜索引擎使用。这些词项将用于构建倒排索引，以提供高效的全文搜索和相关性评分。



### 43、分词器的原理

1. 标记化（Tokenization）： 标记化是将文本切分成一个个有意义的标记或词项（Tokens）的过程。标记可以是单词、数字、符号或短语等。一般来说，标记化的方法有两种常见的方式：
   - 基于规则的标记化：这种方法使用一系列预定义的规则或正则表达式来切分文本。例如，通过按照空格、标点符号等进行切分。
   - 基于机器学习的标记化：这种方法利用机器学习模型，根据大量的训练数据来学习如何将文本切分成有意义的标记。常见的机器学习算法包括最大匹配、最大熵模型、条件随机场等。
2. 字符过滤（Character Filtering）： 字符过滤是在标记化之后的一个步骤，它会去除文本中的无关字符，如标点符号、特殊符号等。字符过滤的目的是将文本限定在有效的词项范围内，去除干扰和噪音。
3. 小写化（Lowercasing）： 小写化是将标记转换为小写字母形式的过程。这样可以忽略大小写的差异，使搜索更加灵活。一般而言，在英文文本处理中进行小写化是常见的做法。
4. 分词（Token Filtering）： 分词是对标记进行进一步的处理，将它们细分成更具有语义意义的词项。这包括以下几个常见的操作：
   - 词干提取（Stemming）：词干提取是将单词缩减为其基本形式的过程。例如，将"running"、"runs"、"ran"等变为词干"run"。这样可以使不同形式的单词都能匹配到同一个词干。
   - 词形还原（Lemmatization）：词形还原是将单词还原为其原始形式的过程。与词干提取不同，词形还原会考虑上下文和词性等因素，将单词还原为其基本词形。例如，将"am"、"are"、"is"还原为词形"be"。
   - 停用词过滤（Stopword Removal）：停用词是在搜索中没有实际意义的常见词语。停用词过滤将这些词从文本中去除，以减小倒排索引的大小并提高搜索效率。例如，"的"、"是"、"and"等。
5. 输出词项： 处理后的词项将作为搜索引擎进行索引和搜索的基本单位。它们会用于构建倒排索引，其中包含每个词项出现在哪些文档中以及其出现的频率等信息。



中文分词器的原理可以进一步解释如下：

1. 基于词典的分词：
   - 正向最大匹配法（FMM）：从左到右遍历文本，并从最长的词开始匹配。匹配成功后，将该词作为一个词语，并从当前位置继续匹配下一个最长词。
   - 逆向最大匹配法（BMM）：从右到左遍历文本，并从最长的词开始匹配。匹配成功后，将该词作为一个词语，并从当前位置继续匹配下一个最长词。
   - 双向最大匹配法（BIMM）：同时使用正向和逆向最大匹配法，然后根据某种规则选择最优结果。通常可以比较两种方法得到的结果，选择词数更少的作为最终的分词结果。
2. 基于统计的分词：
   - 隐马尔可夫模型（HMM）：将文本看作是由一系列隐藏状态和观测状态组成的序列。在分词中，隐藏状态表示各个词语的边界，观测状态表示具体的字符。通过预先标注好的训练数据，可以建立HMM模型，并利用动态规划算法（如Viterbi算法）找到最优的隐藏状态序列，从而得到最优的分词结果。
   - 条件随机场（CRF）：利用特征函数建立条件概率模型，通过训练数据学习参数。在分词中，观测序列为字符，目标序列为词语边界。通过最大化给定观测序列下分词序列的条件概率，可以获得最优的分词结果。
3. 基于规则的分词：
   - 这种方法依赖于预定义的规则集。规则可以基于语法、词性、词典等进行设计。例如，根据句子的语法结构和一些常见的词性规则，将句子切分成词语。
4. 基于深度学习的分词：
   - 近年来，随着深度学习的发展，使用神经网络进行中文分词也越来越流行。通常使用循环神经网络（如长短时记忆网络，LSTM）或者Transformer模型，并通过大规模的标注数据进行训练。这些模型可以通过学习上下文信息来进行分词。



英文分词器的一种常见方法是基于空格和标点符号进行分割。它按照空格和标点符号将文本划分为单词，并忽略其他字符，如空格、标点符号等。这种方法的简单性使得它在许多应用中都可以得到很好的效果。



### 44、倒排索引是什么样的

倒排索引（Inverted Index）是一种常用的数据结构，用于快速定位文档中包含指定词语的位置。它由两部分组成：词典和倒排列表。

具体来说，倒排索引是将文档集合中的每个词语与包含该词语的文档列表关联起来。词典是由所有不重复的词语构成的数据结构，用于存储词语及其对应的倒排列表的位置信息。

倒排列表则记录了包含该词语的文档的详细信息，如文档的编号、出现的位置等。通常使用一个有序的列表来表示，以便快速查找和插入新的文档信息。



### 45、线程池某个线程挂了会对线程池出现什么影响



### 46、BlockingQueue有哪些实现类，基本原理，怎么实现阻塞的

Java 中的 BlockingQueue 接口有以下几个常用的实现类：

1. ArrayBlockingQueue：基于数组的有界阻塞队列。在队列已满时，插入操作会被阻塞，直到有空间可用。在队列为空时，获取操作会被阻塞，直到有元素可用。
2. LinkedBlockingQueue：基于链表的可选有界或无界阻塞队列。如果指定了容量，则队列是有界的；否则，队列是无界的。在队列已满时，插入操作会被阻塞，直到有空间可用。在队列为空时，获取操作会被阻塞，直到有元素可用。
3. PriorityBlockingQueue：基于优先级堆的无界阻塞队列。元素按照优先级进行排序，支持自定义排序规则。在插入和获取操作时都可能阻塞。
4. SynchronousQueue：一个不存储元素的阻塞队列。每个插入操作必须等待对应的删除操作，反之亦然。因此，SynchronousQueue 在同步数据传输场景中很有用。

BlockingQueue 的基本原理是使用内部锁和条件变量来实现阻塞操作。当队列满时，插入操作会被阻塞，直到有空间可用；当队列空时，获取操作会被阻塞，直到有元素可用。这种阻塞是基于线程同步的机制实现的。

具体实现阻塞的方式有以下几种：

1. 使用内部锁和条件变量：通过获取锁来确保线程互斥访问队列，在条件不满足时，通过条件变量将线程阻塞，直到条件满足。
2. 使用原子操作和自旋：通过原子操作比较并交换队列状态来确保队列的一致性，在条件不满足时，使用自旋等待条件满足，避免线程阻塞和唤醒带来的开销。
3. 使用信号量：通过信号量来实现线程的阻塞和唤醒。当队列满时，插入操作会等待空闲信号量；当队列空时，获取操作会等待非空信号量。



### 47、synchronized实现原理，锁的机制

 synchronized 的基本机制和锁的相关概念：

1. 内置锁：每个 Java 对象都有一个与之关联的内置锁。当使用 synchronized 关键字修饰方法或代码块时，实际上是将这部分代码与对象的内置锁关联起来。同一时刻只能有一个线程持有该对象的内置锁。
2. 互斥性：内置锁是一种互斥锁。当一个线程获取到对象的内置锁后，其他线程将被阻塞，在锁被释放之前无法进入被 synchronized 修饰的代码区域。
3. 重入性：同一个线程可以多次获取同一个对象的内置锁。如果一个线程已经获得了某个对象的锁，那么它可以再次进入由该对象锁保护的 synchronized 代码块，而不会被阻塞。
4. 对象监视器：每个对象都有一个与之关联的对象监视器（Monitor）。对象监视器包含着与该对象相关联的锁信息。当一个线程尝试获取对象的内置锁时，它实际上是在请求对象监视器的锁。
5. 锁的释放和获取：当线程进入 synchronized 代码块时，它会尝试获取对象的内置锁。如果锁未被其他线程占有，则该线程会获得锁并执行代码。而在执行完 synchronized 代码块后，线程会释放锁，使其他线程可以获取锁并进入临界区域。

使用 synchronized 实现线程同步时需要注意以下几点：

1. 对象级别锁：synchronized 可以应用于实例方法、静态方法和代码块，但需要注意锁的作用范围。对于实例方法和代码块，锁是对象级别的；而对于静态方法和代码块，锁是类级别的。
2. 锁的粒度：合理选择锁的粒度可以提高并发性能。如果锁的粒度过大，可能导致多个线程之间的竞争过于激烈，降低并发效率；如果锁的粒度过小，可能导致频繁地获取和释放锁，也会影响性能。
3. 避免死锁：死锁是多个线程相互等待对方持有的资源导致的阻塞状态。为避免死锁，应注意锁的获取顺序，避免出现循环依赖的情况